1:"$Sreact.fragment"
2:I[7921,["716","static/chunks/716-8b6c239d56add41d.js","98","static/chunks/98-71e6ffba5da79e51.js","177","static/chunks/app/layout-438f3f1dcf44f88c.js"],""]
3:I[8295,["716","static/chunks/716-8b6c239d56add41d.js","98","static/chunks/98-71e6ffba5da79e51.js","177","static/chunks/app/layout-438f3f1dcf44f88c.js"],"RootProvider"]
4:I[1409,[],""]
5:I[1813,[],""]
6:I[6053,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"TreeContextProvider"]
b:I[323,[],""]
:HL["/_next/static/media/bb3ef058b751a6ad-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/edef1a271f97a8ec-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/d0f7ca2a7022be00.css","style"]
:HL["/_next/static/css/62a6e77bcc5afb05.css","style"]
:HL["/_next/static/css/4cd23781d18a52d3.css","style"]
0:{"P":null,"b":"eGRMFVaehov3-S6q-y93b","p":"","c":["","docs","lecture-1","post-training-overview"],"i":false,"f":[[["",{"children":["docs",{"children":[["slug","lecture-1/post-training-overview","oc"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d0f7ca2a7022be00.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/62a6e77bcc5afb05.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/4cd23781d18a52d3.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"zh-CN","className":"__variable_51740a __variable_3c557b","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","$L2",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-6PZFJCKFSJ","strategy":"afterInteractive"}],["$","$L2",null,{"id":"google-analytics","strategy":"afterInteractive","children":"\n            window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-6PZFJCKFSJ');\n          "}]]}],["$","body",null,{"className":"flex min-h-screen flex-col","children":["$","$L3",null,{"search":{"options":{"type":"static"}},"children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}]]}],{"children":["docs",["$","$1","c",{"children":[null,["$","$L6",null,{"tree":{"$id":"root","name":"课程内容","children":[{"$id":"#0","type":"separator","icon":"$undefined","name":"课程内容"},{"$id":"index.mdx","type":"page","name":"课程总览","description":"大语言模型后训练实践——北京大学软件与微电子学院研究生课程","icon":"$undefined","url":"/docs","$ref":{"file":"index.mdx"}},{"$id":"#2","type":"separator","icon":"$undefined","name":"讲座"},{"type":"folder","name":"第1课：后训练概述与SFT基础","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"lecture-1/index.mdx","type":"page","name":"第1课：后训练概述与监督微调基础","description":"理解后训练在 LLM 开发流程中的位置和核心方法体系，掌握 SFT 训练循环，配置 LoRA/QLoRA 进行参数高效训练","icon":"$undefined","url":"/docs/lecture-1","$ref":{"file":"lecture-1/index.mdx"}},{"$id":"lecture-1/post-training-overview.mdx","type":"page","name":"1.1 后训练的定义与基本流程","description":"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践","icon":"$undefined","url":"/docs/lecture-1/post-training-overview","$ref":{"file":"lecture-1/post-training-overview.mdx"}},{"$id":"lecture-1/sft-core-concepts.mdx","type":"page","name":"1.2 监督微调核心概念","description":"掌握 ChatML 和 Llama 聊天模板格式，理解掩码损失（Masked Loss）的原理，了解数据质量的重要性","icon":"$undefined","url":"/docs/lecture-1/sft-core-concepts","$ref":{"file":"lecture-1/sft-core-concepts.mdx"}},{"$id":"lecture-1/parameter-efficient-ft.mdx","type":"page","name":"1.3 参数高效微调","description":"掌握 LoRA 和 QLoRA 的原理与实践，理解参数高效微调的必要性和显存优化策略","icon":"$undefined","url":"/docs/lecture-1/parameter-efficient-ft","$ref":{"file":"lecture-1/parameter-efficient-ft.mdx"}},{"$id":"lecture-1/evaluation-methods.mdx","type":"page","name":"1.4 模型评估方法","description":"了解 LLM 后训练的主流评估方法：LLM-as-Judge、人类偏好排行榜、能力专项基准和安全评估","icon":"$undefined","url":"/docs/lecture-1/evaluation-methods","$ref":{"file":"lecture-1/evaluation-methods.mdx"}},{"$id":"lecture-1/papers.mdx","type":"page","name":"第1课 推荐论文","description":"第1课推荐阅读的 5 篇核心论文：Tülu 3、LoRA、QLoRA、LIMA、MAGPIE","icon":"$undefined","url":"/docs/lecture-1/papers","$ref":{"file":"lecture-1/papers.mdx"}},{"$id":"lecture-1/lab.mdx","type":"page","name":"实验1：微调 Qwen3-1.7B 为指令跟随助手","description":"使用 QLoRA 和 SFTTrainer 将 Qwen3-1.7B 基座模型微调为指令跟随助手的完整实验","icon":"$undefined","url":"/docs/lecture-1/lab","$ref":{"file":"lecture-1/lab.mdx"}}],"$id":"lecture-1","$ref":{"metaFile":"lecture-1/meta.json"}},{"type":"folder","name":"第2课：SFT进阶","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"lecture-2/index.mdx","type":"page","name":"第2课：SFT 进阶——数据工程与指令微调深入","description":"掌握指令数据集的构建与质量控制方法，理解数据混合策略，实践 LLM-as-Judge 系统化评估","icon":"$undefined","url":"/docs/lecture-2","$ref":{"file":"lecture-2/index.mdx"}},{"$id":"lecture-2/instruction-datasets.mdx","type":"page","name":"2.1 指令数据集构建方法","description":"从 Self-Instruct 到 MAGPIE 的指令数据集技术演进，数据质量控制方法，数据混合策略","icon":"$undefined","url":"/docs/lecture-2/instruction-datasets","$ref":{"file":"lecture-2/instruction-datasets.mdx"}},{"$id":"lecture-2/sft-hyperparameters.mdx","type":"page","name":"2.2 SFT 超参数实践指南","description":"基于 Pareja 等（2024）的系统实验结果，掌握 SFT 核心超参数的选择方法和常见问题诊断","icon":"$undefined","url":"/docs/lecture-2/sft-hyperparameters","$ref":{"file":"lecture-2/sft-hyperparameters.mdx"}},{"$id":"lecture-2/llm-as-judge.mdx","type":"page","name":"2.3 LLM-as-Judge 评估方法","description":"深入理解 LLM-as-Judge 评估框架，掌握 MT-Bench 评判模板，了解位置偏差和评委模型选择","icon":"$undefined","url":"/docs/lecture-2/llm-as-judge","$ref":{"file":"lecture-2/llm-as-judge.mdx"}},{"$id":"lecture-2/papers.mdx","type":"page","name":"第2课 推荐论文","description":"第2课推荐阅读的 5 篇核心论文：SFT 超参数指南、Self-Instruct、MT-Bench、UltraChat、Deita","icon":"$undefined","url":"/docs/lecture-2/papers","$ref":{"file":"lecture-2/papers.mdx"}},{"$id":"lecture-2/lab.mdx","type":"page","name":"实验2：构建领域定制 SFT 模型并系统评估","description":"从数据分析到模型训练到 LLM-as-Judge 评估的完整指令微调实验，含消融实验","icon":"$undefined","url":"/docs/lecture-2/lab","$ref":{"file":"lecture-2/lab.mdx"}}],"$id":"lecture-2","$ref":{"metaFile":"lecture-2/meta.json"}},{"type":"folder","name":"第3课：偏好对齐DPO","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"lecture-3/index.mdx","type":"page","name":"第3课：偏好对齐——DPO 及其变体","description":"理解为什么仅靠 SFT 不足以实现对齐，从 RLHF 目标推导 DPO 损失函数，实现 DPO 训练，并对 DPO 与 SimPO 进行实证比较","icon":"$undefined","url":"/docs/lecture-3","$ref":{"file":"lecture-3/index.mdx"}},{"$id":"lecture-3/alignment-problem.mdx","type":"page","name":"3.1 对齐问题：为什么仅靠 SFT 不够","description":"SFT 教会模型'说什么'，但未教会它'如何选择'。人类偏好本质上是比较性的，偏好优化直接捕获这一信号。","icon":"$undefined","url":"/docs/lecture-3/alignment-problem","$ref":{"file":"lecture-3/alignment-problem.mdx"}},{"$id":"lecture-3/dpo-derivation.mdx","type":"page","name":"3.2 DPO 数学推导","description":"从 RLHF 目标到 DPO 损失函数的完整四步推导，包括闭式最优策略、奖励重参数化和 Bradley-Terry 代入","icon":"$undefined","url":"/docs/lecture-3/dpo-derivation","$ref":{"file":"lecture-3/dpo-derivation.mdx"}},{"$id":"lecture-3/dpo-variants.mdx","type":"page","name":"3.3 DPO 变体","description":"SimPO、KTO、ORPO、IPO 等 DPO 变体的设计理念、数学公式与适用场景比较","icon":"$undefined","url":"/docs/lecture-3/dpo-variants","$ref":{"file":"lecture-3/dpo-variants.mdx"}},{"$id":"lecture-3/practical-considerations.mdx","type":"page","name":"3.4 实践考量","description":"在线 vs 离线 DPO、beta 参数敏感性分析、偏好数据质量、当前领域趋势","icon":"$undefined","url":"/docs/lecture-3/practical-considerations","$ref":{"file":"lecture-3/practical-considerations.mdx"}},{"$id":"lecture-3/papers.mdx","type":"page","name":"第3课推荐论文","description":"DPO、SimPO、KTO、DPO vs PPO 对比实验、DPO 综述等 5 篇核心论文","icon":"$undefined","url":"/docs/lecture-3/papers","$ref":{"file":"lecture-3/papers.mdx"}},{"$id":"lecture-3/lab.mdx","type":"page","name":"第3课实验：DPO 对齐与 SimPO 对比","description":"使用 DPO 对齐 SFT 模型，与 SimPO 进行实证对比，涵盖偏好数据探索、训练、评估的完整流程","icon":"$undefined","url":"/docs/lecture-3/lab","$ref":{"file":"lecture-3/lab.mdx"}}],"$id":"lecture-3","$ref":{"metaFile":"lecture-3/meta.json"}},{"type":"folder","name":"第4课：RLHF与GRPO","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"lecture-4/index.mdx","type":"page","name":"第4课：RLHF 原理与推理强化学习（GRPO）","description":"理解完整的 RLHF 流程，掌握 GRPO 算法，使用可验证奖励复现迷你 DeepSeek-R1-Zero 实验，观察推理能力的涌现","icon":"$undefined","url":"/docs/lecture-4","$ref":{"file":"lecture-4/index.mdx"}},{"$id":"lecture-4/rlhf-pipeline.mdx","type":"page","name":"4.1 经典 RLHF 流程","description":"InstructGPT 三阶段流程、奖励模型训练、PPO 核心组件、四模型架构及常见不稳定性","icon":"$undefined","url":"/docs/lecture-4/rlhf-pipeline","$ref":{"file":"lecture-4/rlhf-pipeline.mdx"}},{"$id":"lecture-4/grpo-reasoning.mdx","type":"page","name":"4.2 GRPO 与推理涌现","description":"DeepSeek-R1-Zero 里程碑、GRPO 四步算法详解、RLVR 可验证奖励、DeepSeek-R1 完整流程","icon":"$undefined","url":"/docs/lecture-4/grpo-reasoning","$ref":{"file":"lecture-4/grpo-reasoning.mdx"}},{"$id":"lecture-4/grpo-improvements.mdx","type":"page","name":"4.3 GRPO 改进与测试时计算","description":"DAPO、Dr. GRPO、REINFORCE++ 等改进方法，以及测试时计算扩展的概念和与 o1/o3/R1 的连接","icon":"$undefined","url":"/docs/lecture-4/grpo-improvements","$ref":{"file":"lecture-4/grpo-improvements.mdx"}},{"$id":"lecture-4/rlhf-engineering.mdx","type":"page","name":"4.4 RLHF 工程工具","description":"TRL、OpenRLHF、veRL 等 RLHF/GRPO 训练工具的功能、架构和使用场景对比","icon":"$undefined","url":"/docs/lecture-4/rlhf-engineering","$ref":{"file":"lecture-4/rlhf-engineering.mdx"}},{"$id":"lecture-4/papers.mdx","type":"page","name":"第4课推荐论文","description":"InstructGPT、DeepSeek-R1、DeepSeekMath、Snell et al.、DAPO、Safe RLHF、Qwen3 等 7 篇核心论文","icon":"$undefined","url":"/docs/lecture-4/papers","$ref":{"file":"lecture-4/papers.mdx"}},{"$id":"lecture-4/lab.mdx","type":"page","name":"第4课实验：迷你 DeepSeek-R1-Zero","description":"使用 GRPO 训练 Qwen3-1.7B-Base 进行数学推理，观察推理能力的涌现过程，并与蒸馏模型和 Qwen3 思考模式对比","icon":"$undefined","url":"/docs/lecture-4/lab","$ref":{"file":"lecture-4/lab.mdx"}}],"$id":"lecture-4","$ref":{"metaFile":"lecture-4/meta.json"}},{"type":"folder","name":"第5课：压缩部署与扩展","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"lecture-5/index.mdx","type":"page","name":"第5课：模型压缩、部署优化与能力扩展","description":"掌握模型量化的原理与实践（INT8/INT4/GPTQ/AWQ），理解知识蒸馏在后训练中的角色，了解多模态和工具使用等能力扩展方法","icon":"$undefined","url":"/docs/lecture-5","$ref":{"file":"lecture-5/index.mdx"}},{"$id":"lecture-5/quantization.mdx","type":"page","name":"5.1 模型量化","description":"深入理解模型量化的原理、主流 PTQ 方法（INT8/INT4/GPTQ/AWQ）与 QAT，掌握精度-速度-显存的权衡","icon":"$undefined","url":"/docs/lecture-5/quantization","$ref":{"file":"lecture-5/quantization.mdx"}},{"$id":"lecture-5/knowledge-distillation.mdx","type":"page","name":"5.2 知识蒸馏","description":"理解经典知识蒸馏范式、LLM 时代的蒸馏实践（DeepSeek-R1-Distill、Qwen3 思考模式融合），以及蒸馏与 RL 训练的权衡","icon":"$undefined","url":"/docs/lecture-5/knowledge-distillation","$ref":{"file":"lecture-5/knowledge-distillation.mdx"}},{"$id":"lecture-5/capability-extensions.mdx","type":"page","name":"5.3 能力扩展概览","description":"多模态后训练（VLM/LLaVA）、工具使用与智能体（函数调用/MCP）、知识编辑（参数编辑/RAG）三大能力扩展方向","icon":"$undefined","url":"/docs/lecture-5/capability-extensions","$ref":{"file":"lecture-5/capability-extensions.mdx"}},{"$id":"lecture-5/papers.mdx","type":"page","name":"第5课 推荐论文","description":"GPTQ、AWQ、LLaVA、ToolACE、DeepSeek-R1 等 5 篇核心论文，涵盖量化、多模态、工具使用与蒸馏","icon":"$undefined","url":"/docs/lecture-5/papers","$ref":{"file":"lecture-5/papers.mdx"}},{"$id":"lecture-5/lab.mdx","type":"page","name":"第5课 上机实验","description":"量化实验（必做）：多精度加载 Qwen3-8B 并评估压缩影响；能力扩展选做（三选一）：蒸馏分析、多模态实验、工具调用实验","icon":"$undefined","url":"/docs/lecture-5/lab","$ref":{"file":"lecture-5/lab.mdx"}}],"$id":"lecture-5","$ref":{"metaFile":"lecture-5/meta.json"}},{"type":"folder","name":"第6课：项目报告与总结","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"lecture-6/index.mdx","type":"page","name":"第6课：课程项目报告与总结","description":"课程项目报告展示、评分标准，以及后训练技术全景回顾与前沿展望","icon":"$undefined","url":"/docs/lecture-6","$ref":{"file":"lecture-6/index.mdx"}},{"$id":"lecture-6/project-directions.mdx","type":"page","name":"推荐项目方向","description":"7 个推荐的课程项目方向，涵盖数学推理、安全对齐、中文写作、代码推理、领域问答、视觉问答、工具调用智能体","icon":"$undefined","url":"/docs/lecture-6/project-directions","$ref":{"file":"lecture-6/project-directions.mdx"}},{"$id":"lecture-6/presentation-guide.mdx","type":"page","name":"演示指南与评分标准","description":"项目演示的时间安排、内容要求、评分细则，以及高质量演示的实用技巧","icon":"$undefined","url":"/docs/lecture-6/presentation-guide","$ref":{"file":"lecture-6/presentation-guide.mdx"}},{"$id":"lecture-6/course-summary.mdx","type":"page","name":"课程总结与展望","description":"后训练技术完整图谱回顾，从 SFT 到 GRPO 的完整路径，以及后训练领域的前沿研究方向","icon":"$undefined","url":"/docs/lecture-6/course-summary","$ref":{"file":"lecture-6/course-summary.mdx"}}],"$id":"lecture-6","$ref":{"metaFile":"lecture-6/meta.json"}},{"$id":"#9","type":"separator","icon":"$undefined","name":"资源"},{"type":"folder","name":"课程资源","icon":"$undefined","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","index":"$undefined","children":[{"$id":"resources/setup-guide.mdx","type":"page","name":"环境配置指南","description":"AutoDL 环境搭建、Colab Pro 替代方案、依赖安装、模型预下载、一键启动脚本与验证步骤","icon":"$undefined","url":"/docs/resources/setup-guide","$ref":{"file":"resources/setup-guide.mdx"}},{"$id":"resources/gpu-cost-guide.mdx","type":"page","name":"GPU 配置与费用估算","description":"各课次 GPU 配置推荐、AutoDL 费用明细、省钱技巧与替代平台","icon":"$undefined","url":"/docs/resources/gpu-cost-guide","$ref":{"file":"resources/gpu-cost-guide.mdx"}},{"$id":"resources/references.mdx","type":"page","name":"完整参考文献","description":"按课次整理的全部推荐论文、教材和在线资源","icon":"$undefined","url":"/docs/resources/references","$ref":{"file":"resources/references.mdx"}},{"$id":"resources/grading.mdx","type":"page","name":"评分标准","description":"课程考核方式、各项评分细则与评分标准详细说明","icon":"$undefined","url":"/docs/resources/grading","$ref":{"file":"resources/grading.mdx"}}],"$id":"resources","$ref":{"metaFile":"resources/meta.json"}}]},"children":"$L7"}]]}],{"children":[["slug","lecture-1/post-training-overview","oc"],"$L8",{"children":["__PAGE__","$L9",{},null,false]},null,false]},null,false]},null,false],"$La",false]],"m":"$undefined","G":["$b",[]],"s":false,"S":true}
c:I[4564,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"NavProvider"]
d:I[4196,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"Navbar"]
e:I[7326,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"default"]
f:I[140,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SearchToggle"]
10:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarTrigger"]
11:I[4196,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"LayoutBody"]
12:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"Sidebar"]
13:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarContentMobile"]
14:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarHeader"]
15:I[5461,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"ThemeToggle"]
16:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarViewport"]
17:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarItem"]
18:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarPageTree"]
19:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarFooter"]
1a:I[4196,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"CollapsibleControl"]
1b:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarContent"]
1c:I[9896,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"SidebarCollapseTrigger"]
1d:I[140,["285","static/chunks/285-5cab2c46bf0cbdc3.js","698","static/chunks/698-2edc64166f51fb90.js","997","static/chunks/997-8062435351294ce8.js","795","static/chunks/795-2e60776a7ce82cea.js","499","static/chunks/app/docs/layout-8640be9db805fb1e.js"],"LargeSearchToggle"]
1f:I[3652,[],"OutletBoundary"]
21:I[1293,[],"AsyncMetadataOutlet"]
23:I[3652,[],"ViewportBoundary"]
25:I[3652,[],"MetadataBoundary"]
26:"$Sreact.suspense"
7:["$","$Lc",null,{"transparentMode":"$undefined","children":[["$","$Ld",null,{"className":"h-(--fd-nav-height) on-root:[--fd-nav-height:56px] md:on-root:[--fd-nav-height:0px] md:hidden","children":[["$","$Le",null,{"href":"/","className":"inline-flex items-center gap-2.5 font-semibold","children":"LLM 后训练课程"}],["$","div",null,{"className":"flex-1","children":"$undefined"}],["$","$Lf",null,{"className":"p-2","hideIfDisabled":true}],["$","$L10",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&_svg]:size-4.5 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide","children":[[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}]],"$undefined"]}]}]]}],["$","$L11",null,{"className":"md:[&_#nd-page_article]:pt-12 xl:[--fd-toc-width:286px] xl:[&_#nd-page_article]:px-8 md:[--fd-sidebar-width:268px] lg:[--fd-sidebar-width:286px]","children":[["$","$L12",null,{"defaultOpenLevel":"$undefined","prefetch":"$undefined","Mobile":["$","$L13",null,{"children":[["$","$L14",null,{"children":[["$","div",null,{"className":"flex text-fd-muted-foreground items-center gap-1.5","children":[["$","div",null,{"className":"flex flex-1","children":[]}],null,["$","$L15",null,{"className":"p-0","mode":"$undefined"}],["$","$L10",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&_svg]:size-4.5 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide","children":[[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}]],"$undefined"]}]}]]}],false,"$undefined"]}],["$","$L16",null,{"children":[[["$","$L17","0",{"href":"/docs","icon":"$undefined","external":"$undefined","className":"mb-4","children":"课程内容"}]],["$","$L18",null,{"components":"$undefined"}]]}],["$","$L19",null,{"className":"empty:hidden","children":"$undefined"}]]}],"Content":[["$","$L1a",null,{}],["$","$L1b",null,{"children":[["$","$L14",null,{"children":[["$","div",null,{"className":"flex","children":[["$","$Le",null,{"href":"/","className":"inline-flex text-[15px] items-center gap-2.5 font-medium me-auto","children":"LLM 后训练课程"}],"$undefined",["$","$L1c",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&_svg]:size-4.5 mb-auto text-fd-muted-foreground","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide","children":[[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}]],"$undefined"]}]}]]}],["$","$L1d",null,{"hideIfDisabled":true}],false,"$undefined"]}],"$7:props:children:1:props:children:0:props:Mobile:props:children:1",["$","$L19",null,{"children":[["$","div",null,{"className":"flex text-fd-muted-foreground items-center empty:hidden","children":[false,[],["$","$L15",null,{"className":"ms-auto p-0","mode":"$undefined"}]]}],"$undefined"]}]]}]]}],false,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]]}]
8:["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":["$L1e",null,["$","$L1f",null,{"children":["$L20",["$","$L21",null,{"promise":"$@22"}]]}]]}]
a:["$","$1","h",{"children":[null,[["$","$L23",null,{"children":"$L24"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$L25",null,{"children":["$","div",null,{"hidden":true,"children":["$","$26",null,{"fallback":null,"children":"$L27"}]}]}]]}]
28:I[2853,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"TOCProvider"]
29:I[3448,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"PageTOCPopover"]
2a:I[3448,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"PageTOCPopoverTrigger"]
2b:I[3448,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"PageTOCPopoverContent"]
2c:I[2853,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"TOCScrollArea"]
2d:I[2853,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"TOCItems"]
2e:I[3448,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"PageBreadcrumb"]
1e:["$","$L28",null,{"toc":[{"depth":2,"url":"#llm-开发的三阶段流程","title":"LLM 开发的三阶段流程"},{"depth":3,"url":"#阶段一预训练pre-training","title":"阶段一：预训练（Pre-training）"},{"depth":3,"url":"#阶段二后训练post-training","title":"阶段二：后训练（Post-training）"},{"depth":3,"url":"#阶段三推理阶段inference","title":"阶段三：推理阶段（Inference）"},{"depth":2,"url":"#后训练的核心方法全景","title":"后训练的核心方法全景"},{"depth":3,"url":"#1-监督微调supervised-fine-tuning-sft","title":"1. 监督微调（Supervised Fine-Tuning, SFT）"},{"depth":3,"url":"#2-偏好对齐preference-alignment-dporlhf","title":"2. 偏好对齐（Preference Alignment: DPO/RLHF）"},{"depth":3,"url":"#3-推理强化学习reasoning-rl-grporlvr","title":"3. 推理强化学习（Reasoning RL: GRPO/RLVR）"},{"depth":3,"url":"#4-专项适配","title":"4. 专项适配"},{"depth":2,"url":"#tülu-3开源后训练的黄金标准","title":"Tülu 3：开源后训练的黄金标准"},{"depth":3,"url":"#sft-阶段","title":"SFT 阶段"},{"depth":3,"url":"#dpo-阶段","title":"DPO 阶段"},{"depth":3,"url":"#rlvr-阶段","title":"RLVR 阶段"},{"depth":2,"url":"#qwen3-的四阶段后训练流程","title":"Qwen3 的四阶段后训练流程"},{"depth":3,"url":"#阶段-1长思维链冷启动-sftlong-cot-cold-start","title":"阶段 1：长思维链冷启动 SFT（Long-CoT Cold Start）"},{"depth":3,"url":"#阶段-2推理-rlreasoning-reinforcement-learning","title":"阶段 2：推理 RL（Reasoning Reinforcement Learning）"},{"depth":3,"url":"#阶段-3思考模式融合thinking-mode-fusion","title":"阶段 3：思考模式融合（Thinking Mode Fusion）"},{"depth":3,"url":"#阶段-4通用-rlgeneral-reinforcement-learning","title":"阶段 4：通用 RL（General Reinforcement Learning）"},{"depth":2,"url":"#think-和-no_think-模式演示","title":[["$","code",null,{"children":"/think"}]," 和 ",["$","code",null,{"children":"/no_think"}]," 模式演示"]},{"depth":2,"url":"#本节小结","title":"本节小结"}],"single":"$undefined","children":["$","div",null,{"id":"nd-page","className":"flex flex-1 w-full mx-auto max-w-(--fd-page-width) pt-(--fd-tocnav-height) pe-(--fd-toc-width)","children":[["$","$L29",null,{"children":[["$","$L2a",null,{}],["$","$L2b",null,{"children":["$undefined",["$","$L2c",null,{"children":["$","$L2d",null,{}]}],"$undefined"]}]]}],["$","article",null,{"children":[["$","$L2e",null,{}],[["$","h1",null,{"ref":"$undefined","children":"1.1 后训练的定义与基本流程","className":"text-[1.75em] font-semibold"}],["$","p",null,{"ref":"$undefined","children":"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践","className":"mb-8 text-lg text-fd-muted-foreground"}],["$","div",null,{"ref":"$undefined","children":[["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"llm-开发的三阶段流程","children":[["$","a",null,{"data-card":"","href":"#llm-开发的三阶段流程","className":"peer","children":"LLM 开发的三阶段流程"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],"\n",["$","p",null,{"children":"现代大语言模型（LLM）的开发可以清晰地划分为三个阶段："}],"\n",["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段一预训练pre-training","children":[["$","a",null,{"data-card":"","href":"#阶段一预训练pre-training","className":"peer","children":"阶段一：预训练（Pre-training）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],"\n",["$","p",null,{"children":["预训练是 LLM 的基础。在这一阶段，模型在",["$","strong",null,{"children":"万亿级 token"}]," 的大规模语料上进行下一个 token 预测（next-token prediction），学习语言知识和世界知识。"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"计算量"}],"：极其巨大，通常需要数千张 GPU 训练数周到数月"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"训练目标"}],"：标准的语言建模目标，最小化负对数似然"]}],"\n"]}],"\n",["$","span",null,{"className":"katex-display","children":["$","span",null,{"className":"katex","children":[["$","span",null,{"className":"katex-mathml","children":"$L2f"}],"$L30"]}]}],"\n","$L31","\n","$L32","\n","$L33","\n","$L34","\n","$L35","\n","$L36","\n","$L37","\n","$L38","\n","$L39","\n","$L3a","\n","$L3b","\n","$L3c","\n","$L3d","\n","$L3e","\n","$L3f","\n","$L40","\n","$L41","\n","$L42","\n","$L43","\n","$L44","\n","$L45","\n","$L46","\n","$L47","\n","$L48","\n","$L49","\n","$L4a","\n","$L4b","\n","$L4c","\n","$L4d","\n","$L4e","\n","$L4f","\n","$L50","\n","$L51","\n","$L52","\n","$L53","\n","$L54","\n","$L55","\n","$L56","\n","$L57","\n","$L58","\n","$L59","\n","$L5a","\n","$L5b","\n","$L5c","\n","$L5d"],"className":"prose flex-1"}]],"$L5e","$L5f"],"className":"flex min-w-0 w-full flex-col gap-4 pt-8 px-4 md:px-6 md:mx-auto"}],"$L60"]}]}]
67:I[646,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"CodeBlock"]
68:I[646,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"Pre"]
6c:I[5282,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"Tabs"]
6d:I[5282,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"Tab"]
71:I[3448,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"PageFooter"]
72:I[3448,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"PageTOC"]
73:I[3734,["285","static/chunks/285-5cab2c46bf0cbdc3.js","697","static/chunks/697-8c55336afc55c2a1.js","324","static/chunks/324-9e7d7f5bb89b8982.js","870","static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js"],"I18nLabel"]
2f:["$","math",null,{"xmlns":"http://www.w3.org/1998/Math/MathML","display":"block","children":["$","semantics",null,{"children":[["$","mrow",null,{"children":[["$","msub",null,{"children":[["$","mi",null,{"mathvariant":"script","children":"L"}],["$","mtext",null,{"children":"pretrain"}]]}],["$","mo",null,{"children":"="}],["$","mo",null,{"children":"−"}],["$","munderover",null,{"children":[["$","mo",null,{"children":"∑"}],["$","mrow",null,{"children":[["$","mi",null,{"children":"t"}],["$","mo",null,{"children":"="}],["$","mn",null,{"children":"1"}]]}],["$","mi",null,{"children":"T"}]]}],["$","mi",null,{"children":"log"}],["$","mo",null,{"children":"⁡"}],["$","msub",null,{"children":[["$","mi",null,{"children":"P"}],["$","mi",null,{"children":"θ"}]]}],["$","mo",null,{"stretchy":"false","children":"("}],["$","msub",null,{"children":[["$","mi",null,{"children":"x"}],["$","mi",null,{"children":"t"}]]}],["$","mi",null,{"mathvariant":"normal","children":"∣"}],["$","msub",null,{"children":[["$","mi",null,{"children":"x"}],["$","mrow",null,{"children":[["$","mo",null,{"children":"<"}],["$","mi",null,{"children":"t"}]]}]]}],["$","mo",null,{"stretchy":"false","children":")"}]]}],["$","annotation",null,{"encoding":"application/x-tex","children":"\\mathcal{L}_{\\text{pretrain}} = -\\sum_{t=1}^{T} \\log P_\\theta(x_t | x_{<t})"}]]}]}]
30:["$","span",null,{"className":"katex-html","aria-hidden":"true","children":[["$","span",null,{"className":"base","children":[["$","span",null,{"className":"strut","style":{"height":"0.9694em","verticalAlign":"-0.2861em"}}],["$","span",null,{"className":"mord","children":[["$","span",null,{"className":"mord mathcal","children":"L"}],["$","span",null,{"className":"msupsub","children":["$","span",null,{"className":"vlist-t vlist-t2","children":[["$","span",null,{"className":"vlist-r","children":[["$","span",null,{"className":"vlist","style":{"height":"0.3175em"},"children":["$","span",null,{"style":{"top":"-2.55em","marginLeft":"0em","marginRight":"0.05em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"2.7em"}}],["$","span",null,{"className":"sizing reset-size6 size3 mtight","children":["$","span",null,{"className":"mord mtight","children":["$","span",null,{"className":"mord text mtight","children":["$","span",null,{"className":"mord mtight","children":"pretrain"}]}]}]}]]}]}],["$","span",null,{"className":"vlist-s","children":"​"}]]}],["$","span",null,{"className":"vlist-r","children":["$","span",null,{"className":"vlist","style":{"height":"0.2861em"},"children":["$","span",null,{}]}]}]]}]}]]}],["$","span",null,{"className":"mspace","style":{"marginRight":"0.2778em"}}],["$","span",null,{"className":"mrel","children":"="}],["$","span",null,{"className":"mspace","style":{"marginRight":"0.2778em"}}]]}],["$","span",null,{"className":"base","children":[["$","span",null,{"className":"strut","style":{"height":"3.0954em","verticalAlign":"-1.2671em"}}],["$","span",null,{"className":"mord","children":"−"}],["$","span",null,{"className":"mspace","style":{"marginRight":"0.1667em"}}],["$","span",null,{"className":"mop op-limits","children":["$","span",null,{"className":"vlist-t vlist-t2","children":[["$","span",null,{"className":"vlist-r","children":[["$","span",null,{"className":"vlist","style":{"height":"1.8283em"},"children":[["$","span",null,{"style":{"top":"-1.8829em","marginLeft":"0em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"3.05em"}}],["$","span",null,{"className":"sizing reset-size6 size3 mtight","children":["$","span",null,{"className":"mord mtight","children":[["$","span",null,{"className":"mord mathnormal mtight","children":"t"}],["$","span",null,{"className":"mrel mtight","children":"="}],["$","span",null,{"className":"mord mtight","children":"1"}]]}]}]]}],["$","span",null,{"style":{"top":"-3.05em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"3.05em"}}],["$","span",null,{"children":["$","span",null,{"className":"mop op-symbol large-op","children":"∑"}]}]]}],["$","span",null,{"style":{"top":"-4.3em","marginLeft":"0em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"3.05em"}}],["$","span",null,{"className":"sizing reset-size6 size3 mtight","children":["$","span",null,{"className":"mord mtight","children":["$","span",null,{"className":"mord mathnormal mtight","style":{"marginRight":"0.13889em"},"children":"T"}]}]}]]}]]}],["$","span",null,{"className":"vlist-s","children":"​"}]]}],["$","span",null,{"className":"vlist-r","children":["$","span",null,{"className":"vlist","style":{"height":"1.2671em"},"children":["$","span",null,{}]}]}]]}]}],["$","span",null,{"className":"mspace","style":{"marginRight":"0.1667em"}}],["$","span",null,{"className":"mop","children":["lo",["$","span",null,{"style":{"marginRight":"0.01389em"},"children":"g"}]]}],["$","span",null,{"className":"mspace","style":{"marginRight":"0.1667em"}}],["$","span",null,{"className":"mord","children":[["$","span",null,{"className":"mord mathnormal","style":{"marginRight":"0.13889em"},"children":"P"}],["$","span",null,{"className":"msupsub","children":["$","span",null,{"className":"vlist-t vlist-t2","children":[["$","span",null,{"className":"vlist-r","children":[["$","span",null,{"className":"vlist","style":{"height":"0.3361em"},"children":["$","span",null,{"style":{"top":"-2.55em","marginLeft":"-0.1389em","marginRight":"0.05em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"2.7em"}}],["$","span",null,{"className":"sizing reset-size6 size3 mtight","children":["$","span",null,{"className":"mord mathnormal mtight","style":{"marginRight":"0.02778em"},"children":"θ"}]}]]}]}],["$","span",null,{"className":"vlist-s","children":"​"}]]}],["$","span",null,{"className":"vlist-r","children":["$","span",null,{"className":"vlist","style":{"height":"0.15em"},"children":["$","span",null,{}]}]}]]}]}]]}],["$","span",null,{"className":"mopen","children":"("}],["$","span",null,{"className":"mord","children":[["$","span",null,{"className":"mord mathnormal","children":"x"}],["$","span",null,{"className":"msupsub","children":["$","span",null,{"className":"vlist-t vlist-t2","children":[["$","span",null,{"className":"vlist-r","children":[["$","span",null,{"className":"vlist","style":{"height":"0.2806em"},"children":["$","span",null,{"style":{"top":"-2.55em","marginLeft":"0em","marginRight":"0.05em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"2.7em"}}],"$L61"]}]}],"$L62"]}],"$L63"]}]}]]}],"$L64","$L65","$L66"]}]]}]
31:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"产出"}],"：一个\"博学但不听话\"的",["$","strong",null,{"children":"基座模型"}],"（base model）——它拥有丰富的知识，但不会遵循人类指令、不懂对话格式、可能生成有害内容"]}],"\n"]}]
32:["$","div",null,{"ref":"$undefined","className":"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md","style":{"--callout-color":"var(--color-fd-info, var(--color-fd-muted))"},"children":[["$","div",null,{"role":"none","className":"w-0.5 bg-(--callout-color)/50 rounded-sm"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card","children":[[["$","circle","1mglay",{"cx":"12","cy":"12","r":"10"}],["$","path","1dtifu",{"d":"M12 16v-4"}],["$","path","e9boi3",{"d":"M12 8h.01"}]],"$undefined"]}],["$","div",null,{"className":"flex flex-col gap-2 min-w-0 flex-1","children":["$undefined",["$","div",null,{"className":"text-fd-muted-foreground prose-no-margin empty:hidden","children":["$","p",null,{"children":"以 Qwen3 为例：Qwen3 系列在约 36 万亿 token 上进行了预训练，涵盖 119 种语言和编程语言。预训练分为三个阶段（S1: 30T tokens, S2: 5T tokens, S3: 退火阶段），逐步提升数据质量。"}]}]]}]]}]
33:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段二后训练post-training","children":[["$","a",null,{"data-card":"","href":"#阶段二后训练post-training","className":"peer","children":"阶段二：后训练（Post-training）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
34:["$","p",null,{"children":"后训练是将基座模型转化为实用助手的关键阶段。通过 SFT、偏好对齐、强化学习等手段，赋予模型指令跟随、安全回复、推理思考等能力。"}]
35:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"计算量"}],"：仅占预训练的约 ",["$","strong",null,{"children":"5%"}],"（以 DeepSeek-R1 为例），但决定了模型的实际可用性"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"核心目标"}],"：让模型学会\"怎么说话\"、\"怎么选择\"、\"怎么思考\""]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"产出"}],"：一个能遵循指令、安全有用的",["$","strong",null,{"children":"对齐模型"}],"（aligned model / instruct model）"]}],"\n"]}]
36:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段三推理阶段inference","children":[["$","a",null,{"data-card":"","href":"#阶段三推理阶段inference","className":"peer","children":"阶段三：推理阶段（Inference）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
37:["$","p",null,{"children":"模型部署后的优化和扩展阶段："}]
38:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"部署优化"}],"：量化（INT8/INT4）、蒸馏、剪枝等方法减少模型体积和推理成本"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"推理时计算扩展"}],"：思维链（Chain-of-Thought）、best-of-N 采样、树搜索等方法在推理时分配更多计算资源"]}],"\n"]}]
39:["$","$L67",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L68",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{"children":"预训练（数月，数千GPU）        后训练（数天，数十GPU）          推理（毫秒级）"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"┌─────────────────┐     ┌─────────────────────┐     ┌──────────────────┐"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"│  万亿级 token    │     │  SFT → DPO → GRPO   │     │  量化 / 蒸馏      │"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"│  下一个 token 预测 │ ──→ │  指令跟随、偏好对齐、  │ ──→ │  推理时计算扩展    │"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"│  基座模型        │     │  推理能力            │     │  部署服务         │"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"└─────────────────┘     └─────────────────────┘     └──────────────────┘"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      ≈95% 成本                 ≈5% 成本                  面向用户"}]}]]}]}]}]
3a:["$","hr",null,{}]
3b:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"后训练的核心方法全景","children":[["$","a",null,{"data-card":"","href":"#后训练的核心方法全景","className":"peer","children":"后训练的核心方法全景"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
3c:["$","p",null,{"children":"后训练涵盖多种方法，按功能可分为四大类："}]
3d:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"1-监督微调supervised-fine-tuning-sft","children":[["$","a",null,{"data-card":"","href":"#1-监督微调supervised-fine-tuning-sft","className":"peer","children":"1. 监督微调（Supervised Fine-Tuning, SFT）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
3e:["$","p",null,{"children":[["$","strong",null,{"children":"教模型\"怎么说话\""}],"——学会遵循指令、按格式回复。"]}]
3f:["$","p",null,{"children":["SFT 使用高质量的 ",["$","code",null,{"children":"(指令, 回复)"}]," 对来训练模型。模型学习的是：给定一个指令，如何生成符合期望的回复。这是后训练的",["$","strong",null,{"children":"第一步"}],"，也是其他所有方法的基础。"]}]
40:["$","ul",null,{"children":["\n",["$","li",null,{"children":["输入：",["$","code",null,{"children":"\"用三句话介绍量子计算\""}]]}],"\n",["$","li",null,{"children":["期望输出：",["$","code",null,{"children":"\"量子计算利用量子力学原理进行信息处理...\""}]]}],"\n"]}]
41:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"2-偏好对齐preference-alignment-dporlhf","children":[["$","a",null,{"data-card":"","href":"#2-偏好对齐preference-alignment-dporlhf","className":"peer","children":"2. 偏好对齐（Preference Alignment: DPO/RLHF）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
42:["$","p",null,{"children":[["$","strong",null,{"children":"教模型\"怎么选择\""}],"——在多个可能的回复中选择更好的。"]}]
43:["$","p",null,{"children":["SFT 后的模型可能生成多种回复，但并非所有回复都同样好。偏好对齐通过",["$","strong",null,{"children":"人类偏好数据"}],"（\"回复 A 优于回复 B\"）来教模型区分好坏："]}]
44:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"RLHF"}],"（Reinforcement Learning from Human Feedback）：训练奖励模型 + PPO 优化"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"DPO"}],"（Direct Preference Optimization）：直接在偏好对上训练，无需奖励模型"]}],"\n"]}]
45:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"3-推理强化学习reasoning-rl-grporlvr","children":[["$","a",null,{"data-card":"","href":"#3-推理强化学习reasoning-rl-grporlvr","className":"peer","children":"3. 推理强化学习（Reasoning RL: GRPO/RLVR）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
46:["$","p",null,{"children":[["$","strong",null,{"children":"教模型\"怎么思考\""}],"——发展逐步推理和自我验证能力。"]}]
47:["$","p",null,{"children":["这是 2024-2025 年最激动人心的进展。通过",["$","strong",null,{"children":"可验证奖励"}],"（如数学答案的正确性），模型在纯强化学习中自发涌现出推理能力："]}]
48:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"GRPO"}],"（Group Relative Policy Optimization）：DeepSeek 提出的高效 RL 算法"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"RLVR"}],"（RL with Verifiable Rewards）：使用确定性奖励函数代替人类标注"]}],"\n"]}]
49:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"4-专项适配","children":[["$","a",null,{"data-card":"","href":"#4-专项适配","className":"peer","children":"4. 专项适配"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
4a:["$","p",null,{"children":"根据应用场景扩展模型能力："}]
4b:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"工具使用"}],"：学会调用 API、函数调用（Function Calling）"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"多模态理解"}],"：视觉-语言对齐（VLM）"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"领域知识注入"}],"：医疗、法律、金融等垂直领域微调"]}],"\n"]}]
4c:["$","hr",null,{}]
4d:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"tülu-3开源后训练的黄金标准","children":[["$","a",null,{"data-card":"","href":"#tülu-3开源后训练的黄金标准","className":"peer","children":"Tülu 3：开源后训练的黄金标准"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
4e:["$","p",null,{"children":[["$","$Le",null,{"href":"https://arxiv.org/abs/2411.15124","children":"Tülu 3"}],"（Lambert 等，2024）是目前最完整的开源后训练方案，其流程为本课程提供了核心参考框架："]}]
4f:["$","div",null,{"className":"fd-steps","children":[["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"sft-阶段","children":[["$","a",null,{"data-card":"","href":"#sft-阶段","className":"peer","children":"SFT 阶段"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],["$","p",null,{"children":"在精心混合的多源指令数据上进行监督微调。Tülu 3 使用了来自多个来源的数据，并通过系统性的数据混合实验确定最优配比。"}]]}],["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"dpo-阶段","children":[["$","a",null,{"data-card":"","href":"#dpo-阶段","className":"peer","children":"DPO 阶段"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],["$","p",null,{"children":["使用偏好数据进行 DPO 对齐，提升模型的回复质量和安全性。关键发现：",["$","strong",null,{"children":"在策略"}],"（on-policy）生成的偏好数据效果优于离线数据。"]}]]}],["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"rlvr-阶段","children":[["$","a",null,{"data-card":"","href":"#rlvr-阶段","className":"peer","children":"RLVR 阶段"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],["$","p",null,{"children":"使用可验证奖励进行强化学习，专门提升数学推理和指令跟随能力。这一步是 Tülu 3 在 GSM8K 等推理基准上取得突破的关键。"}]]}]]}]
50:["$","p",null,{"children":["Tülu 3 的核心贡献在于其",["$","strong",null,{"children":"系统性的消融实验"}],"：每一步的设计选择（数据配比、超参数、方法选型）都有实验支撑，为开源社区提供了可复现的最佳实践。"]}]
51:["$","hr",null,{}]
52:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"qwen3-的四阶段后训练流程","children":[["$","a",null,{"data-card":"","href":"#qwen3-的四阶段后训练流程","className":"peer","children":"Qwen3 的四阶段后训练流程"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
53:["$","p",null,{"children":["Qwen3 的后训练流程是本课程技术体系的",["$","strong",null,{"children":"最佳案例"}],"。根据 Qwen3 技术报告（arXiv:2505.09388），其后训练分为四个精心设计的阶段："]}]
54:["$","div",null,{"className":"fd-steps","children":[["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段-1长思维链冷启动-sftlong-cot-cold-start","children":[["$","a",null,{"data-card":"","href":"#阶段-1长思维链冷启动-sftlong-cot-cold-start","className":"peer","children":"阶段 1：长思维链冷启动 SFT（Long-CoT Cold Start）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],["$","p",null,{"children":["使用精心构造的",["$","strong",null,{"children":"长思维链数据"}],"进行 SFT，为模型注入基本的推理模式。这些数据包含详细的逐步推理过程，教会模型如何展开深度思考。"]}],["$","ul",null,{"children":["\n",["$","li",null,{"children":"数据来源：通过强模型生成、人工筛选的高质量推理数据"}],"\n",["$","li",null,{"children":["目标：让模型掌握 ",["$","code",null,{"children":"<think>...</think>"}]," 格式的思维链输出"]}],"\n"]}]]}],["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段-2推理-rlreasoning-reinforcement-learning","children":[["$","a",null,{"data-card":"","href":"#阶段-2推理-rlreasoning-reinforcement-learning","className":"peer","children":"阶段 2：推理 RL（Reasoning Reinforcement Learning）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],["$","p",null,{"children":["在数学、代码等可验证任务上进行大规模 ",["$","strong",null,{"children":"GRPO"}]," 训练，强化模型的推理能力。"]}],["$","ul",null,{"children":["\n",["$","li",null,{"children":"奖励信号：答案正确性（可验证奖励）"}],"\n",["$","li",null,{"children":"关键效果：模型学会了更长、更深入的推理链，自发涌现出自我验证和回溯能力"}],"\n"]}]]}],["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段-3思考模式融合thinking-mode-fusion","children":[["$","a",null,{"data-card":"","href":"#阶段-3思考模式融合thinking-mode-fusion","className":"peer","children":"阶段 3：思考模式融合（Thinking Mode Fusion）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}],["$","p",null,{"children":["将推理 RL 阶段获得的深度思考能力",["$","strong",null,{"children":"融合回统一模型"}],"，使模型同时具备："]}],["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"思考模式"}],"（Thinking Mode）：生成详细的内部推理过程"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"非思考模式"}],"（Non-Thinking Mode）：直接给出简洁回复"]}],"\n"]}],["$","p",null,{"children":["这一阶段本质上是一种",["$","strong",null,{"children":"蒸馏"}],"：将 RL 训练的推理专家能力蒸馏到一个统一的模型中。"]}]]}],["$","div",null,{"className":"fd-step","children":[["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"阶段-4通用-rlgeneral-reinforcement-learning","children":[["$","a",null,{"data-card":"","href":"#阶段-4通用-rlgeneral-reinforcement-learning","className":"peer","children":"阶段 4：通用 RL（General Reinforcement Learning）"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[["$L69","$L6a"],"$undefined"]}]]}],"$L6b"]}]]}]
55:["$","div",null,{"ref":"$undefined","className":"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md","style":{"--callout-color":"var(--color-fd-info, var(--color-fd-muted))"},"children":[["$","div",null,{"role":"none","className":"w-0.5 bg-(--callout-color)/50 rounded-sm"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card","children":[[["$","circle","1mglay",{"cx":"12","cy":"12","r":"10"}],["$","path","1dtifu",{"d":"M12 16v-4"}],["$","path","e9boi3",{"d":"M12 8h.01"}]],"$undefined"]}],["$","div",null,{"className":"flex flex-col gap-2 min-w-0 flex-1","children":["$undefined",["$","div",null,{"className":"text-fd-muted-foreground prose-no-margin empty:hidden","children":["$","p",null,{"children":"Qwen3 的四阶段后训练流程正好对应了本课程的技术体系：阶段 1 对应第 1-2 课（SFT），阶段 2 对应第 4 课（GRPO），阶段 3-4 对应第 3 课（偏好对齐）和第 5 课（部署优化）。"}]}]]}]]}]
56:["$","hr",null,{}]
57:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"think-和-no_think-模式演示","children":[["$","a",null,{"data-card":"","href":"#think-和-no_think-模式演示","className":"peer","children":[["$","code",null,{"children":"/think"}]," 和 ",["$","code",null,{"children":"/no_think"}]," 模式演示"]}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
58:["$","p",null,{"children":"Qwen3 Instruct 模型内置了思考模式切换功能，这是后训练赋予模型的核心能力之一。"}]
59:["$","$L6c",null,{"items":["思考模式 /think","非思考模式 /no_think"],"children":[["$","$L6d",null,{"value":"思考模式 /think","children":[["$","p",null,{"children":["在思考模式下，模型会先在 ",["$","code",null,{"children":"<think>"}]," 标签内展开内部推理，然后给出最终回复："]}],["$","$L67",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L68",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{"children":"用户：/think"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      解方程 3x + 7 = 22"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"助手：<think>"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"我需要解方程 3x + 7 = 22。"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"首先，将 7 从等式两边减去："}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"3x + 7 - 7 = 22 - 7"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"3x = 15"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"然后，将两边除以 3："}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"x = 15 / 3"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"x = 5"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"让我验证一下：3 × 5 + 7 = 15 + 7 = 22 ✓"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"</think>"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"解方程 3x + 7 = 22："}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"将常数项移到右边：3x = 22 - 7 = 15"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"两边除以 3：**x = 5**"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"验证：3 × 5 + 7 = 22 ✓"}]}]]}]}]}],["$","p",null,{"children":"思考模式适合需要深度推理的任务：数学题、编程、逻辑分析等。"}]]}],["$","$L6d",null,{"value":"非思考模式 /no_think","children":[["$","p",null,{"children":"在非思考模式下，模型跳过内部推理过程，直接给出简洁回复："}],["$","$L67",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L68",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{"children":"用户：/no_think"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      解方程 3x + 7 = 22"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"助手：<think>"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"</think>"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"解方程 3x + 7 = 22："}]}],"\n","$L6e","\n","$L6f"]}]}]}],"$L70"]}]]}]
5a:["$","div",null,{"ref":"$undefined","className":"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md","style":{"--callout-color":"var(--color-fd-warning, var(--color-fd-muted))"},"children":[["$","div",null,{"role":"none","className":"w-0.5 bg-(--callout-color)/50 rounded-sm"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card","children":[[["$","path","wmoenq",{"d":"m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3"}],["$","path","juzpu7",{"d":"M12 9v4"}],["$","path","p32p05",{"d":"M12 17h.01"}]],"$undefined"]}],["$","div",null,{"className":"flex flex-col gap-2 min-w-0 flex-1","children":["$undefined",["$","div",null,{"className":"text-fd-muted-foreground prose-no-margin empty:hidden","children":["$","p",null,{"children":["只有经过完整后训练流程的 ",["$","strong",null,{"children":"Instruct"}]," 版本才支持 ",["$","code",null,{"children":"/think"}]," 和 ",["$","code",null,{"children":"/no_think"}]," 模式切换。基座模型（Base）不具备这一能力——这正是后训练的价值所在。"]}]}]]}]]}]
5b:["$","hr",null,{}]
5c:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"本节小结","children":[["$","a",null,{"data-card":"","href":"#本节小结","className":"peer","children":"本节小结"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-label":"Link to section","children":[[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]],"$undefined"]}]]}]
5d:["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"概念"}],["$","th",null,{"children":"说明"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"预训练"}],["$","td",null,{"children":"万亿级 token 上的语言建模，产出基座模型"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"后训练"}],["$","td",null,{"children":"SFT + 偏好对齐 + 推理 RL，将基座模型转化为实用助手"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"SFT"}],["$","td",null,{"children":"教模型\"怎么说话\""}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"DPO/RLHF"}],["$","td",null,{"children":"教模型\"怎么选择\""}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"GRPO/RLVR"}],["$","td",null,{"children":"教模型\"怎么思考\""}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Tülu 3"}],["$","td",null,{"children":"开源后训练黄金标准：SFT → DPO → RLVR"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Qwen3"}],["$","td",null,{"children":"四阶段后训练：冷启动 SFT → 推理 RL → 模式融合 → 通用 RL"}]]}]]}]]}]}]
5e:["$","div",null,{"className":"flex flex-row flex-wrap items-center justify-between gap-4 empty:hidden","children":["$undefined","$undefined"]}]
5f:["$","$L71",null,{"items":"$undefined"}]
60:["$","$L72",null,{"children":["$undefined",["$","h3",null,{"className":"inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide size-4","children":[[["$","path","olowqp",{"d":"M15 18H3"}],["$","path","16j9eg",{"d":"M17 6H3"}],["$","path","2avoz0",{"d":"M21 12H3"}]],"$undefined"]}],["$","$L73",null,{"label":"toc"}]]}],["$","$L2c",null,{"children":["$","$L2d",null,{}]}],"$undefined"]}]
61:["$","span",null,{"className":"sizing reset-size6 size3 mtight","children":["$","span",null,{"className":"mord mathnormal mtight","children":"t"}]}]
62:["$","span",null,{"className":"vlist-s","children":"​"}]
63:["$","span",null,{"className":"vlist-r","children":["$","span",null,{"className":"vlist","style":{"height":"0.15em"},"children":["$","span",null,{}]}]}]
64:["$","span",null,{"className":"mord","children":"∣"}]
65:["$","span",null,{"className":"mord","children":[["$","span",null,{"className":"mord mathnormal","children":"x"}],["$","span",null,{"className":"msupsub","children":["$","span",null,{"className":"vlist-t vlist-t2","children":[["$","span",null,{"className":"vlist-r","children":[["$","span",null,{"className":"vlist","style":{"height":"0.2806em"},"children":["$","span",null,{"style":{"top":"-2.55em","marginLeft":"0em","marginRight":"0.05em"},"children":[["$","span",null,{"className":"pstrut","style":{"height":"2.7em"}}],["$","span",null,{"className":"sizing reset-size6 size3 mtight","children":["$","span",null,{"className":"mord mtight","children":[["$","span",null,{"className":"mrel mtight","children":"<"}],["$","span",null,{"className":"mord mathnormal mtight","children":"t"}]]}]}]]}]}],["$","span",null,{"className":"vlist-s","children":"​"}]]}],["$","span",null,{"className":"vlist-r","children":["$","span",null,{"className":"vlist","style":{"height":"0.1774em"},"children":["$","span",null,{}]}]}]]}]}]]}]
66:["$","span",null,{"className":"mclose","children":")"}]
69:["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}]
6a:["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]
6b:["$","p",null,{"children":"使用通用奖励信号（包括人类偏好和规则奖励）进行最终的强化学习，全面提升模型在各项能力上的表现，包括指令跟随、安全性、多语言等。"}]
6e:["$","span",null,{"className":"line","children":["$","span",null,{"children":"- 3x = 15"}]}]
6f:["$","span",null,{"className":"line","children":["$","span",null,{"children":"- **x = 5**"}]}]
70:["$","p",null,{"children":"非思考模式适合简单问答、创意写作等不需要深度推理的场景，响应更快。"}]
24:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
20:null
22:{"metadata":[["$","title","0",{"children":"1.1 后训练的定义与基本流程 | LLM 后训练课程"}],["$","meta","1",{"name":"description","content":"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践"}]],"error":null,"digest":"$undefined"}
27:"$22:metadata"
