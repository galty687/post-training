<!DOCTYPE html><!--pUSygr_0A8sEiSKFR56oq--><html lang="zh-CN" class="__variable_51740a __variable_3c557b"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/bb3ef058b751a6ad-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/edef1a271f97a8ec-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/185b0b411056c01b.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/62a6e77bcc5afb05.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/4cd23781d18a52d3.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-a61f7f8836a0480d.js"/><script src="/_next/static/chunks/6ee9f5d1-587662d01a07af8c.js" async=""></script><script src="/_next/static/chunks/4977-b2b53feb1c871da7.js" async=""></script><script src="/_next/static/chunks/main-app-9a763735f42e0f15.js" async=""></script><script src="/_next/static/chunks/1716-ed56095c0e3eb43d.js" async=""></script><script src="/_next/static/chunks/6098-1ad6a5cc0dfa14ba.js" async=""></script><script src="/_next/static/chunks/app/layout-9d0d0c8d6a45b02d.js" async=""></script><script src="/_next/static/chunks/4285-64b9e8f08c1e911d.js" async=""></script><script src="/_next/static/chunks/1698-20472d0927059867.js" async=""></script><script src="/_next/static/chunks/7997-9f155fcb121a084c.js" async=""></script><script src="/_next/static/chunks/795-ed3635716c096e23.js" async=""></script><script src="/_next/static/chunks/app/docs/layout-bc08591310048441.js" async=""></script><script src="/_next/static/chunks/942c9eea-01405fae79cb4292.js" async=""></script><script src="/_next/static/chunks/8697-8ff18c4921047cfe.js" async=""></script><script src="/_next/static/chunks/6249-ace54a767b378723.js" async=""></script><script src="/_next/static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-6PZFJCKFSJ" as="script"/><meta name="next-size-adjust" content=""/><title>1.1 后训练的定义与基本流程 | LLM 后训练课程</title><meta name="description" content="理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="flex min-h-screen flex-col"><div hidden=""><!--$--><!--/$--></div><script>((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","system",null,["light","dark"],null,true,true)</script><div class="bg-fd-secondary/50 p-3 empty:hidden"></div><header id="nd-subnav" class="fixed top-(--fd-banner-height) left-0 right-(--removed-body-scroll-bar-size,0) z-30 flex items-center ps-4 pe-2.5 border-b transition-colors backdrop-blur-sm bg-fd-background/80 h-(--fd-nav-height) on-root:[--fd-nav-height:56px] md:on-root:[--fd-nav-height:0px] md:hidden"><a class="inline-flex items-center gap-2.5 font-semibold" href="/">LLM 后训练实践</a><div class="flex-1"></div><button type="button" class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-4.5 p-2" data-search="" aria-label="Open Search"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button><button class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-4.5 p-2" aria-label="Open Sidebar"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg></button></header><main id="nd-docs-layout" class="flex flex-1 flex-col pt-(--fd-nav-height) transition-[padding] fd-default-layout mx-(--fd-layout-offset) md:[&amp;_#nd-page_article]:pt-12 xl:[--fd-toc-width:286px] xl:[&amp;_#nd-page_article]:px-8 md:[--fd-sidebar-width:268px] lg:[--fd-sidebar-width:286px]" style="padding-inline-start:var(--fd-sidebar-width)"><div class="fixed flex shadow-lg transition-opacity rounded-xl p-0.5 border bg-fd-muted text-fd-muted-foreground z-10 max-md:hidden xl:start-4 max-xl:end-4 pointer-events-none opacity-0" style="top:calc(var(--fd-banner-height) + var(--fd-tocnav-height) + var(--spacing) * 4)"><button type="button" aria-label="Collapse Sidebar" data-collapsed="false" class="inline-flex items-center justify-center text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-4.5 rounded-lg"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg></button><button type="button" class="inline-flex items-center justify-center text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-4.5 rounded-lg" data-search="" aria-label="Open Search"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button></div><aside id="nd-sidebar" data-collapsed="false" class="fixed left-0 rtl:left-auto rtl:right-(--removed-body-scroll-bar-size,0) flex flex-col items-end top-(--fd-sidebar-top) bottom-(--fd-sidebar-margin) z-20 bg-fd-card text-sm border-e transition-[top,opacity,translate,width] duration-200 max-md:hidden *:w-(--fd-sidebar-width)" style="--fd-sidebar-offset:calc(16px - 100%);--fd-sidebar-margin:0px;--fd-sidebar-top:calc(var(--fd-banner-height) + var(--fd-nav-height) + var(--fd-sidebar-margin));width:calc(var(--spacing) + var(--fd-sidebar-width) + var(--fd-layout-offset))"><div class="flex flex-col gap-3 p-4 pb-2"><div class="flex"><a class="inline-flex text-[15px] items-center gap-2.5 font-medium me-auto" href="/">LLM 后训练实践</a><button type="button" aria-label="Collapse Sidebar" data-collapsed="false" class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-4.5 mb-auto text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg></button></div><button type="button" data-search-full="" class="inline-flex items-center gap-2 rounded-lg border bg-fd-secondary/50 p-1.5 ps-2 text-sm text-fd-muted-foreground transition-colors hover:bg-fd-accent hover:text-fd-accent-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-4"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg>Search<div class="ms-auto inline-flex gap-0.5"><kbd class="rounded-md border bg-fd-background px-1.5">⌘</kbd><kbd class="rounded-md border bg-fd-background px-1.5">K</kbd></div></button></div><div dir="ltr" class="overflow-hidden h-full" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" class="size-full rounded-[inherit] p-4 overscroll-contain" style="overflow-x:hidden;overflow-y:hidden;--sidebar-item-offset:calc(var(--spacing) * 2);mask-image:linear-gradient(to bottom, transparent, white 12px, white calc(100% - 12px), transparent)"><div style="min-width:100%;display:table"><a class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none mb-4" data-active="false" href="/docs/">课程内容</a><p class="inline-flex items-center gap-2 mb-1.5 px-2 ps-(--sidebar-item-offset) empty:mb-0 [&amp;_svg]:size-4 [&amp;_svg]:shrink-0">课程内容</p><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/">课程总览</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/grading/">评分标准</a><p class="inline-flex items-center gap-2 mb-1.5 px-2 ps-(--sidebar-item-offset) empty:mb-0 [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 mt-6">授课</p><div data-state="open"><button type="button" aria-controls="radix-_R_5kqd5ulb_" aria-expanded="true" data-state="open" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第1课：后训练概述与SFT基础<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="open" id="radix-_R_5kqd5ulb_" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/lecture-1/">第1课：后训练概述与监督微调基础</a><a data-active="true" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-fd-primary/10 text-fd-primary" href="/docs/lecture-1/post-training-overview/">1.1 后训练的定义与基本流程</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/lecture-1/sft-core-concepts/">1.2 监督微调核心概念</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/lecture-1/parameter-efficient-ft/">1.3 参数高效微调</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/lecture-1/evaluation-methods/">1.4 模型评估方法</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/lecture-1/papers/">第1课 推荐论文</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/lecture-1/lab/">实验1：微调 Qwen3-1.7B 为指令跟随助手</a></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_6kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第2课：SFT进阶<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_6kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_7kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第3课：偏好对齐DPO<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_7kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_8kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第4课：RLHF与GRPO<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_8kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_9kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第5课：压缩部署与扩展<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_9kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_akqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第6课：项目报告与总结<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_akqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><p class="inline-flex items-center gap-2 mb-1.5 px-2 ps-(--sidebar-item-offset) empty:mb-0 [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 mt-6">资源</p><div data-state="closed"><button type="button" aria-controls="radix-_R_ckqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">课程资源<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_ckqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div></div></div></div><div class="flex flex-col border-t p-4 pt-2"><div class="flex text-fd-muted-foreground items-center empty:hidden"><button class="inline-flex items-center rounded-full border ms-auto p-0" aria-label="Toggle Theme" data-theme-toggle=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg></button></div></div></aside><div id="nd-page" class="flex flex-1 w-full mx-auto max-w-(--fd-page-width) pt-(--fd-tocnav-height) pe-(--fd-toc-width)"><header id="nd-tocnav" class="fixed pr-(--removed-body-scroll-bar-size,0) z-10 border-b backdrop-blur-sm transition-colors xl:hidden max-xl:on-root:[--fd-tocnav-height:40px] bg-fd-background/80" style="top:calc(var(--fd-banner-height) + var(--fd-nav-height));inset-inline-start:calc(var(--fd-sidebar-width) + var(--fd-layout-offset));inset-inline-end:0" data-state="closed"><button type="button" aria-controls="radix-_R_anpft5ulb_" aria-expanded="false" data-state="closed" class="flex w-full h-(--fd-tocnav-height) items-center text-sm text-fd-muted-foreground gap-2.5 px-4 py-2.5 text-start focus-visible:outline-none [&amp;_svg]:size-4 md:px-6"><svg role="progressbar" viewBox="0 0 24 24" aria-valuenow="0" aria-valuemin="0" aria-valuemax="1" class="shrink-0"><circle cx="12" cy="12" r="11" fill="none" stroke-width="2" class="stroke-current/25"></circle><circle cx="12" cy="12" r="11" fill="none" stroke-width="2" stroke="currentColor" stroke-dasharray="69.11503837897544" stroke-dashoffset="69.11503837897544" stroke-linecap="round" transform="rotate(-90 12 12)" class="transition-all"></circle></svg><span class="grid flex-1 *:my-auto *:row-start-1 *:col-start-1"><span class="truncate transition-all">1.1 后训练的定义与基本流程</span><span class="truncate transition-all opacity-0 translate-y-full pointer-events-none"></span></span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide shrink-0 transition-transform mx-0.5"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_anpft5ulb_" hidden="" data-toc-popover="" class="overflow-hidden flex flex-col px-4 max-h-[50vh] md:px-6"></div></header><article class="flex min-w-0 w-full flex-col gap-4 pt-8 px-4 md:px-6 md:mx-auto"><div class="flex items-center gap-1.5 text-sm text-fd-muted-foreground"><span class="truncate text-fd-primary font-medium">第1课：后训练概述与SFT基础</span></div><h1 class="text-[1.75em] font-semibold">1.1 后训练的定义与基本流程</h1><p class="mb-8 text-lg text-fd-muted-foreground">理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践</p><div class="prose flex-1"><h2 class="flex scroll-m-28 flex-row items-center gap-2" id="llm-开发的三阶段流程"><a data-card="" href="#llm-开发的三阶段流程" class="peer">LLM 开发的三阶段流程</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>现代大语言模型（LLM）的开发可以清晰地划分为三个阶段：</p>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段一预训练pre-training"><a data-card="" href="#阶段一预训练pre-training" class="peer">阶段一：预训练（Pre-training）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>预训练是 LLM 的基础。在这一阶段，模型在<strong>万亿级 token</strong> 的大规模语料上进行下一个 token 预测（next-token prediction），学习语言知识和世界知识。</p>
<ul>
<li><strong>计算量</strong>：极其巨大，通常需要数千张 GPU 训练数周到数月</li>
<li><strong>训练目标</strong>：标准的语言建模目标，最小化负对数似然</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mtext>pretrain</mtext></msub><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><msub><mi>P</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\text{pretrain}} = -\sum_{t=1}^{T} \log P_\theta(x_t | x_{&lt;t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">pretrain</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
<ul>
<li><strong>产出</strong>：一个&quot;博学但不听话&quot;的<strong>基座模型</strong>（base model）——它拥有丰富的知识，但不会遵循人类指令、不懂对话格式、可能生成有害内容</li>
</ul>
<div class="flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md" style="--callout-color:var(--color-fd-info, var(--color-fd-muted))"><div role="none" class="w-0.5 bg-(--callout-color)/50 rounded-sm"></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div class="flex flex-col gap-2 min-w-0 flex-1"><div class="text-fd-muted-foreground prose-no-margin empty:hidden"><p>以 Qwen3 为例：Qwen3 系列在约 36 万亿 token 上进行了预训练，涵盖 119 种语言和编程语言。预训练分为三个阶段（S1: 30T tokens, S2: 5T tokens, S3: 退火阶段），逐步提升数据质量。</p></div></div></div>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段二后训练post-training"><a data-card="" href="#阶段二后训练post-training" class="peer">阶段二：后训练（Post-training）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>后训练是将基座模型转化为实用助手的关键阶段。通过 SFT、偏好对齐、强化学习等手段，赋予模型指令跟随、安全回复、推理思考等能力。</p>
<ul>
<li><strong>计算量</strong>：仅占预训练的约 <strong>5%</strong>（以 DeepSeek-R1 为例），但决定了模型的实际可用性</li>
<li><strong>核心目标</strong>：让模型学会&quot;怎么说话&quot;、&quot;怎么选择&quot;、&quot;怎么思考&quot;</li>
<li><strong>产出</strong>：一个能遵循指令、安全有用的<strong>对齐模型</strong>（aligned model / instruct model）</li>
</ul>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段三推理阶段inference"><a data-card="" href="#阶段三推理阶段inference" class="peer">阶段三：推理阶段（Inference）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>模型部署后的优化和扩展阶段：</p>
<ul>
<li><strong>部署优化</strong>：量化（INT8/INT4）、蒸馏、剪枝等方法减少模型体积和推理成本</li>
<li><strong>推理时计算扩展</strong>：思维链（Chain-of-Thought）、best-of-N 采样、树搜索等方法在推理时分配更多计算资源</li>
</ul>
<div style="text-align:center;margin:24px 0;padding:20px;background:#FEFCFB;border:1px solid #E8E0DD;border-radius:10px;overflow-x:auto"></div>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="后训练的核心方法全景"><a data-card="" href="#后训练的核心方法全景" class="peer">后训练的核心方法全景</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>后训练涵盖多种方法，按功能可分为四大类：</p>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="1-监督微调supervised-fine-tuning-sft"><a data-card="" href="#1-监督微调supervised-fine-tuning-sft" class="peer">1. 监督微调（Supervised Fine-Tuning, SFT）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p><strong>教模型&quot;怎么说话&quot;</strong>——学会遵循指令、按格式回复。</p>
<p>SFT 使用高质量的 <code>(指令, 回复)</code> 对来训练模型。模型学习的是：给定一个指令，如何生成符合期望的回复。这是后训练的<strong>第一步</strong>，也是其他所有方法的基础。</p>
<ul>
<li>输入：<code>&quot;用三句话介绍量子计算&quot;</code></li>
<li>期望输出：<code>&quot;量子计算利用量子力学原理进行信息处理...&quot;</code></li>
</ul>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="2-偏好对齐preference-alignment-dporlhf"><a data-card="" href="#2-偏好对齐preference-alignment-dporlhf" class="peer">2. 偏好对齐（Preference Alignment: DPO/RLHF）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p><strong>教模型&quot;怎么选择&quot;</strong>——在多个可能的回复中选择更好的。</p>
<p>SFT 后的模型可能生成多种回复，但并非所有回复都同样好。偏好对齐通过<strong>人类偏好数据</strong>（&quot;回复 A 优于回复 B&quot;）来教模型区分好坏：</p>
<ul>
<li><strong>RLHF</strong>（Reinforcement Learning from Human Feedback）：训练奖励模型 + PPO 优化</li>
<li><strong>DPO</strong>（Direct Preference Optimization）：直接在偏好对上训练，无需奖励模型</li>
</ul>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="3-推理强化学习reasoning-rl-grporlvr"><a data-card="" href="#3-推理强化学习reasoning-rl-grporlvr" class="peer">3. 推理强化学习（Reasoning RL: GRPO/RLVR）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p><strong>教模型&quot;怎么思考&quot;</strong>——发展逐步推理和自我验证能力。</p>
<p>这是 2024-2025 年最激动人心的进展。通过<strong>可验证奖励</strong>（如数学答案的正确性），模型在纯强化学习中自发涌现出推理能力：</p>
<ul>
<li><strong>GRPO</strong>（Group Relative Policy Optimization）：DeepSeek 提出的高效 RL 算法</li>
<li><strong>RLVR</strong>（RL with Verifiable Rewards）：使用确定性奖励函数代替人类标注</li>
</ul>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="4-专项适配"><a data-card="" href="#4-专项适配" class="peer">4. 专项适配</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>根据应用场景扩展模型能力：</p>
<ul>
<li><strong>工具使用</strong>：学会调用 API、函数调用（Function Calling）</li>
<li><strong>多模态理解</strong>：视觉-语言对齐（VLM）</li>
<li><strong>领域知识注入</strong>：医疗、法律、金融等垂直领域微调</li>
</ul>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="tülu-3开源后训练的黄金标准"><a data-card="" href="#tülu-3开源后训练的黄金标准" class="peer">Tülu 3：开源后训练的黄金标准</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p><a href="https://arxiv.org/abs/2411.15124" rel="noreferrer noopener" target="_blank">Tülu 3</a>（Lambert 等，2024）是目前最完整的开源后训练方案，其流程为本课程提供了核心参考框架：</p>
<div class="fd-steps"><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="sft-阶段"><a data-card="" href="#sft-阶段" class="peer">SFT 阶段</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>在精心混合的多源指令数据上进行监督微调。Tülu 3 使用了来自多个来源的数据，并通过系统性的数据混合实验确定最优配比。</p></div><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="dpo-阶段"><a data-card="" href="#dpo-阶段" class="peer">DPO 阶段</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>使用偏好数据进行 DPO 对齐，提升模型的回复质量和安全性。关键发现：<strong>在策略</strong>（on-policy）生成的偏好数据效果优于离线数据。</p></div><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="rlvr-阶段"><a data-card="" href="#rlvr-阶段" class="peer">RLVR 阶段</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>使用可验证奖励进行强化学习，专门提升数学推理和指令跟随能力。这一步是 Tülu 3 在 GSM8K 等推理基准上取得突破的关键。</p></div></div>
<p>Tülu 3 的核心贡献在于其<strong>系统性的消融实验</strong>：每一步的设计选择（数据配比、超参数、方法选型）都有实验支撑，为开源社区提供了可复现的最佳实践。</p>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="qwen3-的四阶段后训练流程"><a data-card="" href="#qwen3-的四阶段后训练流程" class="peer">Qwen3 的四阶段后训练流程</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Qwen3 的后训练流程是本课程技术体系的<strong>最佳案例</strong>。根据 Qwen3 技术报告（arXiv:2505.09388），其后训练分为四个精心设计的阶段：</p>
<div class="fd-steps"><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段-1长思维链冷启动-sftlong-cot-cold-start"><a data-card="" href="#阶段-1长思维链冷启动-sftlong-cot-cold-start" class="peer">阶段 1：长思维链冷启动 SFT（Long-CoT Cold Start）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>使用精心构造的<strong>长思维链数据</strong>进行 SFT，为模型注入基本的推理模式。这些数据包含详细的逐步推理过程，教会模型如何展开深度思考。</p><ul>
<li>数据来源：通过强模型生成、人工筛选的高质量推理数据</li>
<li>目标：让模型掌握 <code>&lt;think&gt;...&lt;/think&gt;</code> 格式的思维链输出</li>
</ul></div><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段-2推理-rlreasoning-reinforcement-learning"><a data-card="" href="#阶段-2推理-rlreasoning-reinforcement-learning" class="peer">阶段 2：推理 RL（Reasoning Reinforcement Learning）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>在数学、代码等可验证任务上进行大规模 <strong>GRPO</strong> 训练，强化模型的推理能力。</p><ul>
<li>奖励信号：答案正确性（可验证奖励）</li>
<li>关键效果：模型学会了更长、更深入的推理链，自发涌现出自我验证和回溯能力</li>
</ul></div><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段-3思考模式融合thinking-mode-fusion"><a data-card="" href="#阶段-3思考模式融合thinking-mode-fusion" class="peer">阶段 3：思考模式融合（Thinking Mode Fusion）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>将推理 RL 阶段获得的深度思考能力<strong>融合回统一模型</strong>，使模型同时具备：</p><ul>
<li><strong>思考模式</strong>（Thinking Mode）：生成详细的内部推理过程</li>
<li><strong>非思考模式</strong>（Non-Thinking Mode）：直接给出简洁回复</li>
</ul><p>这一阶段本质上是一种<strong>蒸馏</strong>：将 RL 训练的推理专家能力蒸馏到一个统一的模型中。</p></div><div class="fd-step"><h3 class="flex scroll-m-28 flex-row items-center gap-2" id="阶段-4通用-rlgeneral-reinforcement-learning"><a data-card="" href="#阶段-4通用-rlgeneral-reinforcement-learning" class="peer">阶段 4：通用 RL（General Reinforcement Learning）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3><p>使用通用奖励信号（包括人类偏好和规则奖励）进行最终的强化学习，全面提升模型在各项能力上的表现，包括指令跟随、安全性、多语言等。</p></div></div>
<div class="flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md" style="--callout-color:var(--color-fd-info, var(--color-fd-muted))"><div role="none" class="w-0.5 bg-(--callout-color)/50 rounded-sm"></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div class="flex flex-col gap-2 min-w-0 flex-1"><div class="text-fd-muted-foreground prose-no-margin empty:hidden"><p>Qwen3 的四阶段后训练流程正好对应了本课程的技术体系：阶段 1 对应第 1-2 课（SFT），阶段 2 对应第 4 课（GRPO），阶段 3-4 对应第 3 课（偏好对齐）和第 5 课（部署优化）。</p></div></div></div>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="think-和-no_think-模式演示"><a data-card="" href="#think-和-no_think-模式演示" class="peer"><code>/think</code> 和 <code>/no_think</code> 模式演示</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Qwen3 Instruct 模型内置了思考模式切换功能，这是后训练赋予模型的核心能力之一。</p>
<div dir="ltr" data-orientation="horizontal" class="flex flex-col overflow-hidden rounded-xl border bg-fd-secondary my-4"><div role="tablist" aria-orientation="horizontal" class="flex gap-3.5 text-fd-secondary-foreground overflow-x-auto px-4 not-prose" tabindex="-1" data-orientation="horizontal" style="outline:none"><button type="button" role="tab" aria-selected="true" aria-controls="radix-_R_2tqinpft5ulb_-content-思考模式-/think" data-state="active" id="radix-_R_2tqinpft5ulb_-trigger-思考模式-/think" class="inline-flex items-center gap-2 whitespace-nowrap text-fd-muted-foreground border-b border-transparent py-2 text-sm font-medium transition-colors [&amp;_svg]:size-4 hover:text-fd-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=active]:border-fd-primary data-[state=active]:text-fd-primary" tabindex="-1" data-orientation="horizontal" data-radix-collection-item="">思考模式 /think</button><button type="button" role="tab" aria-selected="false" aria-controls="radix-_R_2tqinpft5ulb_-content-非思考模式-/no_think" data-state="inactive" id="radix-_R_2tqinpft5ulb_-trigger-非思考模式-/no_think" class="inline-flex items-center gap-2 whitespace-nowrap text-fd-muted-foreground border-b border-transparent py-2 text-sm font-medium transition-colors [&amp;_svg]:size-4 hover:text-fd-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=active]:border-fd-primary data-[state=active]:text-fd-primary" tabindex="-1" data-orientation="horizontal" data-radix-collection-item="">非思考模式 /no_think</button></div><div data-state="active" data-orientation="horizontal" role="tabpanel" aria-labelledby="radix-_R_2tqinpft5ulb_-trigger-思考模式-/think" id="radix-_R_2tqinpft5ulb_-content-思考模式-/think" tabindex="0" class="p-4 text-[15px] bg-fd-background rounded-xl outline-none prose-no-margin data-[state=inactive]:hidden [&amp;&gt;figure:only-child]:-m-4 [&amp;&gt;figure:only-child]:border-none" style="animation-duration:0s"><p>在思考模式下，模型会先在 <code>&lt;think&gt;</code> 标签内展开内部推理，然后给出最终回复：</p><figure dir="ltr" class="my-4 bg-fd-card rounded-xl shiki relative border shadow-sm outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-2 right-2 z-2 backdrop-blur-lg rounded-lg text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring p-1 [&amp;_svg]:size-4 hover:text-fd-accent-foreground data-[checked]:text-fd-accent-foreground" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="8" height="4" x="8" y="2" rx="1" ry="1"></rect><path d="M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2"></path></svg></button></div><div class="text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>用户：/think</span></span>
<span class="line"><span>      解方程 3x + 7 = 22</span></span>
<span class="line"><span></span></span>
<span class="line"><span>助手：&lt;think&gt;</span></span>
<span class="line"><span>我需要解方程 3x + 7 = 22。</span></span>
<span class="line"><span>首先，将 7 从等式两边减去：</span></span>
<span class="line"><span>3x + 7 - 7 = 22 - 7</span></span>
<span class="line"><span>3x = 15</span></span>
<span class="line"><span>然后，将两边除以 3：</span></span>
<span class="line"><span>x = 15 / 3</span></span>
<span class="line"><span>x = 5</span></span>
<span class="line"><span>让我验证一下：3 × 5 + 7 = 15 + 7 = 22 ✓</span></span>
<span class="line"><span>&lt;/think&gt;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>解方程 3x + 7 = 22：</span></span>
<span class="line"><span></span></span>
<span class="line"><span>将常数项移到右边：3x = 22 - 7 = 15</span></span>
<span class="line"><span></span></span>
<span class="line"><span>两边除以 3：**x = 5**</span></span>
<span class="line"><span></span></span>
<span class="line"><span>验证：3 × 5 + 7 = 22 ✓</span></span></code></pre></div></figure><p>思考模式适合需要深度推理的任务：数学题、编程、逻辑分析等。</p></div><div data-state="inactive" data-orientation="horizontal" role="tabpanel" aria-labelledby="radix-_R_2tqinpft5ulb_-trigger-非思考模式-/no_think" id="radix-_R_2tqinpft5ulb_-content-非思考模式-/no_think" tabindex="0" class="p-4 text-[15px] bg-fd-background rounded-xl outline-none prose-no-margin data-[state=inactive]:hidden [&amp;&gt;figure:only-child]:-m-4 [&amp;&gt;figure:only-child]:border-none"><p>在非思考模式下，模型跳过内部推理过程，直接给出简洁回复：</p><figure dir="ltr" class="my-4 bg-fd-card rounded-xl shiki relative border shadow-sm outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-2 right-2 z-2 backdrop-blur-lg rounded-lg text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring p-1 [&amp;_svg]:size-4 hover:text-fd-accent-foreground data-[checked]:text-fd-accent-foreground" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="8" height="4" x="8" y="2" rx="1" ry="1"></rect><path d="M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2"></path></svg></button></div><div class="text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>用户：/no_think</span></span>
<span class="line"><span>      解方程 3x + 7 = 22</span></span>
<span class="line"><span></span></span>
<span class="line"><span>助手：&lt;think&gt;</span></span>
<span class="line"><span>&lt;/think&gt;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>解方程 3x + 7 = 22：</span></span>
<span class="line"><span>- 3x = 15</span></span>
<span class="line"><span>- **x = 5**</span></span></code></pre></div></figure><p>非思考模式适合简单问答、创意写作等不需要深度推理的场景，响应更快。</p></div></div>
<div class="flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md" style="--callout-color:var(--color-fd-warning, var(--color-fd-muted))"><div role="none" class="w-0.5 bg-(--callout-color)/50 rounded-sm"></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card"><path d="m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3"></path><path d="M12 9v4"></path><path d="M12 17h.01"></path></svg><div class="flex flex-col gap-2 min-w-0 flex-1"><div class="text-fd-muted-foreground prose-no-margin empty:hidden"><p>只有经过完整后训练流程的 <strong>Instruct</strong> 版本才支持 <code>/think</code> 和 <code>/no_think</code> 模式切换。基座模型（Base）不具备这一能力——这正是后训练的价值所在。</p></div></div></div>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="本节小结"><a data-card="" href="#本节小结" class="peer">本节小结</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>概念</th><th>说明</th></tr></thead><tbody><tr><td>预训练</td><td>万亿级 token 上的语言建模，产出基座模型</td></tr><tr><td>后训练</td><td>SFT + 偏好对齐 + 推理 RL，将基座模型转化为实用助手</td></tr><tr><td>SFT</td><td>教模型&quot;怎么说话&quot;</td></tr><tr><td>DPO/RLHF</td><td>教模型&quot;怎么选择&quot;</td></tr><tr><td>GRPO/RLVR</td><td>教模型&quot;怎么思考&quot;</td></tr><tr><td>Tülu 3</td><td>开源后训练黄金标准：SFT → DPO → RLVR</td></tr><tr><td>Qwen3</td><td>四阶段后训练：冷启动 SFT → 推理 RL → 模式融合 → 通用 RL</td></tr></tbody></table></div></div><div class="flex flex-row flex-wrap items-center justify-between gap-4 empty:hidden"></div><div class="@container grid gap-4 pb-6 grid-cols-2"><a class="flex flex-col gap-2 rounded-lg border p-4 text-sm transition-colors hover:bg-fd-accent/80 hover:text-fd-accent-foreground @max-lg:col-span-full" href="/docs/lecture-1/"><div class="inline-flex items-center gap-1.5 font-medium"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide -mx-1 size-4 shrink-0 rtl:rotate-180"><path d="m15 18-6-6 6-6"></path></svg><p>第1课：后训练概述与监督微调基础</p></div><p class="text-fd-muted-foreground truncate">理解后训练在 LLM 开发流程中的位置和核心方法体系，掌握 SFT 训练循环，配置 LoRA/QLoRA 进行参数高效训练</p></a><a class="flex flex-col gap-2 rounded-lg border p-4 text-sm transition-colors hover:bg-fd-accent/80 hover:text-fd-accent-foreground @max-lg:col-span-full text-end" href="/docs/lecture-1/sft-core-concepts/"><div class="inline-flex items-center gap-1.5 font-medium flex-row-reverse"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide -mx-1 size-4 shrink-0 rtl:rotate-180"><path d="m9 18 6-6-6-6"></path></svg><p>1.2 监督微调核心概念</p></div><p class="text-fd-muted-foreground truncate">掌握 ChatML 和 Llama 聊天模板格式，理解掩码损失（Masked Loss）的原理，了解数据质量的重要性</p></a></div></article><div id="nd-toc" class="fixed bottom-0 pt-12 pb-2 pr-(--removed-body-scroll-bar-size,0) max-xl:hidden" style="top:calc(var(--fd-banner-height) + var(--fd-nav-height));inset-inline-end:max(var(--fd-layout-offset), calc(50vw - var(--fd-sidebar-width)/2 - var(--fd-page-width)/2))"><div class="flex h-full w-(--fd-toc-width) max-w-full flex-col pe-4"><h3 class="inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-4"><path d="M15 18H3"></path><path d="M17 6H3"></path><path d="M21 12H3"></path></svg>On this page</h3><div class="relative min-h-0 text-sm ms-px overflow-auto [scrollbar-width:none] [mask-image:linear-gradient(to_bottom,transparent,white_16px,white_calc(100%-16px),transparent)] py-3"><div role="none" class="absolute top-(--fd-top) h-(--fd-height) w-px bg-fd-primary transition-all"></div><div class="flex flex-col border-s border-fd-foreground/10"><a data-active="false" href="#llm-开发的三阶段流程" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">LLM 开发的三阶段流程</a><a data-active="false" href="#阶段一预训练pre-training" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段一：预训练（Pre-training）</a><a data-active="false" href="#阶段二后训练post-training" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段二：后训练（Post-training）</a><a data-active="false" href="#阶段三推理阶段inference" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段三：推理阶段（Inference）</a><a data-active="false" href="#后训练的核心方法全景" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">后训练的核心方法全景</a><a data-active="false" href="#1-监督微调supervised-fine-tuning-sft" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">1. 监督微调（Supervised Fine-Tuning, SFT）</a><a data-active="false" href="#2-偏好对齐preference-alignment-dporlhf" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">2. 偏好对齐（Preference Alignment: DPO/RLHF）</a><a data-active="false" href="#3-推理强化学习reasoning-rl-grporlvr" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">3. 推理强化学习（Reasoning RL: GRPO/RLVR）</a><a data-active="false" href="#4-专项适配" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">4. 专项适配</a><a data-active="false" href="#tülu-3开源后训练的黄金标准" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">Tülu 3：开源后训练的黄金标准</a><a data-active="false" href="#sft-阶段" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">SFT 阶段</a><a data-active="false" href="#dpo-阶段" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">DPO 阶段</a><a data-active="false" href="#rlvr-阶段" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">RLVR 阶段</a><a data-active="false" href="#qwen3-的四阶段后训练流程" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">Qwen3 的四阶段后训练流程</a><a data-active="false" href="#阶段-1长思维链冷启动-sftlong-cot-cold-start" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段 1：长思维链冷启动 SFT（Long-CoT Cold Start）</a><a data-active="false" href="#阶段-2推理-rlreasoning-reinforcement-learning" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段 2：推理 RL（Reasoning Reinforcement Learning）</a><a data-active="false" href="#阶段-3思考模式融合thinking-mode-fusion" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段 3：思考模式融合（Thinking Mode Fusion）</a><a data-active="false" href="#阶段-4通用-rlgeneral-reinforcement-learning" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">阶段 4：通用 RL（General Reinforcement Learning）</a><a data-active="false" href="#think-和-no_think-模式演示" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3"><code>/think</code> 和 <code>/no_think</code> 模式演示</a><a data-active="false" href="#本节小结" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">本节小结</a></div></div></div></div></div><!--$--><!--/$--></main><script src="/_next/static/chunks/webpack-a61f7f8836a0480d.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[57921,[\"1716\",\"static/chunks/1716-ed56095c0e3eb43d.js\",\"6098\",\"static/chunks/6098-1ad6a5cc0dfa14ba.js\",\"7177\",\"static/chunks/app/layout-9d0d0c8d6a45b02d.js\"],\"\"]\n3:I[28295,[\"1716\",\"static/chunks/1716-ed56095c0e3eb43d.js\",\"6098\",\"static/chunks/6098-1ad6a5cc0dfa14ba.js\",\"7177\",\"static/chunks/app/layout-9d0d0c8d6a45b02d.js\"],\"RootProvider\"]\n4:I[1409,[],\"\"]\n5:I[1813,[],\"\"]\n6:I[58434,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"TreeContextProvider\"]\nb:I[10323,[],\"\"]\n:HL[\"/_next/static/media/bb3ef058b751a6ad-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/edef1a271f97a8ec-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/185b0b411056c01b.css\",\"style\"]\n:HL[\"/_next/static/css/62a6e77bcc5afb05.css\",\"style\"]\n:HL[\"/_next/static/css/4cd23781d18a52d3.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"pUSygr_0A8sEiSKFR56oq\",\"p\":\"\",\"c\":[\"\",\"docs\",\"lecture-1\",\"post-training-overview\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"docs\",{\"children\":[[\"slug\",\"lecture-1/post-training-overview\",\"oc\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/185b0b411056c01b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/62a6e77bcc5afb05.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4cd23781d18a52d3.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"className\":\"__variable_51740a __variable_3c557b\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"$L2\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-6PZFJCKFSJ\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$L2\",null,{\"id\":\"google-analytics\",\"strategy\":\"afterInteractive\",\"children\":\"\\n            window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-6PZFJCKFSJ');\\n          \"}]]}],[\"$\",\"body\",null,{\"className\":\"flex min-h-screen flex-col\",\"children\":[\"$\",\"$L3\",null,{\"search\":{\"options\":{\"type\":\"static\"}},\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]]}],{\"children\":[\"docs\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L6\",null,{\"tree\":{\"$id\":\"root\",\"name\":\"课程内容\",\"children\":[{\"$id\":\"#0\",\"type\":\"separator\",\"icon\":\"$undefined\",\"name\":\"课程内容\"},{\"$id\":\"index.mdx\",\"type\":\"page\",\"name\":\"课程总览\",\"description\":\"大语言模型后训练实践——北京大学软件与微电子学院研究生课程\",\"icon\":\"$undefined\",\"url\":\"/docs\",\"$ref\":{\"file\":\"index.mdx\"}},{\"$id\":\"grading.mdx\",\"type\":\"page\",\"name\":\"评分标准\",\"description\":\"课程考核方式、各项评分细则与评分标准详细说明\",\"icon\":\"$undefined\",\"url\":\"/docs/grading\",\"$ref\":{\"file\":\"grading.mdx\"}},{\"$id\":\"#3\",\"type\":\"separator\",\"icon\":\"$undefined\",\"name\":\"授课\"},{\"type\":\"folder\",\"name\":\"第1课：后训练概述与SFT基础\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-1/index.mdx\",\"type\":\"page\",\"name\":\"第1课：后训练概述与监督微调基础\",\"description\":\"理解后训练在 LLM 开发流程中的位置和核心方法体系，掌握 SFT 训练循环，配置 LoRA/QLoRA 进行参数高效训练\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1\",\"$ref\":{\"file\":\"lecture-1/index.mdx\"}},{\"$id\":\"lecture-1/post-training-overview.mdx\",\"type\":\"page\",\"name\":\"1.1 后训练的定义与基本流程\",\"description\":\"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/post-training-overview\",\"$ref\":{\"file\":\"lecture-1/post-training-overview.mdx\"}},{\"$id\":\"lecture-1/sft-core-concepts.mdx\",\"type\":\"page\",\"name\":\"1.2 监督微调核心概念\",\"description\":\"掌握 ChatML 和 Llama 聊天模板格式，理解掩码损失（Masked Loss）的原理，了解数据质量的重要性\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/sft-core-concepts\",\"$ref\":{\"file\":\"lecture-1/sft-core-concepts.mdx\"}},{\"$id\":\"lecture-1/parameter-efficient-ft.mdx\",\"type\":\"page\",\"name\":\"1.3 参数高效微调\",\"description\":\"掌握 LoRA 和 QLoRA 的原理与实践，理解参数高效微调的必要性和显存优化策略\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/parameter-efficient-ft\",\"$ref\":{\"file\":\"lecture-1/parameter-efficient-ft.mdx\"}},{\"$id\":\"lecture-1/evaluation-methods.mdx\",\"type\":\"page\",\"name\":\"1.4 模型评估方法\",\"description\":\"了解 LLM 后训练的主流评估方法：LLM-as-Judge、人类偏好排行榜、能力专项基准和安全评估\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/evaluation-methods\",\"$ref\":{\"file\":\"lecture-1/evaluation-methods.mdx\"}},{\"$id\":\"lecture-1/papers.mdx\",\"type\":\"page\",\"name\":\"第1课 推荐论文\",\"description\":\"第1课推荐阅读的 5 篇核心论文：Tülu 3、LoRA、QLoRA、LIMA、MAGPIE\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/papers\",\"$ref\":{\"file\":\"lecture-1/papers.mdx\"}},{\"$id\":\"lecture-1/lab.mdx\",\"type\":\"page\",\"name\":\"实验1：微调 Qwen3-1.7B 为指令跟随助手\",\"description\":\"使用 QLoRA 和 SFTTrainer 将 Qwen3-1.7B 基座模型微调为指令跟随助手的完整实验\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/lab\",\"$ref\":{\"file\":\"lecture-1/lab.mdx\"}}],\"$id\":\"lecture-1\",\"$ref\":{\"metaFile\":\"lecture-1/meta.json\"}},{\"type\":\"folder\",\"name\":\"第2课：SFT进阶\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-2/index.mdx\",\"type\":\"page\",\"name\":\"第2课：SFT 进阶——数据工程与指令微调深入\",\"description\":\"掌握指令数据集的构建与质量控制方法，理解数据混合策略，实践 LLM-as-Judge 系统化评估\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2\",\"$ref\":{\"file\":\"lecture-2/index.mdx\"}},{\"$id\":\"lecture-2/instruction-datasets.mdx\",\"type\":\"page\",\"name\":\"2.1 指令数据集构建方法\",\"description\":\"从 Self-Instruct 到 MAGPIE 的指令数据集技术演进，数据质量控制方法，数据混合策略\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/instruction-datasets\",\"$ref\":{\"file\":\"lecture-2/instruction-datasets.mdx\"}},{\"$id\":\"lecture-2/sft-hyperparameters.mdx\",\"type\":\"page\",\"name\":\"2.2 SFT 超参数实践指南\",\"description\":\"基于 Pareja 等（2024）的系统实验结果，掌握 SFT 核心超参数的选择方法和常见问题诊断\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/sft-hyperparameters\",\"$ref\":{\"file\":\"lecture-2/sft-hyperparameters.mdx\"}},{\"$id\":\"lecture-2/llm-as-judge.mdx\",\"type\":\"page\",\"name\":\"2.3 LLM-as-Judge 评估方法\",\"description\":\"深入理解 LLM-as-Judge 评估框架，掌握 MT-Bench 评判模板，了解位置偏差和评委模型选择\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/llm-as-judge\",\"$ref\":{\"file\":\"lecture-2/llm-as-judge.mdx\"}},{\"$id\":\"lecture-2/papers.mdx\",\"type\":\"page\",\"name\":\"第2课 推荐论文\",\"description\":\"第2课推荐阅读的 5 篇核心论文：SFT 超参数指南、Self-Instruct、MT-Bench、UltraChat、Deita\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/papers\",\"$ref\":{\"file\":\"lecture-2/papers.mdx\"}},{\"$id\":\"lecture-2/lab.mdx\",\"type\":\"page\",\"name\":\"实验2：构建领域定制 SFT 模型并系统评估\",\"description\":\"从数据分析到模型训练到 LLM-as-Judge 评估的完整指令微调实验，含消融实验\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/lab\",\"$ref\":{\"file\":\"lecture-2/lab.mdx\"}}],\"$id\":\"lecture-2\",\"$ref\":{\"metaFile\":\"lecture-2/meta.json\"}},{\"type\":\"folder\",\"name\":\"第3课：偏好对齐DPO\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-3/index.mdx\",\"type\":\"page\",\"name\":\"第3课：偏好对齐——DPO 及其变体\",\"description\":\"理解为什么仅靠 SFT 不足以实现对齐，从 RLHF 目标推导 DPO 损失函数，实现 DPO 训练，并对 DPO 与 SimPO 进行实证比较\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3\",\"$ref\":{\"file\":\"lecture-3/index.mdx\"}},{\"$id\":\"lecture-3/alignment-problem.mdx\",\"type\":\"page\",\"name\":\"3.1 对齐问题：为什么仅靠 SFT 不够\",\"description\":\"SFT 教会模型'说什么'，但未教会它'如何选择'。人类偏好本质上是比较性的，偏好优化直接捕获这一信号。\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/alignment-problem\",\"$ref\":{\"file\":\"lecture-3/alignment-problem.mdx\"}},{\"$id\":\"lecture-3/dpo-derivation.mdx\",\"type\":\"page\",\"name\":\"3.2 DPO 数学推导\",\"description\":\"从 RLHF 目标到 DPO 损失函数的完整四步推导，包括闭式最优策略、奖励重参数化和 Bradley-Terry 代入\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/dpo-derivation\",\"$ref\":{\"file\":\"lecture-3/dpo-derivation.mdx\"}},{\"$id\":\"lecture-3/dpo-variants.mdx\",\"type\":\"page\",\"name\":\"3.3 DPO 变体\",\"description\":\"SimPO、KTO、ORPO、IPO 等 DPO 变体的设计理念、数学公式与适用场景比较\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/dpo-variants\",\"$ref\":{\"file\":\"lecture-3/dpo-variants.mdx\"}},{\"$id\":\"lecture-3/practical-considerations.mdx\",\"type\":\"page\",\"name\":\"3.4 实践考量\",\"description\":\"在线 vs 离线 DPO、beta 参数敏感性分析、偏好数据质量、当前领域趋势\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/practical-considerations\",\"$ref\":{\"file\":\"lecture-3/practical-considerations.mdx\"}},{\"$id\":\"lecture-3/papers.mdx\",\"type\":\"page\",\"name\":\"第3课推荐论文\",\"description\":\"DPO、SimPO、KTO、DPO vs PPO 对比实验、DPO 综述等 5 篇核心论文\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/papers\",\"$ref\":{\"file\":\"lecture-3/papers.mdx\"}},{\"$id\":\"lecture-3/lab.mdx\",\"type\":\"page\",\"name\":\"第3课实验：DPO 对齐与 SimPO 对比\",\"description\":\"使用 DPO 对齐 SFT 模型，与 SimPO 进行实证对比，涵盖偏好数据探索、训练、评估的完整流程\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/lab\",\"$ref\":{\"file\":\"lecture-3/lab.mdx\"}}],\"$id\":\"lecture-3\",\"$ref\":{\"metaFile\":\"lecture-3/meta.json\"}},{\"type\":\"folder\",\"name\":\"第4课：RLHF与GRPO\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-4/index.mdx\",\"type\":\"page\",\"name\":\"第4课：RLHF 原理与推理强化学习（GRPO）\",\"description\":\"理解完整的 RLHF 流程，掌握 GRPO 算法，使用可验证奖励复现迷你 DeepSeek-R1-Zero 实验，观察推理能力的涌现\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4\",\"$ref\":{\"file\":\"lecture-4/index.mdx\"}},{\"$id\":\"lecture-4/rlhf-pipeline.mdx\",\"type\":\"page\",\"name\":\"4.1 经典 RLHF 流程\",\"description\":\"InstructGPT 三阶段流程、奖励模型训练、PPO 核心组件、四模型架构及常见不稳定性\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/rlhf-pipeline\",\"$ref\":{\"file\":\"lecture-4/rlhf-pipeline.mdx\"}},{\"$id\":\"lecture-4/grpo-reasoning.mdx\",\"type\":\"page\",\"name\":\"4.2 GRPO 与推理涌现\",\"description\":\"DeepSeek-R1-Zero 里程碑、GRPO 四步算法详解、RLVR 可验证奖励、DeepSeek-R1 完整流程\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/grpo-reasoning\",\"$ref\":{\"file\":\"lecture-4/grpo-reasoning.mdx\"}},{\"$id\":\"lecture-4/grpo-improvements.mdx\",\"type\":\"page\",\"name\":\"4.3 GRPO 改进与测试时计算\",\"description\":\"DAPO、Dr. GRPO、REINFORCE++ 等改进方法，以及测试时计算扩展的概念和与 o1/o3/R1 的连接\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/grpo-improvements\",\"$ref\":{\"file\":\"lecture-4/grpo-improvements.mdx\"}},{\"$id\":\"lecture-4/rlhf-engineering.mdx\",\"type\":\"page\",\"name\":\"4.4 RLHF 工程工具\",\"description\":\"TRL、OpenRLHF、veRL 等 RLHF/GRPO 训练工具的功能、架构和使用场景对比\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/rlhf-engineering\",\"$ref\":{\"file\":\"lecture-4/rlhf-engineering.mdx\"}},{\"$id\":\"lecture-4/papers.mdx\",\"type\":\"page\",\"name\":\"第4课推荐论文\",\"description\":\"InstructGPT、DeepSeek-R1、DeepSeekMath、Snell et al.、DAPO、Safe RLHF、Qwen3 等 7 篇核心论文\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/papers\",\"$ref\":{\"file\":\"lecture-4/papers.mdx\"}},{\"$id\":\"lecture-4/lab.mdx\",\"type\":\"page\",\"name\":\"第4课实验：迷你 DeepSeek-R1-Zero\",\"description\":\"使用 GRPO 训练 Qwen3-1.7B-Base 进行数学推理，观察推理能力的涌现过程，并与蒸馏模型和 Qwen3 思考模式对比\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/lab\",\"$ref\":{\"file\":\"lecture-4/lab.mdx\"}}],\"$id\":\"lecture-4\",\"$ref\":{\"metaFile\":\"lecture-4/meta.json\"}},{\"type\":\"folder\",\"name\":\"第5课：压缩部署与扩展\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-5/index.mdx\",\"type\":\"page\",\"name\":\"第5课：模型压缩、部署优化与能力扩展\",\"description\":\"掌握模型量化的原理与实践（INT8/INT4/GPTQ/AWQ），理解知识蒸馏在后训练中的角色，了解多模态和工具使用等能力扩展方法\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5\",\"$ref\":{\"file\":\"lecture-5/index.mdx\"}},{\"$id\":\"lecture-5/quantization.mdx\",\"type\":\"page\",\"name\":\"5.1 模型量化\",\"description\":\"深入理解模型量化的原理、主流 PTQ 方法（INT8/INT4/GPTQ/AWQ）与 QAT，掌握精度-速度-显存的权衡\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/quantization\",\"$ref\":{\"file\":\"lecture-5/quantization.mdx\"}},{\"$id\":\"lecture-5/knowledge-distillation.mdx\",\"type\":\"page\",\"name\":\"5.2 知识蒸馏\",\"description\":\"理解经典知识蒸馏范式、LLM 时代的蒸馏实践（DeepSeek-R1-Distill、Qwen3 思考模式融合），以及蒸馏与 RL 训练的权衡\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/knowledge-distillation\",\"$ref\":{\"file\":\"lecture-5/knowledge-distillation.mdx\"}},{\"$id\":\"lecture-5/capability-extensions.mdx\",\"type\":\"page\",\"name\":\"5.3 能力扩展概览\",\"description\":\"多模态后训练（VLM/LLaVA）、工具使用与智能体（函数调用/MCP）、知识编辑（参数编辑/RAG）三大能力扩展方向\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/capability-extensions\",\"$ref\":{\"file\":\"lecture-5/capability-extensions.mdx\"}},{\"$id\":\"lecture-5/papers.mdx\",\"type\":\"page\",\"name\":\"第5课 推荐论文\",\"description\":\"GPTQ、AWQ、LLaVA、ToolACE、DeepSeek-R1 等 5 篇核心论文，涵盖量化、多模态、工具使用与蒸馏\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/papers\",\"$ref\":{\"file\":\"lecture-5/papers.mdx\"}},{\"$id\":\"lecture-5/lab.mdx\",\"type\":\"page\",\"name\":\"第5课 上机实验\",\"description\":\"量化实验（必做）：多精度加载 Qwen3-8B 并评估压缩影响；能力扩展选做（三选一）：蒸馏分析、多模态实验、工具调用实验\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/lab\",\"$ref\":{\"file\":\"lecture-5/lab.mdx\"}}],\"$id\":\"lecture-5\",\"$ref\":{\"metaFile\":\"lecture-5/meta.json\"}},{\"type\":\"folder\",\"name\":\"第6课：项目报告与总结\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-6/index.mdx\",\"type\":\"page\",\"name\":\"第6课：课程项目报告与总结\",\"description\":\"课程项目报告展示、评分标准，以及后训练技术全景回顾与前沿展望\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6\",\"$ref\":{\"file\":\"lecture-6/index.mdx\"}},{\"$id\":\"lecture-6/project-directions.mdx\",\"type\":\"page\",\"name\":\"推荐项目方向\",\"description\":\"7 个推荐的课程项目方向，涵盖数学推理、安全对齐、中文写作、代码推理、领域问答、视觉问答、工具调用智能体\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6/project-directions\",\"$ref\":{\"file\":\"lecture-6/project-directions.mdx\"}},{\"$id\":\"lecture-6/presentation-guide.mdx\",\"type\":\"page\",\"name\":\"演示指南与评分标准\",\"description\":\"项目演示的时间安排、内容要求、评分细则，以及高质量演示的实用技巧\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6/presentation-guide\",\"$ref\":{\"file\":\"lecture-6/presentation-guide.mdx\"}},{\"$id\":\"lecture-6/course-summary.mdx\",\"type\":\"page\",\"name\":\"课程总结与展望\",\"description\":\"后训练技术完整图谱回顾，从 SFT 到 GRPO 的完整路径，以及后训练领域的前沿研究方向\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6/course-summary\",\"$ref\":{\"file\":\"lecture-6/course-summary.mdx\"}}],\"$id\":\"lecture-6\",\"$ref\":{\"metaFile\":\"lecture-6/meta.json\"}},{\"$id\":\"#10\",\"type\":\"separator\",\"icon\":\"$undefined\",\"name\":\"资源\"},{\"type\":\"folder\",\"name\":\"课程资源\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"resources/setup-guide.mdx\",\"type\":\"page\",\"name\":\"环境配置指南\",\"description\":\"AutoDL 环境搭建、Colab Pro 替代方案、依赖安装、模型预下载、一键启动脚本与验证步骤\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/setup-guide\",\"$ref\":{\"file\":\"resources/setup-guide.mdx\"}},{\"$id\":\"resources/gpu-cost-guide.mdx\",\"type\":\"page\",\"name\":\"GPU 配置与费用估算\",\"description\":\"各课次 GPU 配置推荐、AutoDL 费用明细、省钱技巧与替代平台\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/gpu-cost-guide\",\"$ref\":{\"file\":\"resources/gpu-cost-guide.mdx\"}},{\"$id\":\"resources/references.mdx\",\"type\":\"page\",\"name\":\"完整参考文献\",\"description\":\"按课次整理的全部推荐论文、教材和在线资源\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/references\",\"$ref\":{\"file\":\"resources/references.mdx\"}}],\"$id\":\"resources\",\"$ref\":{\"metaFile\":\"resources/meta.json\"}}]},\"children\":\"$L7\"}]]}],{\"children\":[[\"slug\",\"lecture-1/post-training-overview\",\"oc\"],\"$L8\",{\"children\":[\"__PAGE__\",\"$L9\",{},null,false]},null,false]},null,false]},null,false],\"$La\",false]],\"m\":\"$undefined\",\"G\":[\"$b\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:I[64564,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"NavProvider\"]\nd:I[54196,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"Navbar\"]\ne:I[57326,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"default\"]\nf:I[70140,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SearchToggle\"]\n10:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarTrigger\"]\n11:I[54196,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"LayoutBody\"]\n12:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"Sidebar\"]\n13:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d092705"])</script><script>self.__next_f.push([1,"9867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarContentMobile\"]\n14:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarHeader\"]\n15:I[55461,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"ThemeToggle\"]\n16:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarViewport\"]\n17:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarItem\"]\n18:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarPageTree\"]\n19:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarFooter\"]\n1a:I[54196,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635"])</script><script>self.__next_f.push([1,"716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"CollapsibleControl\"]\n1b:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarContent\"]\n1c:I[79896,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"SidebarCollapseTrigger\"]\n1d:I[70140,[\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"1698\",\"static/chunks/1698-20472d0927059867.js\",\"7997\",\"static/chunks/7997-9f155fcb121a084c.js\",\"795\",\"static/chunks/795-ed3635716c096e23.js\",\"4499\",\"static/chunks/app/docs/layout-bc08591310048441.js\"],\"LargeSearchToggle\"]\n1f:I[13652,[],\"OutletBoundary\"]\n21:I[1293,[],\"AsyncMetadataOutlet\"]\n23:I[13652,[],\"ViewportBoundary\"]\n25:I[13652,[],\"MetadataBoundary\"]\n26:\"$Sreact.suspense\"\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"$Lc\",null,{\"transparentMode\":\"$undefined\",\"children\":[[\"$\",\"$Ld\",null,{\"className\":\"h-(--fd-nav-height) on-root:[--fd-nav-height:56px] md:on-root:[--fd-nav-height:0px] md:hidden\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center gap-2.5 font-semibold\",\"children\":\"LLM 后训练实践\"}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":\"$undefined\"}],[\"$\",\"$Lf\",null,{\"className\":\"p-2\",\"hideIfDisabled\":true}],[\"$\",\"$L10\",null,{\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [\u0026_svg]:size-4.5 p-2\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide\",\"children\":[[[\"$\",\"rect\",\"afitv7\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\"}],[\"$\",\"path\",\"fh3hqa\",{\"d\":\"M9 3v18\"}]],\"$undefined\"]}]}]]}],[\"$\",\"$L11\",null,{\"className\":\"md:[\u0026_#nd-page_article]:pt-12 xl:[--fd-toc-width:286px] xl:[\u0026_#nd-page_article]:px-8 md:[--fd-sidebar-width:268px] lg:[--fd-sidebar-width:286px]\",\"children\":[[\"$\",\"$L12\",null,{\"defaultOpenLevel\":\"$undefined\",\"prefetch\":\"$undefined\",\"Mobile\":[\"$\",\"$L13\",null,{\"children\":[[\"$\",\"$L14\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex text-fd-muted-foreground items-center gap-1.5\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-1\",\"children\":[]}],null,[\"$\",\"$L15\",null,{\"className\":\"p-0\",\"mode\":\"$undefined\"}],[\"$\",\"$L10\",null,{\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [\u0026_svg]:size-4.5 p-2\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide\",\"children\":[[[\"$\",\"rect\",\"afitv7\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\"}],[\"$\",\"path\",\"fh3hqa\",{\"d\":\"M9 3v18\"}]],\"$undefined\"]}]}]]}],false,\"$undefined\"]}],[\"$\",\"$L16\",null,{\"children\":[[[\"$\",\"$L17\",\"0\",{\"href\":\"/docs\",\"icon\":\"$undefined\",\"external\":\"$undefined\",\"className\":\"mb-4\",\"children\":\"课程内容\"}]],[\"$\",\"$L18\",null,{\"components\":\"$undefined\"}]]}],[\"$\",\"$L19\",null,{\"className\":\"empty:hidden\",\"children\":\"$undefined\"}]]}],\"Content\":[[\"$\",\"$L1a\",null,{}],[\"$\",\"$L1b\",null,{\"children\":[[\"$\",\"$L14\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"inline-flex text-[15px] items-center gap-2.5 font-medium me-auto\",\"children\":\"LLM 后训练实践\"}],\"$undefined\",[\"$\",\"$L1c\",null,{\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [\u0026_svg]:size-4.5 mb-auto text-fd-muted-foreground\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide\",\"children\":[[[\"$\",\"rect\",\"afitv7\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\"}],[\"$\",\"path\",\"fh3hqa\",{\"d\":\"M9 3v18\"}]],\"$undefined\"]}]}]]}],[\"$\",\"$L1d\",null,{\"hideIfDisabled\":true}],false,\"$undefined\"]}],\"$7:props:children:1:props:children:0:props:Mobile:props:children:1\",[\"$\",\"$L19\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex text-fd-muted-foreground items-center empty:hidden\",\"children\":[false,[],[\"$\",\"$L15\",null,{\"className\":\"ms-auto p-0\",\"mode\":\"$undefined\"}]]}],\"$undefined\"]}]]}]]}],false,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n9:[\"$\",\"$1\",\"c\",{\"children\":[\"$L1e\",null,[\"$\",\"$L1f\",null,{\"children\":[\"$L20\",[\"$\",\"$L21\",null,{\"promise\":\"$@22\"}]]}]]}]\na:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L23\",null,{\"children\":\"$L24\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L25\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$26\",null,{\"fallback\":null,\"children\":\"$L27\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"28:I[32853,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"TOCProvider\"]\n29:I[3448,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"PageTOCPopover\"]\n2a:I[3448,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"PageTOCPopoverTrigger\"]\n2b:I[3448,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"PageTOCPopoverContent\"]\n2c:I[32853,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"TOCScrollArea\"]\n2d:I[32853,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"TOCItems\"]\n2e:I[3448,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/c"])</script><script>self.__next_f.push([1,"hunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"PageBreadcrumb\"]\n"])</script><script>self.__next_f.push([1,"1e:[\"$\",\"$L28\",null,{\"toc\":[{\"depth\":2,\"url\":\"#llm-开发的三阶段流程\",\"title\":\"LLM 开发的三阶段流程\"},{\"depth\":3,\"url\":\"#阶段一预训练pre-training\",\"title\":\"阶段一：预训练（Pre-training）\"},{\"depth\":3,\"url\":\"#阶段二后训练post-training\",\"title\":\"阶段二：后训练（Post-training）\"},{\"depth\":3,\"url\":\"#阶段三推理阶段inference\",\"title\":\"阶段三：推理阶段（Inference）\"},{\"depth\":2,\"url\":\"#后训练的核心方法全景\",\"title\":\"后训练的核心方法全景\"},{\"depth\":3,\"url\":\"#1-监督微调supervised-fine-tuning-sft\",\"title\":\"1. 监督微调（Supervised Fine-Tuning, SFT）\"},{\"depth\":3,\"url\":\"#2-偏好对齐preference-alignment-dporlhf\",\"title\":\"2. 偏好对齐（Preference Alignment: DPO/RLHF）\"},{\"depth\":3,\"url\":\"#3-推理强化学习reasoning-rl-grporlvr\",\"title\":\"3. 推理强化学习（Reasoning RL: GRPO/RLVR）\"},{\"depth\":3,\"url\":\"#4-专项适配\",\"title\":\"4. 专项适配\"},{\"depth\":2,\"url\":\"#tülu-3开源后训练的黄金标准\",\"title\":\"Tülu 3：开源后训练的黄金标准\"},{\"depth\":3,\"url\":\"#sft-阶段\",\"title\":\"SFT 阶段\"},{\"depth\":3,\"url\":\"#dpo-阶段\",\"title\":\"DPO 阶段\"},{\"depth\":3,\"url\":\"#rlvr-阶段\",\"title\":\"RLVR 阶段\"},{\"depth\":2,\"url\":\"#qwen3-的四阶段后训练流程\",\"title\":\"Qwen3 的四阶段后训练流程\"},{\"depth\":3,\"url\":\"#阶段-1长思维链冷启动-sftlong-cot-cold-start\",\"title\":\"阶段 1：长思维链冷启动 SFT（Long-CoT Cold Start）\"},{\"depth\":3,\"url\":\"#阶段-2推理-rlreasoning-reinforcement-learning\",\"title\":\"阶段 2：推理 RL（Reasoning Reinforcement Learning）\"},{\"depth\":3,\"url\":\"#阶段-3思考模式融合thinking-mode-fusion\",\"title\":\"阶段 3：思考模式融合（Thinking Mode Fusion）\"},{\"depth\":3,\"url\":\"#阶段-4通用-rlgeneral-reinforcement-learning\",\"title\":\"阶段 4：通用 RL（General Reinforcement Learning）\"},{\"depth\":2,\"url\":\"#think-和-no_think-模式演示\",\"title\":[[\"$\",\"code\",null,{\"children\":\"/think\"}],\" 和 \",[\"$\",\"code\",null,{\"children\":\"/no_think\"}],\" 模式演示\"]},{\"depth\":2,\"url\":\"#本节小结\",\"title\":\"本节小结\"}],\"single\":\"$undefined\",\"children\":[\"$\",\"div\",null,{\"id\":\"nd-page\",\"className\":\"flex flex-1 w-full mx-auto max-w-(--fd-page-width) pt-(--fd-tocnav-height) pe-(--fd-toc-width)\",\"children\":[[\"$\",\"$L29\",null,{\"children\":[[\"$\",\"$L2a\",null,{}],[\"$\",\"$L2b\",null,{\"children\":[\"$undefined\",[\"$\",\"$L2c\",null,{\"children\":[\"$\",\"$L2d\",null,{}]}],\"$undefined\"]}]]}],[\"$\",\"article\",null,{\"children\":[[\"$\",\"$L2e\",null,{}],[[\"$\",\"h1\",null,{\"ref\":\"$undefined\",\"children\":\"1.1 后训练的定义与基本流程\",\"className\":\"text-[1.75em] font-semibold\"}],[\"$\",\"p\",null,{\"ref\":\"$undefined\",\"children\":\"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践\",\"className\":\"mb-8 text-lg text-fd-muted-foreground\"}],[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"llm-开发的三阶段流程\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#llm-开发的三阶段流程\",\"className\":\"peer\",\"children\":\"LLM 开发的三阶段流程\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"现代大语言模型（LLM）的开发可以清晰地划分为三个阶段：\"}],\"\\n\",[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段一预训练pre-training\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段一预训练pre-training\",\"className\":\"peer\",\"children\":\"阶段一：预训练（Pre-training）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"预训练是 LLM 的基础。在这一阶段，模型在\",[\"$\",\"strong\",null,{\"children\":\"万亿级 token\"}],\" 的大规模语料上进行下一个 token 预测（next-token prediction），学习语言知识和世界知识。\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"计算量\"}],\"：极其巨大，通常需要数千张 GPU 训练数周到数月\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"训练目标\"}],\"：标准的语言建模目标，最小化负对数似然\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":\"$L2f\"}],\"$L30\"]}]}],\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\",\"\\n\",\"$L47\",\"\\n\",\"$L48\",\"\\n\",\"$L49\",\"\\n\",\"$L4a\",\"\\n\",\"$L4b\",\"\\n\",\"$L4c\",\"\\n\",\"$L4d\",\"\\n\",\"$L4e\",\"\\n\",\"$L4f\",\"\\n\",\"$L50\",\"\\n\",\"$L51\",\"\\n\",\"$L52\",\"\\n\",\"$L53\",\"\\n\",\"$L54\",\"\\n\",\"$L55\",\"\\n\",\"$L56\",\"\\n\",\"$L57\",\"\\n\",\"$L58\",\"\\n\",\"$L59\",\"\\n\",\"$L5a\",\"\\n\",\"$L5b\",\"\\n\",\"$L5c\",\"\\n\",\"$L5d\"],\"className\":\"prose flex-1\"}]],\"$L5e\",\"$L5f\"],\"className\":\"flex min-w-0 w-full flex-col gap-4 pt-8 px-4 md:px-6 md:mx-auto\"}],\"$L60\"]}]}]\n"])</script><script>self.__next_f.push([1,"67:I[54137,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"Mermaid\"]\n6b:I[45282,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"Tabs\"]\n6c:I[45282,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"Tab\"]\n6d:I[50646,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"CodeBlock\"]\n6e:I[50646,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"Pre\"]\n72:I[3448,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"PageFooter\"]\n73:I[3448,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b35"])</script><script>self.__next_f.push([1,"7e04ad.js\"],\"PageTOC\"]\n74:I[13734,[\"2569\",\"static/chunks/942c9eea-01405fae79cb4292.js\",\"4285\",\"static/chunks/4285-64b9e8f08c1e911d.js\",\"8697\",\"static/chunks/8697-8ff18c4921047cfe.js\",\"6249\",\"static/chunks/6249-ace54a767b378723.js\",\"7870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-19c7862b357e04ad.js\"],\"I18nLabel\"]\n"])</script><script>self.__next_f.push([1,"2f:[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"mathvariant\":\"script\",\"children\":\"L\"}],[\"$\",\"mtext\",null,{\"children\":\"pretrain\"}]]}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}],[\"$\",\"mi\",null,{\"children\":\"T\"}]]}],[\"$\",\"mi\",null,{\"children\":\"log\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"P\"}],[\"$\",\"mi\",null,{\"children\":\"θ\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\"∣\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"\u003c\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\mathcal{L}_{\\\\text{pretrain}} = -\\\\sum_{t=1}^{T} \\\\log P_\\\\theta(x_t | x_{\u003ct})\"}]]}]}]\n"])</script><script>self.__next_f.push([1,"30:[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9694em\",\"verticalAlign\":\"-0.2861em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathcal\",\"children\":\"L\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3175em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"pretrain\"}]}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2861em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"3.0954em\",\"verticalAlign\":\"-1.2671em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mop op-limits\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.8283em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-1.8829em\",\"marginLeft\":\"0em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.05em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"1\"}]]}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.05em\"}}],[\"$\",\"span\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"mop op-symbol large-op\",\"children\":\"∑\"}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-4.3em\",\"marginLeft\":\"0em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.05em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.13889em\"},\"children\":\"T\"}]}]}]]}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.2671em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"lo\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.13889em\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3361em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.1389em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.02778em\"},\"children\":\"θ\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],\"$L61\"]}]}],\"$L62\"]}],\"$L63\"]}]}]]}],\"$L64\",\"$L65\",\"$L66\"]}]]}]\n"])</script><script>self.__next_f.push([1,"31:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"产出\"}],\"：一个\\\"博学但不听话\\\"的\",[\"$\",\"strong\",null,{\"children\":\"基座模型\"}],\"（base model）——它拥有丰富的知识，但不会遵循人类指令、不懂对话格式、可能生成有害内容\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"32:[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"className\":\"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md\",\"style\":{\"--callout-color\":\"var(--color-fd-info, var(--color-fd-muted))\"},\"children\":[[\"$\",\"div\",null,{\"role\":\"none\",\"className\":\"w-0.5 bg-(--callout-color)/50 rounded-sm\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card\",\"children\":[[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"1dtifu\",{\"d\":\"M12 16v-4\"}],[\"$\",\"path\",\"e9boi3\",{\"d\":\"M12 8h.01\"}]],\"$undefined\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-2 min-w-0 flex-1\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"以 Qwen3 为例：Qwen3 系列在约 36 万亿 token 上进行了预训练，涵盖 119 种语言和编程语言。预训练分为三个阶段（S1: 30T tokens, S2: 5T tokens, S3: 退火阶段），逐步提升数据质量。\"}]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"33:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段二后训练post-training\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段二后训练post-training\",\"className\":\"peer\",\"children\":\"阶段二：后训练（Post-training）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"34:[\"$\",\"p\",null,{\"children\":\"后训练是将基座模型转化为实用助手的关键阶段。通过 SFT、偏好对齐、强化学习等手段，赋予模型指令跟随、安全回复、推理思考等能力。\"}]\n35:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"计算量\"}],\"：仅占预训练的约 \",[\"$\",\"strong\",null,{\"children\":\"5%\"}],\"（以 DeepSeek-R1 为例），但决定了模型的实际可用性\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"核心目标\"}],\"：让模型学会\\\"怎么说话\\\"、\\\"怎么选择\\\"、\\\"怎么思考\\\"\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"产出\"}],\"：一个能遵循指令、安全有用的\",[\"$\",\"strong\",null,{\"children\":\"对齐模型\"}],\"（aligned model / instruct model）\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"36:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段三推理阶段inference\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段三推理阶段inference\",\"className\":\"peer\",\"children\":\"阶段三：推理阶段（Inference）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"37:[\"$\",\"p\",null,{\"children\":\"模型部署后的优化和扩展阶段：\"}]\n38:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"部署优化\"}],\"：量化（INT8/INT4）、蒸馏、剪枝等方法减少模型体积和推理成本\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"推理时计算扩展\"}],\"：思维链（Chain-of-Thought）、best-of-N 采样、树搜索等方法在推理时分配更多计算资源\"]}],\"\\n\"]}]\n39:[\"$\",\"$L67\",null,{\"chart\":\"graph LR\\n  A[\\\"\u003cb\u003e预训练\u003c/b\u003e\u003cbr/\u003e数月 · 数千GPU\u003cbr/\u003e万亿级 token\u003cbr/\u003e下一个 token 预测\u003cbr/\u003e基座模型\u003cbr/\u003e\u003ci\u003e≈95% 成本\u003c/i\u003e\\\"]\\n  B[\\\"\u003cb\u003e后训练\u003c/b\u003e\u003cbr/\u003e数天 · 数十GPU\u003cbr/\u003eSFT → DPO → GRPO\u003cbr/\u003e指令跟随、偏好对齐\u003cbr/\u003e推理能力\u003cbr/\u003e\u003ci\u003e≈5% 成本\u003c/i\u003e\\\"]\\n  C[\\\"\u003cb\u003e推理\u003c/b\u003e\u003cbr/\u003e毫秒级\u003cbr/\u003e量化 / 蒸馏\u003cbr/\u003e推理时计算扩展\u003cbr/\u003e部署服务\u003cbr/\u003e\u003ci\u003e面向用户\u003c/i\u003e\\\"]\\n  A --\u003e B --\u003e C\"}]\n3a:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"3b:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"后训练的核心方法全景\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#后训练的核心方法全景\",\"className\":\"peer\",\"children\":\"后训练的核心方法全景\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3c:[\"$\",\"p\",null,{\"children\":\"后训练涵盖多种方法，按功能可分为四大类：\"}]\n"])</script><script>self.__next_f.push([1,"3d:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"1-监督微调supervised-fine-tuning-sft\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#1-监督微调supervised-fine-tuning-sft\",\"className\":\"peer\",\"children\":\"1. 监督微调（Supervised Fine-Tuning, SFT）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3e:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"教模型\\\"怎么说话\\\"\"}],\"——学会遵循指令、按格式回复。\"]}]\n3f:[\"$\",\"p\",null,{\"children\":[\"SFT 使用高质量的 \",[\"$\",\"code\",null,{\"children\":\"(指令, 回复)\"}],\" 对来训练模型。模型学习的是：给定一个指令，如何生成符合期望的回复。这是后训练的\",[\"$\",\"strong\",null,{\"children\":\"第一步\"}],\"，也是其他所有方法的基础。\"]}]\n40:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"输入：\",[\"$\",\"code\",null,{\"children\":\"\\\"用三句话介绍量子计算\\\"\"}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"期望输出：\",[\"$\",\"code\",null,{\"children\":\"\\\"量子计算利用量子力学原理进行信息处理...\\\"\"}]]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"41:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"2-偏好对齐preference-alignment-dporlhf\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#2-偏好对齐preference-alignment-dporlhf\",\"className\":\"peer\",\"children\":\"2. 偏好对齐（Preference Alignment: DPO/RLHF）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"42:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"教模型\\\"怎么选择\\\"\"}],\"——在多个可能的回复中选择更好的。\"]}]\n43:[\"$\",\"p\",null,{\"children\":[\"SFT 后的模型可能生成多种回复，但并非所有回复都同样好。偏好对齐通过\",[\"$\",\"strong\",null,{\"children\":\"人类偏好数据\"}],\"（\\\"回复 A 优于回复 B\\\"）来教模型区分好坏：\"]}]\n44:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"RLHF\"}],\"（Reinforcement Learning from Human Feedback）：训练奖励模型 + PPO 优化\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"DPO\"}],\"（Direct Preference Optimization）：直接在偏好对上训练，无需奖励模型\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"45:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"3-推理强化学习reasoning-rl-grporlvr\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#3-推理强化学习reasoning-rl-grporlvr\",\"className\":\"peer\",\"children\":\"3. 推理强化学习（Reasoning RL: GRPO/RLVR）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"46:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"教模型\\\"怎么思考\\\"\"}],\"——发展逐步推理和自我验证能力。\"]}]\n47:[\"$\",\"p\",null,{\"children\":[\"这是 2024-2025 年最激动人心的进展。通过\",[\"$\",\"strong\",null,{\"children\":\"可验证奖励\"}],\"（如数学答案的正确性），模型在纯强化学习中自发涌现出推理能力：\"]}]\n48:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"GRPO\"}],\"（Group Relative Policy Optimization）：DeepSeek 提出的高效 RL 算法\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"RLVR\"}],\"（RL with Verifiable Rewards）：使用确定性奖励函数代替人类标注\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"49:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"4-专项适配\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#4-专项适配\",\"className\":\"peer\",\"children\":\"4. 专项适配\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"4a:[\"$\",\"p\",null,{\"children\":\"根据应用场景扩展模型能力：\"}]\n4b:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"工具使用\"}],\"：学会调用 API、函数调用（Function Calling）\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"多模态理解\"}],\"：视觉-语言对齐（VLM）\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"领域知识注入\"}],\"：医疗、法律、金融等垂直领域微调\"]}],\"\\n\"]}]\n4c:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"4d:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"tülu-3开源后训练的黄金标准\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#tülu-3开源后训练的黄金标准\",\"className\":\"peer\",\"children\":\"Tülu 3：开源后训练的黄金标准\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"4e:[\"$\",\"p\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2411.15124\",\"children\":\"Tülu 3\"}],\"（Lambert 等，2024）是目前最完整的开源后训练方案，其流程为本课程提供了核心参考框架：\"]}]\n"])</script><script>self.__next_f.push([1,"4f:[\"$\",\"div\",null,{\"className\":\"fd-steps\",\"children\":[[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"sft-阶段\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#sft-阶段\",\"className\":\"peer\",\"children\":\"SFT 阶段\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],[\"$\",\"p\",null,{\"children\":\"在精心混合的多源指令数据上进行监督微调。Tülu 3 使用了来自多个来源的数据，并通过系统性的数据混合实验确定最优配比。\"}]]}],[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"dpo-阶段\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#dpo-阶段\",\"className\":\"peer\",\"children\":\"DPO 阶段\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],[\"$\",\"p\",null,{\"children\":[\"使用偏好数据进行 DPO 对齐，提升模型的回复质量和安全性。关键发现：\",[\"$\",\"strong\",null,{\"children\":\"在策略\"}],\"（on-policy）生成的偏好数据效果优于离线数据。\"]}]]}],[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"rlvr-阶段\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#rlvr-阶段\",\"className\":\"peer\",\"children\":\"RLVR 阶段\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],[\"$\",\"p\",null,{\"children\":\"使用可验证奖励进行强化学习，专门提升数学推理和指令跟随能力。这一步是 Tülu 3 在 GSM8K 等推理基准上取得突破的关键。\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"50:[\"$\",\"p\",null,{\"children\":[\"Tülu 3 的核心贡献在于其\",[\"$\",\"strong\",null,{\"children\":\"系统性的消融实验\"}],\"：每一步的设计选择（数据配比、超参数、方法选型）都有实验支撑，为开源社区提供了可复现的最佳实践。\"]}]\n51:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"52:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"qwen3-的四阶段后训练流程\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#qwen3-的四阶段后训练流程\",\"className\":\"peer\",\"children\":\"Qwen3 的四阶段后训练流程\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"53:[\"$\",\"p\",null,{\"children\":[\"Qwen3 的后训练流程是本课程技术体系的\",[\"$\",\"strong\",null,{\"children\":\"最佳案例\"}],\"。根据 Qwen3 技术报告（arXiv:2505.09388），其后训练分为四个精心设计的阶段：\"]}]\n"])</script><script>self.__next_f.push([1,"54:[\"$\",\"div\",null,{\"className\":\"fd-steps\",\"children\":[[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段-1长思维链冷启动-sftlong-cot-cold-start\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段-1长思维链冷启动-sftlong-cot-cold-start\",\"className\":\"peer\",\"children\":\"阶段 1：长思维链冷启动 SFT（Long-CoT Cold Start）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],[\"$\",\"p\",null,{\"children\":[\"使用精心构造的\",[\"$\",\"strong\",null,{\"children\":\"长思维链数据\"}],\"进行 SFT，为模型注入基本的推理模式。这些数据包含详细的逐步推理过程，教会模型如何展开深度思考。\"]}],[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"数据来源：通过强模型生成、人工筛选的高质量推理数据\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"目标：让模型掌握 \",[\"$\",\"code\",null,{\"children\":\"\u003cthink\u003e...\u003c/think\u003e\"}],\" 格式的思维链输出\"]}],\"\\n\"]}]]}],[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段-2推理-rlreasoning-reinforcement-learning\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段-2推理-rlreasoning-reinforcement-learning\",\"className\":\"peer\",\"children\":\"阶段 2：推理 RL（Reasoning Reinforcement Learning）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],[\"$\",\"p\",null,{\"children\":[\"在数学、代码等可验证任务上进行大规模 \",[\"$\",\"strong\",null,{\"children\":\"GRPO\"}],\" 训练，强化模型的推理能力。\"]}],[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"奖励信号：答案正确性（可验证奖励）\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"关键效果：模型学会了更长、更深入的推理链，自发涌现出自我验证和回溯能力\"}],\"\\n\"]}]]}],[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段-3思考模式融合thinking-mode-fusion\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段-3思考模式融合thinking-mode-fusion\",\"className\":\"peer\",\"children\":\"阶段 3：思考模式融合（Thinking Mode Fusion）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],[\"$\",\"p\",null,{\"children\":[\"将推理 RL 阶段获得的深度思考能力\",[\"$\",\"strong\",null,{\"children\":\"融合回统一模型\"}],\"，使模型同时具备：\"]}],[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"思考模式\"}],\"（Thinking Mode）：生成详细的内部推理过程\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"非思考模式\"}],\"（Non-Thinking Mode）：直接给出简洁回复\"]}],\"\\n\"]}],[\"$\",\"p\",null,{\"children\":[\"这一阶段本质上是一种\",[\"$\",\"strong\",null,{\"children\":\"蒸馏\"}],\"：将 RL 训练的推理专家能力蒸馏到一个统一的模型中。\"]}]]}],[\"$\",\"div\",null,{\"className\":\"fd-step\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"阶段-4通用-rlgeneral-reinforcement-learning\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#阶段-4通用-rlgeneral-reinforcement-learning\",\"className\":\"peer\",\"children\":\"阶段 4：通用 RL（General Reinforcement Learning）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[\"$L68\",\"$L69\"],\"$undefined\"]}]]}],\"$L6a\"]}]]}]\n"])</script><script>self.__next_f.push([1,"55:[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"className\":\"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md\",\"style\":{\"--callout-color\":\"var(--color-fd-info, var(--color-fd-muted))\"},\"children\":[[\"$\",\"div\",null,{\"role\":\"none\",\"className\":\"w-0.5 bg-(--callout-color)/50 rounded-sm\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card\",\"children\":[[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"1dtifu\",{\"d\":\"M12 16v-4\"}],[\"$\",\"path\",\"e9boi3\",{\"d\":\"M12 8h.01\"}]],\"$undefined\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-2 min-w-0 flex-1\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Qwen3 的四阶段后训练流程正好对应了本课程的技术体系：阶段 1 对应第 1-2 课（SFT），阶段 2 对应第 4 课（GRPO），阶段 3-4 对应第 3 课（偏好对齐）和第 5 课（部署优化）。\"}]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"56:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"57:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"think-和-no_think-模式演示\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#think-和-no_think-模式演示\",\"className\":\"peer\",\"children\":[[\"$\",\"code\",null,{\"children\":\"/think\"}],\" 和 \",[\"$\",\"code\",null,{\"children\":\"/no_think\"}],\" 模式演示\"]}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"58:[\"$\",\"p\",null,{\"children\":\"Qwen3 Instruct 模型内置了思考模式切换功能，这是后训练赋予模型的核心能力之一。\"}]\n"])</script><script>self.__next_f.push([1,"59:[\"$\",\"$L6b\",null,{\"items\":[\"思考模式 /think\",\"非思考模式 /no_think\"],\"children\":[[\"$\",\"$L6c\",null,{\"value\":\"思考模式 /think\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"在思考模式下，模型会先在 \",[\"$\",\"code\",null,{\"children\":\"\u003cthink\u003e\"}],\" 标签内展开内部推理，然后给出最终回复：\"]}],[\"$\",\"$L6d\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L6e\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"用户：/think\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"      解方程 3x + 7 = 22\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"助手：\u003cthink\u003e\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"我需要解方程 3x + 7 = 22。\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"首先，将 7 从等式两边减去：\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"3x + 7 - 7 = 22 - 7\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"3x = 15\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"然后，将两边除以 3：\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"x = 15 / 3\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"x = 5\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"让我验证一下：3 × 5 + 7 = 15 + 7 = 22 ✓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"\u003c/think\u003e\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"解方程 3x + 7 = 22：\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"将常数项移到右边：3x = 22 - 7 = 15\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"两边除以 3：**x = 5**\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"验证：3 × 5 + 7 = 22 ✓\"}]}]]}]}]}],[\"$\",\"p\",null,{\"children\":\"思考模式适合需要深度推理的任务：数学题、编程、逻辑分析等。\"}]]}],[\"$\",\"$L6c\",null,{\"value\":\"非思考模式 /no_think\",\"children\":[[\"$\",\"p\",null,{\"children\":\"在非思考模式下，模型跳过内部推理过程，直接给出简洁回复：\"}],[\"$\",\"$L6d\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L6e\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"用户：/no_think\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"      解方程 3x + 7 = 22\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"助手：\u003cthink\u003e\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"\u003c/think\u003e\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"解方程 3x + 7 = 22：\"}]}],\"\\n\",\"$L6f\",\"\\n\",\"$L70\"]}]}]}],\"$L71\"]}]]}]\n"])</script><script>self.__next_f.push([1,"5a:[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"className\":\"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md\",\"style\":{\"--callout-color\":\"var(--color-fd-warning, var(--color-fd-muted))\"},\"children\":[[\"$\",\"div\",null,{\"role\":\"none\",\"className\":\"w-0.5 bg-(--callout-color)/50 rounded-sm\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card\",\"children\":[[[\"$\",\"path\",\"wmoenq\",{\"d\":\"m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3\"}],[\"$\",\"path\",\"juzpu7\",{\"d\":\"M12 9v4\"}],[\"$\",\"path\",\"p32p05\",{\"d\":\"M12 17h.01\"}]],\"$undefined\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-2 min-w-0 flex-1\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":[\"只有经过完整后训练流程的 \",[\"$\",\"strong\",null,{\"children\":\"Instruct\"}],\" 版本才支持 \",[\"$\",\"code\",null,{\"children\":\"/think\"}],\" 和 \",[\"$\",\"code\",null,{\"children\":\"/no_think\"}],\" 模式切换。基座模型（Base）不具备这一能力——这正是后训练的价值所在。\"]}]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"5b:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"5c:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"本节小结\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#本节小结\",\"className\":\"peer\",\"children\":\"本节小结\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"5d:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"概念\"}],[\"$\",\"th\",null,{\"children\":\"说明\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"预训练\"}],[\"$\",\"td\",null,{\"children\":\"万亿级 token 上的语言建模，产出基座模型\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"后训练\"}],[\"$\",\"td\",null,{\"children\":\"SFT + 偏好对齐 + 推理 RL，将基座模型转化为实用助手\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"SFT\"}],[\"$\",\"td\",null,{\"children\":\"教模型\\\"怎么说话\\\"\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"DPO/RLHF\"}],[\"$\",\"td\",null,{\"children\":\"教模型\\\"怎么选择\\\"\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"GRPO/RLVR\"}],[\"$\",\"td\",null,{\"children\":\"教模型\\\"怎么思考\\\"\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Tülu 3\"}],[\"$\",\"td\",null,{\"children\":\"开源后训练黄金标准：SFT → DPO → RLVR\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Qwen3\"}],[\"$\",\"td\",null,{\"children\":\"四阶段后训练：冷启动 SFT → 推理 RL → 模式融合 → 通用 RL\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"5e:[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-center justify-between gap-4 empty:hidden\",\"children\":[\"$undefined\",\"$undefined\"]}]\n5f:[\"$\",\"$L72\",null,{\"items\":\"$undefined\"}]\n60:[\"$\",\"$L73\",null,{\"children\":[\"$undefined\",[\"$\",\"h3\",null,{\"className\":\"inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-4\",\"children\":[[[\"$\",\"path\",\"olowqp\",{\"d\":\"M15 18H3\"}],[\"$\",\"path\",\"16j9eg\",{\"d\":\"M17 6H3\"}],[\"$\",\"path\",\"2avoz0\",{\"d\":\"M21 12H3\"}]],\"$undefined\"]}],[\"$\",\"$L74\",null,{\"label\":\"toc\"}]]}],[\"$\",\"$L2c\",null,{\"children\":[\"$\",\"$L2d\",null,{}]}],\"$undefined\"]}]\n"])</script><script>self.__next_f.push([1,"61:[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}]}]\n62:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\n63:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\n64:[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"∣\"}]\n"])</script><script>self.__next_f.push([1,"65:[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\"\u003c\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}]]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1774em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"66:[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]\n68:[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}]\n69:[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]\n6a:[\"$\",\"p\",null,{\"children\":\"使用通用奖励信号（包括人类偏好和规则奖励）进行最终的强化学习，全面提升模型在各项能力上的表现，包括指令跟随、安全性、多语言等。\"}]\n6f:[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"- 3x = 15\"}]}]\n70:[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"- **x = 5**\"}]}]\n71:[\"$\",\"p\",null,{\"children\":\"非思考模式适合简单问答、创意写作等不需要深度推理的场景，响应更快。\"}]\n"])</script><script>self.__next_f.push([1,"24:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n20:null\n"])</script><script>self.__next_f.push([1,"22:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"1.1 后训练的定义与基本流程 | LLM 后训练课程\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"27:\"$22:metadata\"\n"])</script></body></html>