<!DOCTYPE html><!--ch1b6kq8kuWTUda8E58Ln--><html lang="zh-CN" class="__variable_51740a __variable_3c557b"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/bb3ef058b751a6ad-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/edef1a271f97a8ec-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/d0f7ca2a7022be00.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/62a6e77bcc5afb05.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/4cd23781d18a52d3.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-d558155d46ca9095.js"/><script src="/_next/static/chunks/6ee9f5d1-f81e370e11b7c28f.js" async=""></script><script src="/_next/static/chunks/977-6595e84e5e48e161.js" async=""></script><script src="/_next/static/chunks/main-app-63fde83b8b4f34d4.js" async=""></script><script src="/_next/static/chunks/716-8b6c239d56add41d.js" async=""></script><script src="/_next/static/chunks/98-71e6ffba5da79e51.js" async=""></script><script src="/_next/static/chunks/app/layout-438f3f1dcf44f88c.js" async=""></script><script src="/_next/static/chunks/285-5cab2c46bf0cbdc3.js" async=""></script><script src="/_next/static/chunks/698-2edc64166f51fb90.js" async=""></script><script src="/_next/static/chunks/997-8062435351294ce8.js" async=""></script><script src="/_next/static/chunks/795-2e60776a7ce82cea.js" async=""></script><script src="/_next/static/chunks/app/docs/layout-8640be9db805fb1e.js" async=""></script><script src="/_next/static/chunks/697-8c55336afc55c2a1.js" async=""></script><script src="/_next/static/chunks/324-9e7d7f5bb89b8982.js" async=""></script><script src="/_next/static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-6PZFJCKFSJ" as="script"/><meta name="next-size-adjust" content=""/><title>完整参考文献 | LLM 后训练课程</title><meta name="description" content="按课次整理的全部推荐论文、教材和在线资源"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="flex min-h-screen flex-col"><div hidden=""><!--$--><!--/$--></div><script>((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","system",null,["light","dark"],null,true,true)</script><div class="bg-fd-secondary/50 p-3 empty:hidden"></div><header id="nd-subnav" class="fixed top-(--fd-banner-height) left-0 right-(--removed-body-scroll-bar-size,0) z-30 flex items-center ps-4 pe-2.5 border-b transition-colors backdrop-blur-sm bg-fd-background/80 h-(--fd-nav-height) on-root:[--fd-nav-height:56px] md:on-root:[--fd-nav-height:0px] md:hidden"><a class="inline-flex items-center gap-2.5 font-semibold" href="/">LLM 后训练实践</a><div class="flex-1"></div><button type="button" class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-4.5 p-2" data-search="" aria-label="Open Search"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button><button class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-4.5 p-2" aria-label="Open Sidebar"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg></button></header><main id="nd-docs-layout" class="flex flex-1 flex-col pt-(--fd-nav-height) transition-[padding] fd-default-layout mx-(--fd-layout-offset) md:[&amp;_#nd-page_article]:pt-12 xl:[--fd-toc-width:286px] xl:[&amp;_#nd-page_article]:px-8 md:[--fd-sidebar-width:268px] lg:[--fd-sidebar-width:286px]" style="padding-inline-start:var(--fd-sidebar-width)"><div class="fixed flex shadow-lg transition-opacity rounded-xl p-0.5 border bg-fd-muted text-fd-muted-foreground z-10 max-md:hidden xl:start-4 max-xl:end-4 pointer-events-none opacity-0" style="top:calc(var(--fd-banner-height) + var(--fd-tocnav-height) + var(--spacing) * 4)"><button type="button" aria-label="Collapse Sidebar" data-collapsed="false" class="inline-flex items-center justify-center text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-4.5 rounded-lg"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg></button><button type="button" class="inline-flex items-center justify-center text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-4.5 rounded-lg" data-search="" aria-label="Open Search"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button></div><aside id="nd-sidebar" data-collapsed="false" class="fixed left-0 rtl:left-auto rtl:right-(--removed-body-scroll-bar-size,0) flex flex-col items-end top-(--fd-sidebar-top) bottom-(--fd-sidebar-margin) z-20 bg-fd-card text-sm border-e transition-[top,opacity,translate,width] duration-200 max-md:hidden *:w-(--fd-sidebar-width)" style="--fd-sidebar-offset:calc(16px - 100%);--fd-sidebar-margin:0px;--fd-sidebar-top:calc(var(--fd-banner-height) + var(--fd-nav-height) + var(--fd-sidebar-margin));width:calc(var(--spacing) + var(--fd-sidebar-width) + var(--fd-layout-offset))"><div class="flex flex-col gap-3 p-4 pb-2"><div class="flex"><a class="inline-flex text-[15px] items-center gap-2.5 font-medium me-auto" href="/">LLM 后训练实践</a><button type="button" aria-label="Collapse Sidebar" data-collapsed="false" class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-4.5 mb-auto text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg></button></div><button type="button" data-search-full="" class="inline-flex items-center gap-2 rounded-lg border bg-fd-secondary/50 p-1.5 ps-2 text-sm text-fd-muted-foreground transition-colors hover:bg-fd-accent hover:text-fd-accent-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-4"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg>Search<div class="ms-auto inline-flex gap-0.5"><kbd class="rounded-md border bg-fd-background px-1.5">⌘</kbd><kbd class="rounded-md border bg-fd-background px-1.5">K</kbd></div></button></div><div dir="ltr" class="overflow-hidden h-full" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" class="size-full rounded-[inherit] p-4 overscroll-contain" style="overflow-x:hidden;overflow-y:hidden;--sidebar-item-offset:calc(var(--spacing) * 2);mask-image:linear-gradient(to bottom, transparent, white 12px, white calc(100% - 12px), transparent)"><div style="min-width:100%;display:table"><a class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none mb-4" data-active="false" href="/docs">课程内容</a><p class="inline-flex items-center gap-2 mb-1.5 px-2 ps-(--sidebar-item-offset) empty:mb-0 [&amp;_svg]:size-4 [&amp;_svg]:shrink-0">课程内容</p><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs">课程总览</a><p class="inline-flex items-center gap-2 mb-1.5 px-2 ps-(--sidebar-item-offset) empty:mb-0 [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 mt-6">讲座</p><div data-state="closed"><button type="button" aria-controls="radix-_R_4kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第1课：后训练概述与SFT基础<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_4kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_5kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第2课：SFT进阶<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_5kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_6kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第3课：偏好对齐DPO<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_6kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_7kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第4课：RLHF与GRPO<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_7kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_8kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第5课：压缩部署与扩展<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_8kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><div data-state="closed"><button type="button" aria-controls="radix-_R_9kqd5ulb_" aria-expanded="false" data-state="closed" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">第6课：项目报告与总结<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform -rotate-90" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_9kqd5ulb_" hidden="" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"></div></div><p class="inline-flex items-center gap-2 mb-1.5 px-2 ps-(--sidebar-item-offset) empty:mb-0 [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 mt-6">资源</p><div data-state="open"><button type="button" aria-controls="radix-_R_bkqd5ulb_" aria-expanded="true" data-state="open" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none w-full">课程资源<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide ms-auto transition-transform" data-icon="true"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="open" id="radix-_R_bkqd5ulb_" class="overflow-hidden relative before:content-[&#x27;&#x27;] before:absolute before:w-px before:inset-y-1 before:bg-fd-border before:start-2.5 **:data-[active=true]:before:content-[&#x27;&#x27;] **:data-[active=true]:before:bg-fd-primary **:data-[active=true]:before:absolute **:data-[active=true]:before:w-px **:data-[active=true]:before:inset-y-2.5 **:data-[active=true]:before:start-2.5" style="--sidebar-item-offset:calc(var(--spacing) * 6)"><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/resources/setup-guide">环境配置指南</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/resources/gpu-cost-guide">GPU 配置与费用估算</a><a data-active="true" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-fd-primary/10 text-fd-primary" href="/docs/resources/references">完整参考文献</a><a data-active="false" class="relative flex flex-row items-center gap-2 rounded-lg p-2 ps-(--sidebar-item-offset) text-start text-fd-muted-foreground [overflow-wrap:anywhere] [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 transition-colors hover:bg-fd-accent/50 hover:text-fd-accent-foreground/80 hover:transition-none" href="/docs/resources/grading">评分标准</a></div></div></div></div></div><div class="flex flex-col border-t p-4 pt-2"><div class="flex text-fd-muted-foreground items-center empty:hidden"><button class="inline-flex items-center rounded-full border ms-auto p-0" aria-label="Toggle Theme" data-theme-toggle=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg></button></div></div></aside><div id="nd-page" class="flex flex-1 w-full mx-auto max-w-(--fd-page-width) pt-(--fd-tocnav-height) pe-(--fd-toc-width)"><header id="nd-tocnav" class="fixed pr-(--removed-body-scroll-bar-size,0) z-10 border-b backdrop-blur-sm transition-colors xl:hidden max-xl:on-root:[--fd-tocnav-height:40px] bg-fd-background/80" style="top:calc(var(--fd-banner-height) + var(--fd-nav-height));inset-inline-start:calc(var(--fd-sidebar-width) + var(--fd-layout-offset));inset-inline-end:0" data-state="closed"><button type="button" aria-controls="radix-_R_anpft5ulb_" aria-expanded="false" data-state="closed" class="flex w-full h-(--fd-tocnav-height) items-center text-sm text-fd-muted-foreground gap-2.5 px-4 py-2.5 text-start focus-visible:outline-none [&amp;_svg]:size-4 md:px-6"><svg role="progressbar" viewBox="0 0 24 24" aria-valuenow="0" aria-valuemin="0" aria-valuemax="1" class="shrink-0"><circle cx="12" cy="12" r="11" fill="none" stroke-width="2" class="stroke-current/25"></circle><circle cx="12" cy="12" r="11" fill="none" stroke-width="2" stroke="currentColor" stroke-dasharray="69.11503837897544" stroke-dashoffset="69.11503837897544" stroke-linecap="round" transform="rotate(-90 12 12)" class="transition-all"></circle></svg><span class="grid flex-1 *:my-auto *:row-start-1 *:col-start-1"><span class="truncate transition-all">完整参考文献</span><span class="truncate transition-all opacity-0 translate-y-full pointer-events-none"></span></span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide shrink-0 transition-transform mx-0.5"><path d="m6 9 6 6 6-6"></path></svg></button><div data-state="closed" id="radix-_R_anpft5ulb_" hidden="" data-toc-popover="" class="overflow-hidden flex flex-col px-4 max-h-[50vh] md:px-6"></div></header><article class="flex min-w-0 w-full flex-col gap-4 pt-8 px-4 md:px-6 md:mx-auto"><div class="flex items-center gap-1.5 text-sm text-fd-muted-foreground"><span class="truncate text-fd-primary font-medium">课程资源</span></div><h1 class="text-[1.75em] font-semibold">完整参考文献</h1><p class="mb-8 text-lg text-fd-muted-foreground">按课次整理的全部推荐论文、教材和在线资源</p><div class="prose flex-1"><h2 class="flex scroll-m-28 flex-row items-center gap-2" id="教材与综合资源"><a data-card="" href="#教材与综合资源" class="peer">教材与综合资源</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>资源</th><th>作者</th><th>年份</th><th>说明</th></tr></thead><tbody><tr><td><a href="https://arxiv.org/abs/2505.09388" rel="noreferrer noopener" target="_blank">Qwen3 Technical Report</a></td><td>Qwen Team</td><td>2025</td><td>Qwen3 系列完整技术报告，贯穿全课程</td></tr><tr><td><a href="https://rlhfbook.com" rel="noreferrer noopener" target="_blank">Reinforcement Learning from Human Feedback</a></td><td>Nathan Lambert</td><td>2025</td><td>第一本 RLHF 综合教材，免费获取</td></tr><tr><td><a href="https://github.com/huggingface/smol-course" rel="noreferrer noopener" target="_blank">Hugging Face smol-course</a></td><td>Hugging Face</td><td>2024</td><td>开源实践迷你课程，涵盖 SFT、DPO、VLM</td></tr><tr><td><a href="https://github.com/huggingface/alignment-handbook" rel="noreferrer noopener" target="_blank">Hugging Face Alignment Handbook</a></td><td>Hugging Face</td><td>2024</td><td>生产级 SFT → DPO/ORPO 流程方案</td></tr><tr><td><a href="https://cs336.stanford.edu/" rel="noreferrer noopener" target="_blank">Stanford CS336: Language Modeling from Scratch</a></td><td>Stanford</td><td>2025</td><td>作业5涵盖对齐与推理 RL</td></tr><tr><td><a href="https://www.deeplearning.ai/" rel="noreferrer noopener" target="_blank">Intro to Post-Training</a></td><td>DeepLearning.AI</td><td>2025</td><td>5模块视频课程</td></tr></tbody></table></div>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="第1课后训练概述与监督微调基础"><a data-card="" href="#第1课后训练概述与监督微调基础" class="peer">第1课：后训练概述与监督微调基础</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="核心论文"><a data-card="" href="#核心论文" class="peer">核心论文</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<div class="grid grid-cols-2 gap-3 @container"><a href="https://arxiv.org/abs/2411.15124" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">1. Tülu 3: Pushing Frontiers in Open Language Model Post-Training</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Lambert et al. (2024.11) — 最完整的开源后训练方案，SFT → DPO → RLVR 的黄金标准流程</p></div></a><a href="https://arxiv.org/abs/2106.09685" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">2. LoRA: Low-Rank Adaptation of Large Language Models</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Hu et al. (2021) — 参数高效微调奠基论文，提出低秩分解训练方法</p></div></a><a href="https://arxiv.org/abs/2305.14314" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">3. QLoRA: Efficient Finetuning of Quantized LLMs</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Dettmers et al. (2023) — NF4 量化 + LoRA，使大模型微调走向消费级 GPU</p></div></a><a href="https://arxiv.org/abs/2305.11206" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">4. LIMA: Less Is More for Alignment</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Zhou et al. (2023) — 证明 1000 条高质量数据可超越 50000 条噪声数据</p></div></a><a href="https://arxiv.org/abs/2406.08464" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">5. MAGPIE: Alignment Data Synthesis from Scratch</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Xu et al. (ICLR 2025) — 利用对齐模型的自动补全行为合成指令数据</p></div></a></div>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="扩展阅读"><a data-card="" href="#扩展阅读" class="peer">扩展阅读</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><a href="https://arxiv.org/abs/2305.16264" rel="noreferrer noopener" target="_blank">Scaling Data-Constrained Language Models</a> — Muennighoff et al. (2024), 数据规模与质量的系统研究</li>
<li><a href="https://arxiv.org/abs/2402.09353" rel="noreferrer noopener" target="_blank">DoRA: Weight-Decomposed Low-Rank Adaptation</a> — Liu et al. (2024), LoRA 的改进版本</li>
<li><a href="https://arxiv.org/abs/2406.06623" rel="noreferrer noopener" target="_blank">Spectrum: Targeted Training on Signal to Noise Ratio</a> — Verma et al. (2024), 基于信噪比的层选择</li>
</ul>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="第2课sft-进阶与数据工程"><a data-card="" href="#第2课sft-进阶与数据工程" class="peer">第2课：SFT 进阶与数据工程</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="核心论文-1"><a data-card="" href="#核心论文-1" class="peer">核心论文</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<div class="grid grid-cols-2 gap-3 @container"><a href="https://arxiv.org/abs/2412.13337" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">1. Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Pareja et al. (2024.12) — 3B-7B 模型 SFT 的全面超参数指南</p></div></a><a href="https://arxiv.org/abs/2212.10560" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">2. Self-Instruct: Aligning Language Models with Self-Generated Instructions</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Wang et al. (2023) — 指令数据合成的开创性工作</p></div></a><a href="https://arxiv.org/abs/2306.05685" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">3. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Zheng et al. (NeurIPS 2023) — LLM-as-Judge 评估框架</p></div></a><a href="https://arxiv.org/abs/2305.14233" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">4. UltraChat: A Large-scale Auto-generated Multi-turn Instruction Dataset</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Ding et al. (2023) — 高质量多轮对话数据集构建方法</p></div></a><a href="https://arxiv.org/abs/2312.15685" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">5. Deita: Data-Efficient Instruction Tuning Alignment</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Liu et al. (2024) — 数据高效选择策略</p></div></a></div>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="扩展阅读-1"><a data-card="" href="#扩展阅读-1" class="peer">扩展阅读</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" rel="noreferrer noopener" target="_blank">Alpaca: A Strong, Replicable Instruction-Following Model</a> — Stanford (2023), 指令微调的早期里程碑</li>
<li><a href="https://arxiv.org/abs/2410.01220" rel="noreferrer noopener" target="_blank">GRAPE: Generalizing Robot Policy via Preference Alignment</a> — 2025, 适配基座模型分布的数据选择</li>
<li><a href="https://arxiv.org/abs/2304.12244" rel="noreferrer noopener" target="_blank">WizardLM: Empowering Large Language Models to Follow Complex Instructions</a> — Xu et al. (2023)</li>
</ul>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="第3课偏好对齐dpo-及其变体"><a data-card="" href="#第3课偏好对齐dpo-及其变体" class="peer">第3课：偏好对齐——DPO 及其变体</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="核心论文-2"><a data-card="" href="#核心论文-2" class="peer">核心论文</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<div class="grid grid-cols-2 gap-3 @container"><a href="https://arxiv.org/abs/2305.18290" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">1. Direct Preference Optimization: Your Language Model is Secretly a Reward Model</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Rafailov et al. (NeurIPS 2023) — DPO 奠基论文，必读</p></div></a><a href="https://arxiv.org/abs/2405.14734" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">2. SimPO: Simple Preference Optimization with a Reference-Free Reward</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Meng et al. (NeurIPS 2024) — 无参考模型对齐，&lt;10B 模型 AlpacaEval 2 排名第一</p></div></a><a href="https://arxiv.org/abs/2402.01306" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">3. KTO: Model Alignment as Prospect Theoretic Optimization</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Ethayarajh et al. (2024) — 行为经济学与 LLM 对齐的关联</p></div></a><a href="https://arxiv.org/abs/2406.09279" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">4. Unpacking DPO and PPO: Disentangling Best Practices</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Ivison et al. (2024.06) — DPO 与 PPO 的系统性控制实验</p></div></a><a href="https://arxiv.org/abs/2410.15595" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">5. A Comprehensive Survey of Direct Preference Optimization</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>(2024.10, 更新至2025) — 覆盖 20+ DPO 变体的综述</p></div></a></div>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="扩展阅读-2"><a data-card="" href="#扩展阅读-2" class="peer">扩展阅读</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><a href="https://arxiv.org/abs/2403.07691" rel="noreferrer noopener" target="_blank">ORPO: Monolithic Preference Optimization without Reference Model</a> — Hong et al. (2024), 将 SFT 和对齐合并为单一损失</li>
<li><a href="https://arxiv.org/abs/2310.12036" rel="noreferrer noopener" target="_blank">IPO: A General Theoretical Paradigm to Understand Learning from Human Preferences</a> — Azar et al. (Google DeepMind, 2023)</li>
<li><a href="https://arxiv.org/abs/2212.08073" rel="noreferrer noopener" target="_blank">Constitutional AI: Harmlessness from AI Feedback</a> — Bai et al. (Anthropic, 2022)</li>
</ul>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="第4课rlhf-原理与推理强化学习grpo"><a data-card="" href="#第4课rlhf-原理与推理强化学习grpo" class="peer">第4课：RLHF 原理与推理强化学习（GRPO）</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="核心论文-3"><a data-card="" href="#核心论文-3" class="peer">核心论文</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<div class="grid grid-cols-2 gap-3 @container"><a href="https://arxiv.org/abs/2203.02155" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">1. Training Language Models to Follow Instructions with Human Feedback</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Ouyang et al. (OpenAI, 2022) — InstructGPT，确立 RLHF 三阶段流程</p></div></a><a href="https://arxiv.org/abs/2501.12948" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">2. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via RL</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>DeepSeek-AI (2025.01) — 推理涌现的里程碑论文</p></div></a><a href="https://arxiv.org/abs/2402.03300" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">3. DeepSeekMath: Pushing the Limits of Mathematical Reasoning</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Shao et al. (2024.02) — GRPO 算法的原始论文</p></div></a><a href="https://arxiv.org/abs/2408.03314" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">4. Scaling LLM Test-Time Compute Optimally</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Snell et al. (2024.08) — 测试时计算扩展的理论基础</p></div></a><a href="https://arxiv.org/abs/2503.14476" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">5. DAPO: An Open-Source LLM Reinforcement Learning System at Scale</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Yu et al. (ByteDance, 2025.03) — GRPO 的实用改进，完全开源</p></div></a></div>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="扩展阅读-3"><a data-card="" href="#扩展阅读-3" class="peer">扩展阅读</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><a href="https://arxiv.org/abs/2310.12773" rel="noreferrer noopener" target="_blank">Safe RLHF: Safe Reinforcement Learning from Human Feedback</a> — 北京大学对齐团队 (ICLR 2024), 解耦有用性和无害性</li>
<li><a href="https://arxiv.org/abs/2505.09388" rel="noreferrer noopener" target="_blank">Qwen3 Technical Report</a> — Qwen Team (2025), Section 4.2 详述四阶段后训练</li>
<li><a href="https://arxiv.org/abs/2503.20783" rel="noreferrer noopener" target="_blank">Dr. GRPO</a> — MIT (2025), 去除长度偏差的 GRPO 改进</li>
<li><a href="https://arxiv.org/abs/2501.03262" rel="noreferrer noopener" target="_blank">REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models</a> — Hu (2025)</li>
<li><a href="https://arxiv.org/abs/1707.06347" rel="noreferrer noopener" target="_blank">Proximal Policy Optimization Algorithms</a> — Schulman et al. (OpenAI, 2017), PPO 原始论文</li>
</ul>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="第5课模型压缩部署优化与能力扩展"><a data-card="" href="#第5课模型压缩部署优化与能力扩展" class="peer">第5课：模型压缩、部署优化与能力扩展</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="核心论文-4"><a data-card="" href="#核心论文-4" class="peer">核心论文</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<div class="grid grid-cols-2 gap-3 @container"><a href="https://arxiv.org/abs/2210.17323" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">1. GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Frantar et al. (2023) — 基于 Hessian 信息的大模型量化方法</p></div></a><a href="https://arxiv.org/abs/2306.00978" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">2. AWQ: Activation-aware Weight Quantization</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Lin et al. (MLSys 2024) — 激活感知量化，保护重要通道</p></div></a><a href="https://arxiv.org/abs/2304.08485" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">3. Visual Instruction Tuning (LLaVA)</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Liu et al. (NeurIPS 2023) — VLM 两阶段训练范式</p></div></a><a href="https://arxiv.org/abs/2409.00920" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">4. ToolACE: Winning the Points of LLM Function Calling</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>Liu et al. (ICLR 2025) — 8B 模型函数调用超越 GPT-4</p></div></a><a href="https://arxiv.org/abs/2501.12948" rel="noreferrer noopener" target="_blank" data-card="true" class="block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80"><h3 class="not-prose mb-1 text-sm font-medium">5. DeepSeek-R1 (蒸馏部分)</h3><div class="text-sm text-fd-muted-foreground prose-no-margin empty:hidden"><p>DeepSeek-AI (2025.01) — 将推理能力蒸馏到小模型</p></div></a></div>
<h3 class="flex scroll-m-28 flex-row items-center gap-2" id="扩展阅读-4"><a data-card="" href="#扩展阅读-4" class="peer">扩展阅读</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p><strong>量化方向</strong>：</p>
<ul>
<li><a href="https://arxiv.org/abs/2208.07339" rel="noreferrer noopener" target="_blank">LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a> — Dettmers et al. (2022)</li>
<li><a href="https://arxiv.org/abs/2306.07629" rel="noreferrer noopener" target="_blank">SqueezeLLM: Dense-and-Sparse Quantization</a> — Kim et al. (2023)</li>
</ul>
<p><strong>多模态方向</strong>：</p>
<ul>
<li><a href="https://arxiv.org/abs/2408.03326" rel="noreferrer noopener" target="_blank">LLaVA-OneVision: Easy Visual Task Transfer</a> — Li et al. (2024)</li>
<li><a href="https://arxiv.org/abs/2312.14238" rel="noreferrer noopener" target="_blank">InternVL: Scaling Up Vision Foundation Models</a> — Chen et al. (2023)</li>
<li><a href="https://arxiv.org/abs/2312.00849" rel="noreferrer noopener" target="_blank">RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment</a> — Yu et al. (2023)</li>
</ul>
<p><strong>工具使用方向</strong>：</p>
<ul>
<li><a href="https://arxiv.org/abs/2305.15334" rel="noreferrer noopener" target="_blank">Gorilla: Large Language Model Connected with Massive APIs</a> — Patil et al. (2023)</li>
<li><a href="https://arxiv.org/abs/2302.04761" rel="noreferrer noopener" target="_blank">Toolformer: Language Models Can Teach Themselves to Use Tools</a> — Schick et al. (2023)</li>
<li><a href="https://arxiv.org/abs/2210.03629" rel="noreferrer noopener" target="_blank">ReAct: Synergizing Reasoning and Acting in Language Models</a> — Yao et al. (2022)</li>
</ul>
<p><strong>知识蒸馏方向</strong>：</p>
<ul>
<li><a href="https://arxiv.org/abs/1503.02531" rel="noreferrer noopener" target="_blank">Distilling the Knowledge in a Neural Network</a> — Hinton et al. (2015), 经典蒸馏论文</li>
</ul>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="开源框架与工具"><a data-card="" href="#开源框架与工具" class="peer">开源框架与工具</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>框架</th><th>用途</th><th>GitHub</th><th>课程中使用</th></tr></thead><tbody><tr><td>Hugging Face Transformers</td><td>模型加载与推理</td><td><a href="https://github.com/huggingface/transformers" rel="noreferrer noopener" target="_blank">github.com/huggingface/transformers</a></td><td>全部课次</td></tr><tr><td>TRL</td><td>SFT/DPO/GRPO 训练</td><td><a href="https://github.com/huggingface/trl" rel="noreferrer noopener" target="_blank">github.com/huggingface/trl</a></td><td>第1-4课</td></tr><tr><td>PEFT</td><td>LoRA/QLoRA 适配器</td><td><a href="https://github.com/huggingface/peft" rel="noreferrer noopener" target="_blank">github.com/huggingface/peft</a></td><td>第1-4课</td></tr><tr><td>bitsandbytes</td><td>量化工具</td><td><a href="https://github.com/bitsandbytes-foundation/bitsandbytes" rel="noreferrer noopener" target="_blank">github.com/bitsandbytes-foundation/bitsandbytes</a></td><td>第1、5课</td></tr><tr><td>LLaMA-Factory</td><td>一站式微调框架</td><td><a href="https://github.com/hiyouga/LLaMA-Factory" rel="noreferrer noopener" target="_blank">github.com/hiyouga/LLaMA-Factory</a></td><td>第5课选做</td></tr><tr><td>vLLM</td><td>高性能推理引擎</td><td><a href="https://github.com/vllm-project/vllm" rel="noreferrer noopener" target="_blank">github.com/vllm-project/vllm</a></td><td>第4-5课</td></tr><tr><td>OpenRLHF</td><td>分布式 RLHF 框架</td><td><a href="https://github.com/OpenRLHF/OpenRLHF" rel="noreferrer noopener" target="_blank">github.com/OpenRLHF/OpenRLHF</a></td><td>参考</td></tr><tr><td>veRL</td><td>大规模 GRPO 训练</td><td><a href="https://github.com/volcengine/verl" rel="noreferrer noopener" target="_blank">github.com/volcengine/verl</a></td><td>参考</td></tr><tr><td>Outlines</td><td>约束解码</td><td><a href="https://github.com/outlines-dev/outlines" rel="noreferrer noopener" target="_blank">github.com/outlines-dev/outlines</a></td><td>第5课</td></tr></tbody></table></div>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="数据集索引"><a data-card="" href="#数据集索引" class="peer">数据集索引</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>数据集</th><th>类型</th><th>规模</th><th>课次</th><th>链接</th></tr></thead><tbody><tr><td>UltraChat-200K</td><td>多轮对话</td><td>200K</td><td>第1课</td><td><a href="https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr><tr><td>UltraFeedback</td><td>偏好数据</td><td>64K</td><td>第3课</td><td><a href="https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr><tr><td>GSM8K</td><td>数学推理</td><td>8.8K</td><td>第4课</td><td><a href="https://huggingface.co/datasets/openai/gsm8k" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr><tr><td>COIG-CQIA</td><td>中文指令</td><td>多种</td><td>第2课</td><td><a href="https://huggingface.co/datasets/m-a-p/COIG-CQIA" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr><tr><td>PKU-SafeRLHF</td><td>安全偏好</td><td>361K</td><td>期末项目</td><td><a href="https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr><tr><td>LLaVA-Instruct-150K</td><td>视觉指令</td><td>150K</td><td>期末项目</td><td><a href="https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr><tr><td>Glaive FC v2</td><td>函数调用</td><td>113K</td><td>第5课/期末</td><td><a href="https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2" rel="noreferrer noopener" target="_blank">HuggingFace</a></td></tr></tbody></table></div>
<hr/>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="推荐学习路径"><a data-card="" href="#推荐学习路径" class="peer">推荐学习路径</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<div class="flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md" style="--callout-color:var(--color-fd-info, var(--color-fd-muted))"><div role="none" class="w-0.5 bg-(--callout-color)/50 rounded-sm"></div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div class="flex flex-col gap-2 min-w-0 flex-1"><div class="text-fd-muted-foreground prose-no-margin empty:hidden"><p><strong>论文阅读建议</strong>：每课精读 1-2 篇核心论文（标记为&quot;必读&quot;的），其余泛读 Abstract 和实验部分。整个课程建议精读 8-10 篇论文，泛读 15-20 篇。</p></div></div></div>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>阶段</th><th>重点论文</th><th>阅读优先级</th></tr></thead><tbody><tr><td>入门（第1-2课）</td><td>LoRA, QLoRA, LIMA</td><td>必读</td></tr><tr><td>对齐（第3课）</td><td>DPO, SimPO</td><td>必读</td></tr><tr><td>推理（第4课）</td><td>DeepSeek-R1, GRPO</td><td>必读</td></tr><tr><td>部署（第5课）</td><td>GPTQ 或 AWQ (选一), LLaVA</td><td>推荐</td></tr><tr><td>综合（第6课）</td><td>Tülu 3, Qwen3 Technical Report</td><td>必读</td></tr></tbody></table></div></div><div class="flex flex-row flex-wrap items-center justify-between gap-4 empty:hidden"></div><div class="@container grid gap-4 pb-6 grid-cols-2"><a class="flex flex-col gap-2 rounded-lg border p-4 text-sm transition-colors hover:bg-fd-accent/80 hover:text-fd-accent-foreground @max-lg:col-span-full" href="/docs/resources/gpu-cost-guide"><div class="inline-flex items-center gap-1.5 font-medium"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide -mx-1 size-4 shrink-0 rtl:rotate-180"><path d="m15 18-6-6 6-6"></path></svg><p>GPU 配置与费用估算</p></div><p class="text-fd-muted-foreground truncate">各课次 GPU 配置推荐、AutoDL 费用明细、省钱技巧与替代平台</p></a><a class="flex flex-col gap-2 rounded-lg border p-4 text-sm transition-colors hover:bg-fd-accent/80 hover:text-fd-accent-foreground @max-lg:col-span-full text-end" href="/docs/resources/grading"><div class="inline-flex items-center gap-1.5 font-medium flex-row-reverse"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide -mx-1 size-4 shrink-0 rtl:rotate-180"><path d="m9 18 6-6-6-6"></path></svg><p>评分标准</p></div><p class="text-fd-muted-foreground truncate">课程考核方式、各项评分细则与评分标准详细说明</p></a></div></article><div id="nd-toc" class="fixed bottom-0 pt-12 pb-2 pr-(--removed-body-scroll-bar-size,0) max-xl:hidden" style="top:calc(var(--fd-banner-height) + var(--fd-nav-height));inset-inline-end:max(var(--fd-layout-offset), calc(50vw - var(--fd-sidebar-width)/2 - var(--fd-page-width)/2))"><div class="flex h-full w-(--fd-toc-width) max-w-full flex-col pe-4"><h3 class="inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-4"><path d="M15 18H3"></path><path d="M17 6H3"></path><path d="M21 12H3"></path></svg>On this page</h3><div class="relative min-h-0 text-sm ms-px overflow-auto [scrollbar-width:none] [mask-image:linear-gradient(to_bottom,transparent,white_16px,white_calc(100%-16px),transparent)] py-3"><div role="none" class="absolute top-(--fd-top) h-(--fd-height) w-px bg-fd-primary transition-all"></div><div class="flex flex-col border-s border-fd-foreground/10"><a data-active="false" href="#教材与综合资源" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">教材与综合资源</a><a data-active="false" href="#第1课后训练概述与监督微调基础" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">第1课：后训练概述与监督微调基础</a><a data-active="false" href="#核心论文" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">核心论文</a><a data-active="false" href="#扩展阅读" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">扩展阅读</a><a data-active="false" href="#第2课sft-进阶与数据工程" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">第2课：SFT 进阶与数据工程</a><a data-active="false" href="#核心论文-1" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">核心论文</a><a data-active="false" href="#扩展阅读-1" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">扩展阅读</a><a data-active="false" href="#第3课偏好对齐dpo-及其变体" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">第3课：偏好对齐——DPO 及其变体</a><a data-active="false" href="#核心论文-2" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">核心论文</a><a data-active="false" href="#扩展阅读-2" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">扩展阅读</a><a data-active="false" href="#第4课rlhf-原理与推理强化学习grpo" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">第4课：RLHF 原理与推理强化学习（GRPO）</a><a data-active="false" href="#核心论文-3" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">核心论文</a><a data-active="false" href="#扩展阅读-3" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">扩展阅读</a><a data-active="false" href="#第5课模型压缩部署优化与能力扩展" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">第5课：模型压缩、部署优化与能力扩展</a><a data-active="false" href="#核心论文-4" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">核心论文</a><a data-active="false" href="#扩展阅读-4" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-6">扩展阅读</a><a data-active="false" href="#开源框架与工具" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">开源框架与工具</a><a data-active="false" href="#数据集索引" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">数据集索引</a><a data-active="false" href="#推荐学习路径" class="prose py-1.5 text-sm text-fd-muted-foreground transition-colors [overflow-wrap:anywhere] first:pt-0 last:pb-0 data-[active=true]:text-fd-primary ps-3">推荐学习路径</a></div></div></div></div></div><!--$--><!--/$--></main><script src="/_next/static/chunks/webpack-d558155d46ca9095.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7921,[\"716\",\"static/chunks/716-8b6c239d56add41d.js\",\"98\",\"static/chunks/98-71e6ffba5da79e51.js\",\"177\",\"static/chunks/app/layout-438f3f1dcf44f88c.js\"],\"\"]\n3:I[8295,[\"716\",\"static/chunks/716-8b6c239d56add41d.js\",\"98\",\"static/chunks/98-71e6ffba5da79e51.js\",\"177\",\"static/chunks/app/layout-438f3f1dcf44f88c.js\"],\"RootProvider\"]\n4:I[1409,[],\"\"]\n5:I[1813,[],\"\"]\n6:I[6053,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"TreeContextProvider\"]\nb:I[323,[],\"\"]\n:HL[\"/_next/static/media/bb3ef058b751a6ad-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/edef1a271f97a8ec-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/d0f7ca2a7022be00.css\",\"style\"]\n:HL[\"/_next/static/css/62a6e77bcc5afb05.css\",\"style\"]\n:HL[\"/_next/static/css/4cd23781d18a52d3.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"ch1b6kq8kuWTUda8E58Ln\",\"p\":\"\",\"c\":[\"\",\"docs\",\"resources\",\"references\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"docs\",{\"children\":[[\"slug\",\"resources/references\",\"oc\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d0f7ca2a7022be00.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/62a6e77bcc5afb05.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4cd23781d18a52d3.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"className\":\"__variable_51740a __variable_3c557b\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"$L2\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-6PZFJCKFSJ\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$L2\",null,{\"id\":\"google-analytics\",\"strategy\":\"afterInteractive\",\"children\":\"\\n            window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-6PZFJCKFSJ');\\n          \"}]]}],[\"$\",\"body\",null,{\"className\":\"flex min-h-screen flex-col\",\"children\":[\"$\",\"$L3\",null,{\"search\":{\"options\":{\"type\":\"static\"}},\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]]}],{\"children\":[\"docs\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L6\",null,{\"tree\":{\"$id\":\"root\",\"name\":\"课程内容\",\"children\":[{\"$id\":\"#0\",\"type\":\"separator\",\"icon\":\"$undefined\",\"name\":\"课程内容\"},{\"$id\":\"index.mdx\",\"type\":\"page\",\"name\":\"课程总览\",\"description\":\"大语言模型后训练实践——北京大学软件与微电子学院研究生课程\",\"icon\":\"$undefined\",\"url\":\"/docs\",\"$ref\":{\"file\":\"index.mdx\"}},{\"$id\":\"#2\",\"type\":\"separator\",\"icon\":\"$undefined\",\"name\":\"讲座\"},{\"type\":\"folder\",\"name\":\"第1课：后训练概述与SFT基础\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-1/index.mdx\",\"type\":\"page\",\"name\":\"第1课：后训练概述与监督微调基础\",\"description\":\"理解后训练在 LLM 开发流程中的位置和核心方法体系，掌握 SFT 训练循环，配置 LoRA/QLoRA 进行参数高效训练\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1\",\"$ref\":{\"file\":\"lecture-1/index.mdx\"}},{\"$id\":\"lecture-1/post-training-overview.mdx\",\"type\":\"page\",\"name\":\"1.1 后训练的定义与基本流程\",\"description\":\"理解 LLM 开发的三阶段流程，掌握后训练的核心方法体系，了解 Tülu 3 和 Qwen3 的后训练实践\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/post-training-overview\",\"$ref\":{\"file\":\"lecture-1/post-training-overview.mdx\"}},{\"$id\":\"lecture-1/sft-core-concepts.mdx\",\"type\":\"page\",\"name\":\"1.2 监督微调核心概念\",\"description\":\"掌握 ChatML 和 Llama 聊天模板格式，理解掩码损失（Masked Loss）的原理，了解数据质量的重要性\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/sft-core-concepts\",\"$ref\":{\"file\":\"lecture-1/sft-core-concepts.mdx\"}},{\"$id\":\"lecture-1/parameter-efficient-ft.mdx\",\"type\":\"page\",\"name\":\"1.3 参数高效微调\",\"description\":\"掌握 LoRA 和 QLoRA 的原理与实践，理解参数高效微调的必要性和显存优化策略\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/parameter-efficient-ft\",\"$ref\":{\"file\":\"lecture-1/parameter-efficient-ft.mdx\"}},{\"$id\":\"lecture-1/evaluation-methods.mdx\",\"type\":\"page\",\"name\":\"1.4 模型评估方法\",\"description\":\"了解 LLM 后训练的主流评估方法：LLM-as-Judge、人类偏好排行榜、能力专项基准和安全评估\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/evaluation-methods\",\"$ref\":{\"file\":\"lecture-1/evaluation-methods.mdx\"}},{\"$id\":\"lecture-1/papers.mdx\",\"type\":\"page\",\"name\":\"第1课 推荐论文\",\"description\":\"第1课推荐阅读的 5 篇核心论文：Tülu 3、LoRA、QLoRA、LIMA、MAGPIE\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/papers\",\"$ref\":{\"file\":\"lecture-1/papers.mdx\"}},{\"$id\":\"lecture-1/lab.mdx\",\"type\":\"page\",\"name\":\"实验1：微调 Qwen3-1.7B 为指令跟随助手\",\"description\":\"使用 QLoRA 和 SFTTrainer 将 Qwen3-1.7B 基座模型微调为指令跟随助手的完整实验\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-1/lab\",\"$ref\":{\"file\":\"lecture-1/lab.mdx\"}}],\"$id\":\"lecture-1\",\"$ref\":{\"metaFile\":\"lecture-1/meta.json\"}},{\"type\":\"folder\",\"name\":\"第2课：SFT进阶\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-2/index.mdx\",\"type\":\"page\",\"name\":\"第2课：SFT 进阶——数据工程与指令微调深入\",\"description\":\"掌握指令数据集的构建与质量控制方法，理解数据混合策略，实践 LLM-as-Judge 系统化评估\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2\",\"$ref\":{\"file\":\"lecture-2/index.mdx\"}},{\"$id\":\"lecture-2/instruction-datasets.mdx\",\"type\":\"page\",\"name\":\"2.1 指令数据集构建方法\",\"description\":\"从 Self-Instruct 到 MAGPIE 的指令数据集技术演进，数据质量控制方法，数据混合策略\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/instruction-datasets\",\"$ref\":{\"file\":\"lecture-2/instruction-datasets.mdx\"}},{\"$id\":\"lecture-2/sft-hyperparameters.mdx\",\"type\":\"page\",\"name\":\"2.2 SFT 超参数实践指南\",\"description\":\"基于 Pareja 等（2024）的系统实验结果，掌握 SFT 核心超参数的选择方法和常见问题诊断\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/sft-hyperparameters\",\"$ref\":{\"file\":\"lecture-2/sft-hyperparameters.mdx\"}},{\"$id\":\"lecture-2/llm-as-judge.mdx\",\"type\":\"page\",\"name\":\"2.3 LLM-as-Judge 评估方法\",\"description\":\"深入理解 LLM-as-Judge 评估框架，掌握 MT-Bench 评判模板，了解位置偏差和评委模型选择\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/llm-as-judge\",\"$ref\":{\"file\":\"lecture-2/llm-as-judge.mdx\"}},{\"$id\":\"lecture-2/papers.mdx\",\"type\":\"page\",\"name\":\"第2课 推荐论文\",\"description\":\"第2课推荐阅读的 5 篇核心论文：SFT 超参数指南、Self-Instruct、MT-Bench、UltraChat、Deita\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/papers\",\"$ref\":{\"file\":\"lecture-2/papers.mdx\"}},{\"$id\":\"lecture-2/lab.mdx\",\"type\":\"page\",\"name\":\"实验2：构建领域定制 SFT 模型并系统评估\",\"description\":\"从数据分析到模型训练到 LLM-as-Judge 评估的完整指令微调实验，含消融实验\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-2/lab\",\"$ref\":{\"file\":\"lecture-2/lab.mdx\"}}],\"$id\":\"lecture-2\",\"$ref\":{\"metaFile\":\"lecture-2/meta.json\"}},{\"type\":\"folder\",\"name\":\"第3课：偏好对齐DPO\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-3/index.mdx\",\"type\":\"page\",\"name\":\"第3课：偏好对齐——DPO 及其变体\",\"description\":\"理解为什么仅靠 SFT 不足以实现对齐，从 RLHF 目标推导 DPO 损失函数，实现 DPO 训练，并对 DPO 与 SimPO 进行实证比较\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3\",\"$ref\":{\"file\":\"lecture-3/index.mdx\"}},{\"$id\":\"lecture-3/alignment-problem.mdx\",\"type\":\"page\",\"name\":\"3.1 对齐问题：为什么仅靠 SFT 不够\",\"description\":\"SFT 教会模型'说什么'，但未教会它'如何选择'。人类偏好本质上是比较性的，偏好优化直接捕获这一信号。\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/alignment-problem\",\"$ref\":{\"file\":\"lecture-3/alignment-problem.mdx\"}},{\"$id\":\"lecture-3/dpo-derivation.mdx\",\"type\":\"page\",\"name\":\"3.2 DPO 数学推导\",\"description\":\"从 RLHF 目标到 DPO 损失函数的完整四步推导，包括闭式最优策略、奖励重参数化和 Bradley-Terry 代入\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/dpo-derivation\",\"$ref\":{\"file\":\"lecture-3/dpo-derivation.mdx\"}},{\"$id\":\"lecture-3/dpo-variants.mdx\",\"type\":\"page\",\"name\":\"3.3 DPO 变体\",\"description\":\"SimPO、KTO、ORPO、IPO 等 DPO 变体的设计理念、数学公式与适用场景比较\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/dpo-variants\",\"$ref\":{\"file\":\"lecture-3/dpo-variants.mdx\"}},{\"$id\":\"lecture-3/practical-considerations.mdx\",\"type\":\"page\",\"name\":\"3.4 实践考量\",\"description\":\"在线 vs 离线 DPO、beta 参数敏感性分析、偏好数据质量、当前领域趋势\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/practical-considerations\",\"$ref\":{\"file\":\"lecture-3/practical-considerations.mdx\"}},{\"$id\":\"lecture-3/papers.mdx\",\"type\":\"page\",\"name\":\"第3课推荐论文\",\"description\":\"DPO、SimPO、KTO、DPO vs PPO 对比实验、DPO 综述等 5 篇核心论文\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/papers\",\"$ref\":{\"file\":\"lecture-3/papers.mdx\"}},{\"$id\":\"lecture-3/lab.mdx\",\"type\":\"page\",\"name\":\"第3课实验：DPO 对齐与 SimPO 对比\",\"description\":\"使用 DPO 对齐 SFT 模型，与 SimPO 进行实证对比，涵盖偏好数据探索、训练、评估的完整流程\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-3/lab\",\"$ref\":{\"file\":\"lecture-3/lab.mdx\"}}],\"$id\":\"lecture-3\",\"$ref\":{\"metaFile\":\"lecture-3/meta.json\"}},{\"type\":\"folder\",\"name\":\"第4课：RLHF与GRPO\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-4/index.mdx\",\"type\":\"page\",\"name\":\"第4课：RLHF 原理与推理强化学习（GRPO）\",\"description\":\"理解完整的 RLHF 流程，掌握 GRPO 算法，使用可验证奖励复现迷你 DeepSeek-R1-Zero 实验，观察推理能力的涌现\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4\",\"$ref\":{\"file\":\"lecture-4/index.mdx\"}},{\"$id\":\"lecture-4/rlhf-pipeline.mdx\",\"type\":\"page\",\"name\":\"4.1 经典 RLHF 流程\",\"description\":\"InstructGPT 三阶段流程、奖励模型训练、PPO 核心组件、四模型架构及常见不稳定性\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/rlhf-pipeline\",\"$ref\":{\"file\":\"lecture-4/rlhf-pipeline.mdx\"}},{\"$id\":\"lecture-4/grpo-reasoning.mdx\",\"type\":\"page\",\"name\":\"4.2 GRPO 与推理涌现\",\"description\":\"DeepSeek-R1-Zero 里程碑、GRPO 四步算法详解、RLVR 可验证奖励、DeepSeek-R1 完整流程\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/grpo-reasoning\",\"$ref\":{\"file\":\"lecture-4/grpo-reasoning.mdx\"}},{\"$id\":\"lecture-4/grpo-improvements.mdx\",\"type\":\"page\",\"name\":\"4.3 GRPO 改进与测试时计算\",\"description\":\"DAPO、Dr. GRPO、REINFORCE++ 等改进方法，以及测试时计算扩展的概念和与 o1/o3/R1 的连接\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/grpo-improvements\",\"$ref\":{\"file\":\"lecture-4/grpo-improvements.mdx\"}},{\"$id\":\"lecture-4/rlhf-engineering.mdx\",\"type\":\"page\",\"name\":\"4.4 RLHF 工程工具\",\"description\":\"TRL、OpenRLHF、veRL 等 RLHF/GRPO 训练工具的功能、架构和使用场景对比\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/rlhf-engineering\",\"$ref\":{\"file\":\"lecture-4/rlhf-engineering.mdx\"}},{\"$id\":\"lecture-4/papers.mdx\",\"type\":\"page\",\"name\":\"第4课推荐论文\",\"description\":\"InstructGPT、DeepSeek-R1、DeepSeekMath、Snell et al.、DAPO、Safe RLHF、Qwen3 等 7 篇核心论文\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/papers\",\"$ref\":{\"file\":\"lecture-4/papers.mdx\"}},{\"$id\":\"lecture-4/lab.mdx\",\"type\":\"page\",\"name\":\"第4课实验：迷你 DeepSeek-R1-Zero\",\"description\":\"使用 GRPO 训练 Qwen3-1.7B-Base 进行数学推理，观察推理能力的涌现过程，并与蒸馏模型和 Qwen3 思考模式对比\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-4/lab\",\"$ref\":{\"file\":\"lecture-4/lab.mdx\"}}],\"$id\":\"lecture-4\",\"$ref\":{\"metaFile\":\"lecture-4/meta.json\"}},{\"type\":\"folder\",\"name\":\"第5课：压缩部署与扩展\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-5/index.mdx\",\"type\":\"page\",\"name\":\"第5课：模型压缩、部署优化与能力扩展\",\"description\":\"掌握模型量化的原理与实践（INT8/INT4/GPTQ/AWQ），理解知识蒸馏在后训练中的角色，了解多模态和工具使用等能力扩展方法\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5\",\"$ref\":{\"file\":\"lecture-5/index.mdx\"}},{\"$id\":\"lecture-5/quantization.mdx\",\"type\":\"page\",\"name\":\"5.1 模型量化\",\"description\":\"深入理解模型量化的原理、主流 PTQ 方法（INT8/INT4/GPTQ/AWQ）与 QAT，掌握精度-速度-显存的权衡\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/quantization\",\"$ref\":{\"file\":\"lecture-5/quantization.mdx\"}},{\"$id\":\"lecture-5/knowledge-distillation.mdx\",\"type\":\"page\",\"name\":\"5.2 知识蒸馏\",\"description\":\"理解经典知识蒸馏范式、LLM 时代的蒸馏实践（DeepSeek-R1-Distill、Qwen3 思考模式融合），以及蒸馏与 RL 训练的权衡\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/knowledge-distillation\",\"$ref\":{\"file\":\"lecture-5/knowledge-distillation.mdx\"}},{\"$id\":\"lecture-5/capability-extensions.mdx\",\"type\":\"page\",\"name\":\"5.3 能力扩展概览\",\"description\":\"多模态后训练（VLM/LLaVA）、工具使用与智能体（函数调用/MCP）、知识编辑（参数编辑/RAG）三大能力扩展方向\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/capability-extensions\",\"$ref\":{\"file\":\"lecture-5/capability-extensions.mdx\"}},{\"$id\":\"lecture-5/papers.mdx\",\"type\":\"page\",\"name\":\"第5课 推荐论文\",\"description\":\"GPTQ、AWQ、LLaVA、ToolACE、DeepSeek-R1 等 5 篇核心论文，涵盖量化、多模态、工具使用与蒸馏\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/papers\",\"$ref\":{\"file\":\"lecture-5/papers.mdx\"}},{\"$id\":\"lecture-5/lab.mdx\",\"type\":\"page\",\"name\":\"第5课 上机实验\",\"description\":\"量化实验（必做）：多精度加载 Qwen3-8B 并评估压缩影响；能力扩展选做（三选一）：蒸馏分析、多模态实验、工具调用实验\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-5/lab\",\"$ref\":{\"file\":\"lecture-5/lab.mdx\"}}],\"$id\":\"lecture-5\",\"$ref\":{\"metaFile\":\"lecture-5/meta.json\"}},{\"type\":\"folder\",\"name\":\"第6课：项目报告与总结\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"lecture-6/index.mdx\",\"type\":\"page\",\"name\":\"第6课：课程项目报告与总结\",\"description\":\"课程项目报告展示、评分标准，以及后训练技术全景回顾与前沿展望\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6\",\"$ref\":{\"file\":\"lecture-6/index.mdx\"}},{\"$id\":\"lecture-6/project-directions.mdx\",\"type\":\"page\",\"name\":\"推荐项目方向\",\"description\":\"7 个推荐的课程项目方向，涵盖数学推理、安全对齐、中文写作、代码推理、领域问答、视觉问答、工具调用智能体\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6/project-directions\",\"$ref\":{\"file\":\"lecture-6/project-directions.mdx\"}},{\"$id\":\"lecture-6/presentation-guide.mdx\",\"type\":\"page\",\"name\":\"演示指南与评分标准\",\"description\":\"项目演示的时间安排、内容要求、评分细则，以及高质量演示的实用技巧\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6/presentation-guide\",\"$ref\":{\"file\":\"lecture-6/presentation-guide.mdx\"}},{\"$id\":\"lecture-6/course-summary.mdx\",\"type\":\"page\",\"name\":\"课程总结与展望\",\"description\":\"后训练技术完整图谱回顾，从 SFT 到 GRPO 的完整路径，以及后训练领域的前沿研究方向\",\"icon\":\"$undefined\",\"url\":\"/docs/lecture-6/course-summary\",\"$ref\":{\"file\":\"lecture-6/course-summary.mdx\"}}],\"$id\":\"lecture-6\",\"$ref\":{\"metaFile\":\"lecture-6/meta.json\"}},{\"$id\":\"#9\",\"type\":\"separator\",\"icon\":\"$undefined\",\"name\":\"资源\"},{\"type\":\"folder\",\"name\":\"课程资源\",\"icon\":\"$undefined\",\"root\":\"$undefined\",\"defaultOpen\":\"$undefined\",\"description\":\"$undefined\",\"index\":\"$undefined\",\"children\":[{\"$id\":\"resources/setup-guide.mdx\",\"type\":\"page\",\"name\":\"环境配置指南\",\"description\":\"AutoDL 环境搭建、Colab Pro 替代方案、依赖安装、模型预下载、一键启动脚本与验证步骤\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/setup-guide\",\"$ref\":{\"file\":\"resources/setup-guide.mdx\"}},{\"$id\":\"resources/gpu-cost-guide.mdx\",\"type\":\"page\",\"name\":\"GPU 配置与费用估算\",\"description\":\"各课次 GPU 配置推荐、AutoDL 费用明细、省钱技巧与替代平台\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/gpu-cost-guide\",\"$ref\":{\"file\":\"resources/gpu-cost-guide.mdx\"}},{\"$id\":\"resources/references.mdx\",\"type\":\"page\",\"name\":\"完整参考文献\",\"description\":\"按课次整理的全部推荐论文、教材和在线资源\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/references\",\"$ref\":{\"file\":\"resources/references.mdx\"}},{\"$id\":\"resources/grading.mdx\",\"type\":\"page\",\"name\":\"评分标准\",\"description\":\"课程考核方式、各项评分细则与评分标准详细说明\",\"icon\":\"$undefined\",\"url\":\"/docs/resources/grading\",\"$ref\":{\"file\":\"resources/grading.mdx\"}}],\"$id\":\"resources\",\"$ref\":{\"metaFile\":\"resources/meta.json\"}}]},\"children\":\"$L7\"}]]}],{\"children\":[[\"slug\",\"resources/references\",\"oc\"],\"$L8\",{\"children\":[\"__PAGE__\",\"$L9\",{},null,false]},null,false]},null,false]},null,false],\"$La\",false]],\"m\":\"$undefined\",\"G\":[\"$b\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:I[4564,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"NavProvider\"]\nd:I[4196,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"Navbar\"]\ne:I[7326,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"default\"]\nf:I[140,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SearchToggle\"]\n10:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarTrigger\"]\n11:I[4196,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"LayoutBody\"]\n12:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"Sidebar\"]\n13:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static"])</script><script>self.__next_f.push([1,"/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarContentMobile\"]\n14:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarHeader\"]\n15:I[5461,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"ThemeToggle\"]\n16:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarViewport\"]\n17:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarItem\"]\n18:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarPageTree\"]\n19:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarFooter\"]\n1a:I[4196,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"CollapsibleControl\"]\n1b:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunk"])</script><script>self.__next_f.push([1,"s/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarContent\"]\n1c:I[9896,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"SidebarCollapseTrigger\"]\n1d:I[140,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"698\",\"static/chunks/698-2edc64166f51fb90.js\",\"997\",\"static/chunks/997-8062435351294ce8.js\",\"795\",\"static/chunks/795-2e60776a7ce82cea.js\",\"499\",\"static/chunks/app/docs/layout-8640be9db805fb1e.js\"],\"LargeSearchToggle\"]\n1f:I[3652,[],\"OutletBoundary\"]\n21:I[1293,[],\"AsyncMetadataOutlet\"]\n23:I[3652,[],\"ViewportBoundary\"]\n25:I[3652,[],\"MetadataBoundary\"]\n26:\"$Sreact.suspense\"\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"$Lc\",null,{\"transparentMode\":\"$undefined\",\"children\":[[\"$\",\"$Ld\",null,{\"className\":\"h-(--fd-nav-height) on-root:[--fd-nav-height:56px] md:on-root:[--fd-nav-height:0px] md:hidden\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center gap-2.5 font-semibold\",\"children\":\"LLM 后训练实践\"}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":\"$undefined\"}],[\"$\",\"$Lf\",null,{\"className\":\"p-2\",\"hideIfDisabled\":true}],[\"$\",\"$L10\",null,{\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [\u0026_svg]:size-4.5 p-2\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide\",\"children\":[[[\"$\",\"rect\",\"afitv7\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\"}],[\"$\",\"path\",\"fh3hqa\",{\"d\":\"M9 3v18\"}]],\"$undefined\"]}]}]]}],[\"$\",\"$L11\",null,{\"className\":\"md:[\u0026_#nd-page_article]:pt-12 xl:[--fd-toc-width:286px] xl:[\u0026_#nd-page_article]:px-8 md:[--fd-sidebar-width:268px] lg:[--fd-sidebar-width:286px]\",\"children\":[[\"$\",\"$L12\",null,{\"defaultOpenLevel\":\"$undefined\",\"prefetch\":\"$undefined\",\"Mobile\":[\"$\",\"$L13\",null,{\"children\":[[\"$\",\"$L14\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex text-fd-muted-foreground items-center gap-1.5\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-1\",\"children\":[]}],null,[\"$\",\"$L15\",null,{\"className\":\"p-0\",\"mode\":\"$undefined\"}],[\"$\",\"$L10\",null,{\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [\u0026_svg]:size-4.5 p-2\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide\",\"children\":[[[\"$\",\"rect\",\"afitv7\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\"}],[\"$\",\"path\",\"fh3hqa\",{\"d\":\"M9 3v18\"}]],\"$undefined\"]}]}]]}],false,\"$undefined\"]}],[\"$\",\"$L16\",null,{\"children\":[[[\"$\",\"$L17\",\"0\",{\"href\":\"/docs\",\"icon\":\"$undefined\",\"external\":\"$undefined\",\"className\":\"mb-4\",\"children\":\"课程内容\"}]],[\"$\",\"$L18\",null,{\"components\":\"$undefined\"}]]}],[\"$\",\"$L19\",null,{\"className\":\"empty:hidden\",\"children\":\"$undefined\"}]]}],\"Content\":[[\"$\",\"$L1a\",null,{}],[\"$\",\"$L1b\",null,{\"children\":[[\"$\",\"$L14\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"inline-flex text-[15px] items-center gap-2.5 font-medium me-auto\",\"children\":\"LLM 后训练实践\"}],\"$undefined\",[\"$\",\"$L1c\",null,{\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [\u0026_svg]:size-4.5 mb-auto text-fd-muted-foreground\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide\",\"children\":[[[\"$\",\"rect\",\"afitv7\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\"}],[\"$\",\"path\",\"fh3hqa\",{\"d\":\"M9 3v18\"}]],\"$undefined\"]}]}]]}],[\"$\",\"$L1d\",null,{\"hideIfDisabled\":true}],false,\"$undefined\"]}],\"$7:props:children:1:props:children:0:props:Mobile:props:children:1\",[\"$\",\"$L19\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex text-fd-muted-foreground items-center empty:hidden\",\"children\":[false,[],[\"$\",\"$L15\",null,{\"className\":\"ms-auto p-0\",\"mode\":\"$undefined\"}]]}],\"$undefined\"]}]]}]]}],false,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n9:[\"$\",\"$1\",\"c\",{\"children\":[\"$L1e\",null,[\"$\",\"$L1f\",null,{\"children\":[\"$L20\",[\"$\",\"$L21\",null,{\"promise\":\"$@22\"}]]}]]}]\na:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L23\",null,{\"children\":\"$L24\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L25\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$26\",null,{\"fallback\":null,\"children\":\"$L27\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"28:I[2853,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"TOCProvider\"]\n29:I[3448,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"PageTOCPopover\"]\n2a:I[3448,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"PageTOCPopoverTrigger\"]\n2b:I[3448,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"PageTOCPopoverContent\"]\n2c:I[2853,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"TOCScrollArea\"]\n2d:I[2853,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"TOCItems\"]\n2e:I[3448,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"PageBreadcrumb\"]\n"])</script><script>self.__next_f.push([1,"1e:[\"$\",\"$L28\",null,{\"toc\":[{\"depth\":2,\"url\":\"#教材与综合资源\",\"title\":\"教材与综合资源\"},{\"depth\":2,\"url\":\"#第1课后训练概述与监督微调基础\",\"title\":\"第1课：后训练概述与监督微调基础\"},{\"depth\":3,\"url\":\"#核心论文\",\"title\":\"核心论文\"},{\"depth\":3,\"url\":\"#扩展阅读\",\"title\":\"扩展阅读\"},{\"depth\":2,\"url\":\"#第2课sft-进阶与数据工程\",\"title\":\"第2课：SFT 进阶与数据工程\"},{\"depth\":3,\"url\":\"#核心论文-1\",\"title\":\"核心论文\"},{\"depth\":3,\"url\":\"#扩展阅读-1\",\"title\":\"扩展阅读\"},{\"depth\":2,\"url\":\"#第3课偏好对齐dpo-及其变体\",\"title\":\"第3课：偏好对齐——DPO 及其变体\"},{\"depth\":3,\"url\":\"#核心论文-2\",\"title\":\"核心论文\"},{\"depth\":3,\"url\":\"#扩展阅读-2\",\"title\":\"扩展阅读\"},{\"depth\":2,\"url\":\"#第4课rlhf-原理与推理强化学习grpo\",\"title\":\"第4课：RLHF 原理与推理强化学习（GRPO）\"},{\"depth\":3,\"url\":\"#核心论文-3\",\"title\":\"核心论文\"},{\"depth\":3,\"url\":\"#扩展阅读-3\",\"title\":\"扩展阅读\"},{\"depth\":2,\"url\":\"#第5课模型压缩部署优化与能力扩展\",\"title\":\"第5课：模型压缩、部署优化与能力扩展\"},{\"depth\":3,\"url\":\"#核心论文-4\",\"title\":\"核心论文\"},{\"depth\":3,\"url\":\"#扩展阅读-4\",\"title\":\"扩展阅读\"},{\"depth\":2,\"url\":\"#开源框架与工具\",\"title\":\"开源框架与工具\"},{\"depth\":2,\"url\":\"#数据集索引\",\"title\":\"数据集索引\"},{\"depth\":2,\"url\":\"#推荐学习路径\",\"title\":\"推荐学习路径\"}],\"single\":\"$undefined\",\"children\":[\"$\",\"div\",null,{\"id\":\"nd-page\",\"className\":\"flex flex-1 w-full mx-auto max-w-(--fd-page-width) pt-(--fd-tocnav-height) pe-(--fd-toc-width)\",\"children\":[[\"$\",\"$L29\",null,{\"children\":[[\"$\",\"$L2a\",null,{}],[\"$\",\"$L2b\",null,{\"children\":[\"$undefined\",[\"$\",\"$L2c\",null,{\"children\":[\"$\",\"$L2d\",null,{}]}],\"$undefined\"]}]]}],[\"$\",\"article\",null,{\"children\":[[\"$\",\"$L2e\",null,{}],[[\"$\",\"h1\",null,{\"ref\":\"$undefined\",\"children\":\"完整参考文献\",\"className\":\"text-[1.75em] font-semibold\"}],[\"$\",\"p\",null,{\"ref\":\"$undefined\",\"children\":\"按课次整理的全部推荐论文、教材和在线资源\",\"className\":\"mb-8 text-lg text-fd-muted-foreground\"}],[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"教材与综合资源\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#教材与综合资源\",\"className\":\"peer\",\"children\":\"教材与综合资源\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}],\"\\n\",[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"资源\"}],[\"$\",\"th\",null,{\"children\":\"作者\"}],[\"$\",\"th\",null,{\"children\":\"年份\"}],[\"$\",\"th\",null,{\"children\":\"说明\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2505.09388\",\"children\":\"Qwen3 Technical Report\"}]}],[\"$\",\"td\",null,{\"children\":\"Qwen Team\"}],[\"$\",\"td\",null,{\"children\":\"2025\"}],[\"$\",\"td\",null,{\"children\":\"Qwen3 系列完整技术报告，贯穿全课程\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://rlhfbook.com\",\"children\":\"Reinforcement Learning from Human Feedback\"}]}],[\"$\",\"td\",null,{\"children\":\"Nathan Lambert\"}],[\"$\",\"td\",null,{\"children\":\"2025\"}],[\"$\",\"td\",null,{\"children\":\"第一本 RLHF 综合教材，免费获取\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/huggingface/smol-course\",\"children\":\"Hugging Face smol-course\"}]}],[\"$\",\"td\",null,{\"children\":\"Hugging Face\"}],[\"$\",\"td\",null,{\"children\":\"2024\"}],[\"$\",\"td\",null,{\"children\":\"开源实践迷你课程，涵盖 SFT、DPO、VLM\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/huggingface/alignment-handbook\",\"children\":\"Hugging Face Alignment Handbook\"}]}],[\"$\",\"td\",null,{\"children\":\"Hugging Face\"}],[\"$\",\"td\",null,{\"children\":\"2024\"}],[\"$\",\"td\",null,{\"children\":\"生产级 SFT → DPO/ORPO 流程方案\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://cs336.stanford.edu/\",\"children\":\"Stanford CS336: Language Modeling from Scratch\"}]}],[\"$\",\"td\",null,{\"children\":\"Stanford\"}],[\"$\",\"td\",null,{\"children\":\"2025\"}],[\"$\",\"td\",null,{\"children\":\"作业5涵盖对齐与推理 RL\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://www.deeplearning.ai/\",\"children\":\"Intro to Post-Training\"}]}],[\"$\",\"td\",null,{\"children\":\"DeepLearning.AI\"}],[\"$\",\"td\",null,{\"children\":\"2025\"}],[\"$\",\"td\",null,{\"children\":\"5模块视频课程\"}]]}]]}]]}]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"第1课后训练概述与监督微调基础\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#第1课后训练概述与监督微调基础\",\"className\":\"peer\",\"children\":\"第1课：后训练概述与监督微调基础\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[\"$L2f\",\"$L30\"],\"$undefined\"]}]]}],\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\",\"\\n\",\"$L47\",\"\\n\",\"$L48\",\"\\n\",\"$L49\",\"\\n\",\"$L4a\",\"\\n\",\"$L4b\",\"\\n\",\"$L4c\",\"\\n\",\"$L4d\",\"\\n\",\"$L4e\",\"\\n\",\"$L4f\",\"\\n\",\"$L50\",\"\\n\",\"$L51\",\"\\n\",\"$L52\",\"\\n\",\"$L53\",\"\\n\",\"$L54\",\"\\n\",\"$L55\",\"\\n\",\"$L56\",\"\\n\",\"$L57\",\"\\n\",\"$L58\",\"\\n\",\"$L59\",\"\\n\",\"$L5a\",\"\\n\",\"$L5b\",\"\\n\",\"$L5c\",\"\\n\",\"$L5d\"],\"className\":\"prose flex-1\"}]],\"$L5e\",\"$L5f\"],\"className\":\"flex min-w-0 w-full flex-col gap-4 pt-8 px-4 md:px-6 md:mx-auto\"}],\"$L60\"]}]}]\n"])</script><script>self.__next_f.push([1,"61:I[3448,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"PageFooter\"]\n62:I[3448,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"PageTOC\"]\n63:I[3734,[\"285\",\"static/chunks/285-5cab2c46bf0cbdc3.js\",\"697\",\"static/chunks/697-8c55336afc55c2a1.js\",\"324\",\"static/chunks/324-9e7d7f5bb89b8982.js\",\"870\",\"static/chunks/app/docs/%5B%5B...slug%5D%5D/page-6a2f4c9a93e41015.js\"],\"I18nLabel\"]\n2f:[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}]\n30:[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]\n"])</script><script>self.__next_f.push([1,"31:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"核心论文\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#核心论文\",\"className\":\"peer\",\"children\":\"核心论文\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"32:[\"$\",\"div\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2411.15124\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"1. Tülu 3: Pushing Frontiers in Open Language Model Post-Training\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Lambert et al. (2024.11) — 最完整的开源后训练方案，SFT → DPO → RLVR 的黄金标准流程\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2106.09685\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"2. LoRA: Low-Rank Adaptation of Large Language Models\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Hu et al. (2021) — 参数高效微调奠基论文，提出低秩分解训练方法\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2305.14314\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"3. QLoRA: Efficient Finetuning of Quantized LLMs\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Dettmers et al. (2023) — NF4 量化 + LoRA，使大模型微调走向消费级 GPU\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2305.11206\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"4. LIMA: Less Is More for Alignment\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Zhou et al. (2023) — 证明 1000 条高质量数据可超越 50000 条噪声数据\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2406.08464\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"5. MAGPIE: Alignment Data Synthesis from Scratch\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Xu et al. (ICLR 2025) — 利用对齐模型的自动补全行为合成指令数据\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}]],\"className\":\"grid grid-cols-2 gap-3 @container\"}]\n"])</script><script>self.__next_f.push([1,"33:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"扩展阅读\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#扩展阅读\",\"className\":\"peer\",\"children\":\"扩展阅读\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"34:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2305.16264\",\"children\":\"Scaling Data-Constrained Language Models\"}],\" — Muennighoff et al. (2024), 数据规模与质量的系统研究\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2402.09353\",\"children\":\"DoRA: Weight-Decomposed Low-Rank Adaptation\"}],\" — Liu et al. (2024), LoRA 的改进版本\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2406.06623\",\"children\":\"Spectrum: Targeted Training on Signal to Noise Ratio\"}],\" — Verma et al. (2024), 基于信噪比的层选择\"]}],\"\\n\"]}]\n35:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"36:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"第2课sft-进阶与数据工程\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#第2课sft-进阶与数据工程\",\"className\":\"peer\",\"children\":\"第2课：SFT 进阶与数据工程\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"37:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"核心论文-1\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#核心论文-1\",\"className\":\"peer\",\"children\":\"核心论文\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"38:[\"$\",\"div\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2412.13337\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"1. Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Pareja et al. (2024.12) — 3B-7B 模型 SFT 的全面超参数指南\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2212.10560\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"2. Self-Instruct: Aligning Language Models with Self-Generated Instructions\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Wang et al. (2023) — 指令数据合成的开创性工作\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2306.05685\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"3. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Zheng et al. (NeurIPS 2023) — LLM-as-Judge 评估框架\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2305.14233\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"4. UltraChat: A Large-scale Auto-generated Multi-turn Instruction Dataset\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Ding et al. (2023) — 高质量多轮对话数据集构建方法\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2312.15685\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"5. Deita: Data-Efficient Instruction Tuning Alignment\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Liu et al. (2024) — 数据高效选择策略\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}]],\"className\":\"grid grid-cols-2 gap-3 @container\"}]\n"])</script><script>self.__next_f.push([1,"39:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"扩展阅读-1\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#扩展阅读-1\",\"className\":\"peer\",\"children\":\"扩展阅读\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3a:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://crfm.stanford.edu/2023/03/13/alpaca.html\",\"children\":\"Alpaca: A Strong, Replicable Instruction-Following Model\"}],\" — Stanford (2023), 指令微调的早期里程碑\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2410.01220\",\"children\":\"GRAPE: Generalizing Robot Policy via Preference Alignment\"}],\" — 2025, 适配基座模型分布的数据选择\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2304.12244\",\"children\":\"WizardLM: Empowering Large Language Models to Follow Complex Instructions\"}],\" — Xu et al. (2023)\"]}],\"\\n\"]}]\n3b:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"3c:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"第3课偏好对齐dpo-及其变体\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#第3课偏好对齐dpo-及其变体\",\"className\":\"peer\",\"children\":\"第3课：偏好对齐——DPO 及其变体\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3d:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"核心论文-2\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#核心论文-2\",\"className\":\"peer\",\"children\":\"核心论文\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3e:[\"$\",\"div\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2305.18290\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"1. Direct Preference Optimization: Your Language Model is Secretly a Reward Model\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Rafailov et al. (NeurIPS 2023) — DPO 奠基论文，必读\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2405.14734\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"2. SimPO: Simple Preference Optimization with a Reference-Free Reward\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Meng et al. (NeurIPS 2024) — 无参考模型对齐，\u003c10B 模型 AlpacaEval 2 排名第一\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2402.01306\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"3. KTO: Model Alignment as Prospect Theoretic Optimization\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Ethayarajh et al. (2024) — 行为经济学与 LLM 对齐的关联\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2406.09279\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"4. Unpacking DPO and PPO: Disentangling Best Practices\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Ivison et al. (2024.06) — DPO 与 PPO 的系统性控制实验\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2410.15595\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"5. A Comprehensive Survey of Direct Preference Optimization\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"(2024.10, 更新至2025) — 覆盖 20+ DPO 变体的综述\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}]],\"className\":\"grid grid-cols-2 gap-3 @container\"}]\n"])</script><script>self.__next_f.push([1,"3f:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"扩展阅读-2\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#扩展阅读-2\",\"className\":\"peer\",\"children\":\"扩展阅读\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"40:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2403.07691\",\"children\":\"ORPO: Monolithic Preference Optimization without Reference Model\"}],\" — Hong et al. (2024), 将 SFT 和对齐合并为单一损失\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2310.12036\",\"children\":\"IPO: A General Theoretical Paradigm to Understand Learning from Human Preferences\"}],\" — Azar et al. (Google DeepMind, 2023)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2212.08073\",\"children\":\"Constitutional AI: Harmlessness from AI Feedback\"}],\" — Bai et al. (Anthropic, 2022)\"]}],\"\\n\"]}]\n41:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"42:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"第4课rlhf-原理与推理强化学习grpo\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#第4课rlhf-原理与推理强化学习grpo\",\"className\":\"peer\",\"children\":\"第4课：RLHF 原理与推理强化学习（GRPO）\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"43:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"核心论文-3\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#核心论文-3\",\"className\":\"peer\",\"children\":\"核心论文\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"44:[\"$\",\"div\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2203.02155\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"1. Training Language Models to Follow Instructions with Human Feedback\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Ouyang et al. (OpenAI, 2022) — InstructGPT，确立 RLHF 三阶段流程\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2501.12948\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"2. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via RL\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"DeepSeek-AI (2025.01) — 推理涌现的里程碑论文\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2402.03300\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"3. DeepSeekMath: Pushing the Limits of Mathematical Reasoning\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Shao et al. (2024.02) — GRPO 算法的原始论文\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2408.03314\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"4. Scaling LLM Test-Time Compute Optimally\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Snell et al. (2024.08) — 测试时计算扩展的理论基础\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2503.14476\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"5. DAPO: An Open-Source LLM Reinforcement Learning System at Scale\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Yu et al. (ByteDance, 2025.03) — GRPO 的实用改进，完全开源\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}]],\"className\":\"grid grid-cols-2 gap-3 @container\"}]\n"])</script><script>self.__next_f.push([1,"45:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"扩展阅读-3\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#扩展阅读-3\",\"className\":\"peer\",\"children\":\"扩展阅读\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"46:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2310.12773\",\"children\":\"Safe RLHF: Safe Reinforcement Learning from Human Feedback\"}],\" — 北京大学对齐团队 (ICLR 2024), 解耦有用性和无害性\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2505.09388\",\"children\":\"Qwen3 Technical Report\"}],\" — Qwen Team (2025), Section 4.2 详述四阶段后训练\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2503.20783\",\"children\":\"Dr. GRPO\"}],\" — MIT (2025), 去除长度偏差的 GRPO 改进\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2501.03262\",\"children\":\"REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models\"}],\" — Hu (2025)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/1707.06347\",\"children\":\"Proximal Policy Optimization Algorithms\"}],\" — Schulman et al. (OpenAI, 2017), PPO 原始论文\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"47:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"48:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"第5课模型压缩部署优化与能力扩展\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#第5课模型压缩部署优化与能力扩展\",\"className\":\"peer\",\"children\":\"第5课：模型压缩、部署优化与能力扩展\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"49:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"核心论文-4\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#核心论文-4\",\"className\":\"peer\",\"children\":\"核心论文\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"4a:[\"$\",\"div\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2210.17323\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"1. GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Frantar et al. (2023) — 基于 Hessian 信息的大模型量化方法\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2306.00978\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"2. AWQ: Activation-aware Weight Quantization\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Lin et al. (MLSys 2024) — 激活感知量化，保护重要通道\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2304.08485\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"3. Visual Instruction Tuning (LLaVA)\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Liu et al. (NeurIPS 2023) — VLM 两阶段训练范式\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2409.00920\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"4. ToolACE: Winning the Points of LLM Function Calling\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"Liu et al. (ICLR 2025) — 8B 模型函数调用超越 GPT-4\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}],[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2501.12948\",\"children\":[null,[\"$\",\"h3\",null,{\"className\":\"not-prose mb-1 text-sm font-medium\",\"children\":\"5. DeepSeek-R1 (蒸馏部分)\"}],null,[\"$\",\"div\",null,{\"className\":\"text-sm text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":\"DeepSeek-AI (2025.01) — 将推理能力蒸馏到小模型\"}]}]],\"data-card\":true,\"className\":\"block rounded-xl border bg-fd-card p-4 text-fd-card-foreground transition-colors @max-lg:col-span-full hover:bg-fd-accent/80\"}]],\"className\":\"grid grid-cols-2 gap-3 @container\"}]\n"])</script><script>self.__next_f.push([1,"4b:[\"$\",\"h3\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"扩展阅读-4\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#扩展阅读-4\",\"className\":\"peer\",\"children\":\"扩展阅读\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"4c:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"量化方向\"}],\"：\"]}]\n4d:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2208.07339\",\"children\":\"LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale\"}],\" — Dettmers et al. (2022)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2306.07629\",\"children\":\"SqueezeLLM: Dense-and-Sparse Quantization\"}],\" — Kim et al. (2023)\"]}],\"\\n\"]}]\n4e:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"多模态方向\"}],\"：\"]}]\n4f:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2408.03326\",\"children\":\"LLaVA-OneVision: Easy Visual Task Transfer\"}],\" — Li et al. (2024)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2312.14238\",\"children\":\"InternVL: Scaling Up Vision Foundation Models\"}],\" — Chen et al. (2023)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2312.00849\",\"children\":\"RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment\"}],\" — Yu et al. (2023)\"]}],\"\\n\"]}]\n50:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"工具使用方向\"}],\"：\"]}]\n51:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2305.15334\",\"children\":\"Gorilla: Large Language Model Connected with Massive APIs\"}],\" — Patil et al. (2023)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2302.04761\",\"children\":\"Toolformer: Language Models Can Teach Themselves to Use Tools\"}],\" — Schick et al. (2023)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/2210.03629\",\"children\":\"ReAct: Synergizing Reasoning and Acting in Language Models\"}],\" — Yao et al. (2022)\"]}],\"\\n\"]}]\n52:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"知识蒸馏方向\"}],\"：\"]}]\n53:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\","])</script><script>self.__next_f.push([1,"null,{\"children\":[[\"$\",\"$Le\",null,{\"href\":\"https://arxiv.org/abs/1503.02531\",\"children\":\"Distilling the Knowledge in a Neural Network\"}],\" — Hinton et al. (2015), 经典蒸馏论文\"]}],\"\\n\"]}]\n54:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"55:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"开源框架与工具\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#开源框架与工具\",\"className\":\"peer\",\"children\":\"开源框架与工具\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"56:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"框架\"}],[\"$\",\"th\",null,{\"children\":\"用途\"}],[\"$\",\"th\",null,{\"children\":\"GitHub\"}],[\"$\",\"th\",null,{\"children\":\"课程中使用\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Hugging Face Transformers\"}],[\"$\",\"td\",null,{\"children\":\"模型加载与推理\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/huggingface/transformers\",\"children\":\"github.com/huggingface/transformers\"}]}],[\"$\",\"td\",null,{\"children\":\"全部课次\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"TRL\"}],[\"$\",\"td\",null,{\"children\":\"SFT/DPO/GRPO 训练\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/huggingface/trl\",\"children\":\"github.com/huggingface/trl\"}]}],[\"$\",\"td\",null,{\"children\":\"第1-4课\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"PEFT\"}],[\"$\",\"td\",null,{\"children\":\"LoRA/QLoRA 适配器\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/huggingface/peft\",\"children\":\"github.com/huggingface/peft\"}]}],[\"$\",\"td\",null,{\"children\":\"第1-4课\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"bitsandbytes\"}],[\"$\",\"td\",null,{\"children\":\"量化工具\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/bitsandbytes-foundation/bitsandbytes\",\"children\":\"github.com/bitsandbytes-foundation/bitsandbytes\"}]}],[\"$\",\"td\",null,{\"children\":\"第1、5课\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"LLaMA-Factory\"}],[\"$\",\"td\",null,{\"children\":\"一站式微调框架\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/hiyouga/LLaMA-Factory\",\"children\":\"github.com/hiyouga/LLaMA-Factory\"}]}],[\"$\",\"td\",null,{\"children\":\"第5课选做\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"vLLM\"}],[\"$\",\"td\",null,{\"children\":\"高性能推理引擎\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/vllm-project/vllm\",\"children\":\"github.com/vllm-project/vllm\"}]}],[\"$\",\"td\",null,{\"children\":\"第4-5课\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"OpenRLHF\"}],[\"$\",\"td\",null,{\"children\":\"分布式 RLHF 框架\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/OpenRLHF/OpenRLHF\",\"children\":\"github.com/OpenRLHF/OpenRLHF\"}]}],[\"$\",\"td\",null,{\"children\":\"参考\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"veRL\"}],[\"$\",\"td\",null,{\"children\":\"大规模 GRPO 训练\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/volcengine/verl\",\"children\":\"github.com/volcengine/verl\"}]}],[\"$\",\"td\",null,{\"children\":\"参考\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Outlines\"}],[\"$\",\"td\",null,{\"children\":\"约束解码\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://github.com/outlines-dev/outlines\",\"children\":\"github.com/outlines-dev/outlines\"}]}],[\"$\",\"td\",null,{\"children\":\"第5课\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"57:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"58:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"数据集索引\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#数据集索引\",\"className\":\"peer\",\"children\":\"数据集索引\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"59:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"数据集\"}],[\"$\",\"th\",null,{\"children\":\"类型\"}],[\"$\",\"th\",null,{\"children\":\"规模\"}],[\"$\",\"th\",null,{\"children\":\"课次\"}],[\"$\",\"th\",null,{\"children\":\"链接\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"UltraChat-200K\"}],[\"$\",\"td\",null,{\"children\":\"多轮对话\"}],[\"$\",\"td\",null,{\"children\":\"200K\"}],[\"$\",\"td\",null,{\"children\":\"第1课\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k\",\"children\":\"HuggingFace\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"UltraFeedback\"}],[\"$\",\"td\",null,{\"children\":\"偏好数据\"}],[\"$\",\"td\",null,{\"children\":\"64K\"}],[\"$\",\"td\",null,{\"children\":\"第3课\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized\",\"children\":\"HuggingFace\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"GSM8K\"}],[\"$\",\"td\",null,{\"children\":\"数学推理\"}],[\"$\",\"td\",null,{\"children\":\"8.8K\"}],[\"$\",\"td\",null,{\"children\":\"第4课\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/openai/gsm8k\",\"children\":\"HuggingFace\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"COIG-CQIA\"}],[\"$\",\"td\",null,{\"children\":\"中文指令\"}],[\"$\",\"td\",null,{\"children\":\"多种\"}],[\"$\",\"td\",null,{\"children\":\"第2课\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/m-a-p/COIG-CQIA\",\"children\":\"HuggingFace\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"PKU-SafeRLHF\"}],[\"$\",\"td\",null,{\"children\":\"安全偏好\"}],[\"$\",\"td\",null,{\"children\":\"361K\"}],[\"$\",\"td\",null,{\"children\":\"期末项目\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF\",\"children\":\"HuggingFace\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"LLaVA-Instruct-150K\"}],[\"$\",\"td\",null,{\"children\":\"视觉指令\"}],[\"$\",\"td\",null,{\"children\":\"150K\"}],[\"$\",\"td\",null,{\"children\":\"期末项目\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K\",\"children\":\"HuggingFace\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Glaive FC v2\"}],[\"$\",\"td\",null,{\"children\":\"函数调用\"}],[\"$\",\"td\",null,{\"children\":\"113K\"}],[\"$\",\"td\",null,{\"children\":\"第5课/期末\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2\",\"children\":\"HuggingFace\"}]}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"5a:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"5b:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"推荐学习路径\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#推荐学习路径\",\"className\":\"peer\",\"children\":\"推荐学习路径\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"5c:[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"className\":\"flex gap-2 my-4 rounded-xl border bg-fd-card p-3 ps-1 text-sm text-fd-card-foreground shadow-md\",\"style\":{\"--callout-color\":\"var(--color-fd-info, var(--color-fd-muted))\"},\"children\":[[\"$\",\"div\",null,{\"role\":\"none\",\"className\":\"w-0.5 bg-(--callout-color)/50 rounded-sm\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-5 -me-0.5 fill-(--callout-color) text-fd-card\",\"children\":[[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"1dtifu\",{\"d\":\"M12 16v-4\"}],[\"$\",\"path\",\"e9boi3\",{\"d\":\"M12 8h.01\"}]],\"$undefined\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-2 min-w-0 flex-1\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-fd-muted-foreground prose-no-margin empty:hidden\",\"children\":[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"论文阅读建议\"}],\"：每课精读 1-2 篇核心论文（标记为\\\"必读\\\"的），其余泛读 Abstract 和实验部分。整个课程建议精读 8-10 篇论文，泛读 15-20 篇。\"]}]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"5d:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"阶段\"}],[\"$\",\"th\",null,{\"children\":\"重点论文\"}],[\"$\",\"th\",null,{\"children\":\"阅读优先级\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"入门（第1-2课）\"}],[\"$\",\"td\",null,{\"children\":\"LoRA, QLoRA, LIMA\"}],[\"$\",\"td\",null,{\"children\":\"必读\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"对齐（第3课）\"}],[\"$\",\"td\",null,{\"children\":\"DPO, SimPO\"}],[\"$\",\"td\",null,{\"children\":\"必读\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"推理（第4课）\"}],[\"$\",\"td\",null,{\"children\":\"DeepSeek-R1, GRPO\"}],[\"$\",\"td\",null,{\"children\":\"必读\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"部署（第5课）\"}],[\"$\",\"td\",null,{\"children\":\"GPTQ 或 AWQ (选一), LLaVA\"}],[\"$\",\"td\",null,{\"children\":\"推荐\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"综合（第6课）\"}],[\"$\",\"td\",null,{\"children\":\"Tülu 3, Qwen3 Technical Report\"}],[\"$\",\"td\",null,{\"children\":\"必读\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"5e:[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-center justify-between gap-4 empty:hidden\",\"children\":[\"$undefined\",\"$undefined\"]}]\n5f:[\"$\",\"$L61\",null,{\"items\":\"$undefined\"}]\n60:[\"$\",\"$L62\",null,{\"children\":[\"$undefined\",[\"$\",\"h3\",null,{\"className\":\"inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-4\",\"children\":[[[\"$\",\"path\",\"olowqp\",{\"d\":\"M15 18H3\"}],[\"$\",\"path\",\"16j9eg\",{\"d\":\"M17 6H3\"}],[\"$\",\"path\",\"2avoz0\",{\"d\":\"M21 12H3\"}]],\"$undefined\"]}],[\"$\",\"$L63\",null,{\"label\":\"toc\"}]]}],[\"$\",\"$L2c\",null,{\"children\":[\"$\",\"$L2d\",null,{}]}],\"$undefined\"]}]\n"])</script><script>self.__next_f.push([1,"24:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n20:null\n"])</script><script>self.__next_f.push([1,"22:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"完整参考文献 | LLM 后训练课程\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"按课次整理的全部推荐论文、教材和在线资源\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"27:\"$22:metadata\"\n"])</script></body></html>